2022-06-21 17:48:17,270 - Log file for this run: /home/geffencooper/Model_Development/ai8x-training/jupyter_logging/train_log___2022.06.21-174817/train_log___2022.06.21-174817.log
2022-06-21 17:48:17,278 - dataset_name:cats_and_dogs
dataset_fn=<function cats_and_dogs_get_datasets at 0x7fcef0358820>
num_classes=2
model_name=catdognet
dimensions=(3, 128, 128)
batch_size=32
validation_split=0.1
lr=0.001000
2022-06-21 17:48:18,349 - Dataset sizes:
	training=18000
	validation=2000
	test=5000
2022-06-21 17:48:18,350 - Augmentations:Compose(
    Resize(size=(128, 128), interpolation=bilinear)
    RandomHorizontalFlip(p=0.5)
    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 5))
    ToTensor()
    <ai8x.normalize object at 0x7fd038618fa0>
)
2022-06-21 17:48:20,667 - epochs: 40
2022-06-21 17:48:20,668 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-06-21 17:48:20,669 - lr_schedule:base: [0.001] milestones: Counter({5: 1, 25: 1}) gamma: 0.5
2022-06-21 17:48:20,670 - qat policy: {'start_epoch': 5, 'weight_bits': 8}
2022-06-21 17:48:23,267 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:48:25,692 - Epoch: [0][  100/  563]    objective_loss 0.664932                                        LR 0.001000    Time 0.024220    
2022-06-21 17:48:27,866 - Epoch: [0][  200/  563]    objective_loss 0.640472                                        LR 0.001000    Time 0.022959    
2022-06-21 17:48:30,031 - Epoch: [0][  300/  563]    objective_loss 0.627607                                        LR 0.001000    Time 0.022510    
2022-06-21 17:48:32,216 - Epoch: [0][  400/  563]    objective_loss 0.610300                                        LR 0.001000    Time 0.022336    
2022-06-21 17:48:34,399 - Epoch: [0][  500/  563]    objective_loss 0.594996                                        LR 0.001000    Time 0.022226    
2022-06-21 17:48:35,756 - Epoch: [0][  563/  563]    objective_loss 0.583438    Top1 83.333333    LR 0.001000    Time 0.022145    
2022-06-21 17:48:35,798 - --- validate (epoch=0)-----------
2022-06-21 17:48:35,799 - 2000 samples (32 per mini-batch)
2022-06-21 17:48:37,367 - Epoch: [0][   63/   63]    Loss 0.600485    Top1 67.850000    
2022-06-21 17:48:37,409 - ==> Top1: 67.850    Loss: 0.600

2022-06-21 17:48:37,409 - ==> Confusion:
[[405 580]
 [ 63 952]]

2022-06-21 17:48:37,464 - ==> Best [Top1: 67.850 on epoch: 0]
2022-06-21 17:48:37,470 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_checkpoint.pth.tar
2022-06-21 17:48:37,493 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:48:39,919 - Epoch: [1][  100/  563]    objective_loss 0.476420                                        LR 0.001000    Time 0.024213    
2022-06-21 17:48:42,093 - Epoch: [1][  200/  563]    objective_loss 0.464826                                        LR 0.001000    Time 0.022954    
2022-06-21 17:48:44,248 - Epoch: [1][  300/  563]    objective_loss 0.456843                                        LR 0.001000    Time 0.022474    
2022-06-21 17:48:46,418 - Epoch: [1][  400/  563]    objective_loss 0.446679                                        LR 0.001000    Time 0.022271    
2022-06-21 17:48:48,575 - Epoch: [1][  500/  563]    objective_loss 0.440880                                        LR 0.001000    Time 0.022124    
2022-06-21 17:48:49,927 - Epoch: [1][  563/  563]    objective_loss 0.437735    Top1 87.500000    LR 0.001000    Time 0.022044    
2022-06-21 17:48:49,969 - --- validate (epoch=1)-----------
2022-06-21 17:48:49,970 - 2000 samples (32 per mini-batch)
2022-06-21 17:48:51,531 - Epoch: [1][   63/   63]    Loss 0.412594    Top1 80.700000    
2022-06-21 17:48:51,583 - ==> Top1: 80.700    Loss: 0.413

2022-06-21 17:48:51,584 - ==> Confusion:
[[865 120]
 [266 749]]

2022-06-21 17:48:51,636 - ==> Best [Top1: 80.700 on epoch: 1]
2022-06-21 17:48:51,642 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_checkpoint.pth.tar
2022-06-21 17:48:51,674 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:48:54,099 - Epoch: [2][  100/  563]    objective_loss 0.375455                                        LR 0.001000    Time 0.024206    
2022-06-21 17:48:56,254 - Epoch: [2][  200/  563]    objective_loss 0.375453                                        LR 0.001000    Time 0.022854    
2022-06-21 17:48:58,409 - Epoch: [2][  300/  563]    objective_loss 0.376784                                        LR 0.001000    Time 0.022405    
2022-06-21 17:49:00,569 - Epoch: [2][  400/  563]    objective_loss 0.372835                                        LR 0.001000    Time 0.022196    
2022-06-21 17:49:02,709 - Epoch: [2][  500/  563]    objective_loss 0.369396                                        LR 0.001000    Time 0.022030    
2022-06-21 17:49:04,055 - Epoch: [2][  563/  563]    objective_loss 0.366365    Top1 79.166667    LR 0.001000    Time 0.021949    
2022-06-21 17:49:04,103 - --- validate (epoch=2)-----------
2022-06-21 17:49:04,104 - 2000 samples (32 per mini-batch)
2022-06-21 17:49:05,664 - Epoch: [2][   63/   63]    Loss 0.398449    Top1 82.650000    
2022-06-21 17:49:05,706 - ==> Top1: 82.650    Loss: 0.398

2022-06-21 17:49:05,707 - ==> Confusion:
[[716 269]
 [ 78 937]]

2022-06-21 17:49:05,757 - ==> Best [Top1: 82.650 on epoch: 2]
2022-06-21 17:49:05,762 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_checkpoint.pth.tar
2022-06-21 17:49:05,792 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:49:08,203 - Epoch: [3][  100/  563]    objective_loss 0.332682                                        LR 0.001000    Time 0.024066    
2022-06-21 17:49:10,349 - Epoch: [3][  200/  563]    objective_loss 0.329543                                        LR 0.001000    Time 0.022744    
2022-06-21 17:49:12,496 - Epoch: [3][  300/  563]    objective_loss 0.328671                                        LR 0.001000    Time 0.022306    
2022-06-21 17:49:14,651 - Epoch: [3][  400/  563]    objective_loss 0.326368                                        LR 0.001000    Time 0.022108    
2022-06-21 17:49:16,794 - Epoch: [3][  500/  563]    objective_loss 0.322627                                        LR 0.001000    Time 0.021966    
2022-06-21 17:49:18,137 - Epoch: [3][  563/  563]    objective_loss 0.321379    Top1 93.750000    LR 0.001000    Time 0.021889    
2022-06-21 17:49:18,179 - --- validate (epoch=3)-----------
2022-06-21 17:49:18,180 - 2000 samples (32 per mini-batch)
2022-06-21 17:49:19,746 - Epoch: [3][   63/   63]    Loss 0.351466    Top1 84.100000    
2022-06-21 17:49:19,791 - ==> Top1: 84.100    Loss: 0.351

2022-06-21 17:49:19,792 - ==> Confusion:
[[893  92]
 [226 789]]

2022-06-21 17:49:19,842 - ==> Best [Top1: 84.100 on epoch: 3]
2022-06-21 17:49:19,847 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_checkpoint.pth.tar
2022-06-21 17:49:19,877 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:49:22,337 - Epoch: [4][  100/  563]    objective_loss 0.273052                                        LR 0.001000    Time 0.024564    
2022-06-21 17:49:24,504 - Epoch: [4][  200/  563]    objective_loss 0.283976                                        LR 0.001000    Time 0.023093    
2022-06-21 17:49:26,670 - Epoch: [4][  300/  563]    objective_loss 0.283508                                        LR 0.001000    Time 0.022605    
2022-06-21 17:49:28,847 - Epoch: [4][  400/  563]    objective_loss 0.281456                                        LR 0.001000    Time 0.022386    
2022-06-21 17:49:31,011 - Epoch: [4][  500/  563]    objective_loss 0.280036                                        LR 0.001000    Time 0.022230    
2022-06-21 17:49:32,364 - Epoch: [4][  563/  563]    objective_loss 0.278672    Top1 79.166667    LR 0.001000    Time 0.022141    
2022-06-21 17:49:32,407 - --- validate (epoch=4)-----------
2022-06-21 17:49:32,407 - 2000 samples (32 per mini-batch)
2022-06-21 17:49:33,997 - Epoch: [4][   63/   63]    Loss 0.482228    Top1 77.900000    
2022-06-21 17:49:34,050 - ==> Top1: 77.900    Loss: 0.482

2022-06-21 17:49:34,051 - ==> Confusion:
[[956  29]
 [413 602]]

2022-06-21 17:49:34,102 - ==> Best [Top1: 84.100 on epoch: 3]
2022-06-21 17:49:34,106 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_checkpoint.pth.tar
2022-06-21 17:49:34,159 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:49:37,258 - Epoch: [5][  100/  563]    objective_loss 0.385264                                        LR 0.000500    Time 0.030957    
2022-06-21 17:49:39,959 - Epoch: [5][  200/  563]    objective_loss 0.363695                                        LR 0.000500    Time 0.028964    
2022-06-21 17:49:42,662 - Epoch: [5][  300/  563]    objective_loss 0.346825                                        LR 0.000500    Time 0.028307    
2022-06-21 17:49:45,404 - Epoch: [5][  400/  563]    objective_loss 0.337933                                        LR 0.000500    Time 0.028078    
2022-06-21 17:49:48,112 - Epoch: [5][  500/  563]    objective_loss 0.330921                                        LR 0.000500    Time 0.027872    
2022-06-21 17:49:49,812 - Epoch: [5][  563/  563]    objective_loss 0.326072    Top1 87.500000    LR 0.000500    Time 0.027768    
2022-06-21 17:49:49,854 - --- validate (epoch=5)-----------
2022-06-21 17:49:49,855 - 2000 samples (32 per mini-batch)
2022-06-21 17:49:51,457 - Epoch: [5][   63/   63]    Loss 0.334377    Top1 84.900000    
2022-06-21 17:49:51,499 - ==> Top1: 84.900    Loss: 0.334

2022-06-21 17:49:51,500 - ==> Confusion:
[[875 110]
 [192 823]]

2022-06-21 17:49:51,549 - ==> Best [Top1: 84.900 on epoch: 5]
2022-06-21 17:49:51,554 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:49:51,572 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:49:54,580 - Epoch: [6][  100/  563]    objective_loss 0.273206                                        LR 0.000500    Time 0.030034    
2022-06-21 17:49:57,320 - Epoch: [6][  200/  563]    objective_loss 0.269332                                        LR 0.000500    Time 0.028696    
2022-06-21 17:50:00,053 - Epoch: [6][  300/  563]    objective_loss 0.271082                                        LR 0.000500    Time 0.028231    
2022-06-21 17:50:02,787 - Epoch: [6][  400/  563]    objective_loss 0.271809                                        LR 0.000500    Time 0.028000    
2022-06-21 17:50:05,518 - Epoch: [6][  500/  563]    objective_loss 0.266134                                        LR 0.000500    Time 0.027854    
2022-06-21 17:50:07,248 - Epoch: [6][  563/  563]    objective_loss 0.267950    Top1 91.666667    LR 0.000500    Time 0.027805    
2022-06-21 17:50:07,289 - --- validate (epoch=6)-----------
2022-06-21 17:50:07,291 - 2000 samples (32 per mini-batch)
2022-06-21 17:50:08,864 - Epoch: [6][   63/   63]    Loss 0.325431    Top1 85.450000    
2022-06-21 17:50:08,907 - ==> Top1: 85.450    Loss: 0.325

2022-06-21 17:50:08,908 - ==> Confusion:
[[887  98]
 [193 822]]

2022-06-21 17:50:08,959 - ==> Best [Top1: 85.450 on epoch: 6]
2022-06-21 17:50:08,962 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:50:08,991 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:50:11,978 - Epoch: [7][  100/  563]    objective_loss 0.225163                                        LR 0.000500    Time 0.029817    
2022-06-21 17:50:14,811 - Epoch: [7][  200/  563]    objective_loss 0.235718                                        LR 0.000500    Time 0.029054    
2022-06-21 17:50:17,683 - Epoch: [7][  300/  563]    objective_loss 0.235347                                        LR 0.000500    Time 0.028932    
2022-06-21 17:50:20,503 - Epoch: [7][  400/  563]    objective_loss 0.234507                                        LR 0.000500    Time 0.028741    
2022-06-21 17:50:23,219 - Epoch: [7][  500/  563]    objective_loss 0.237951                                        LR 0.000500    Time 0.028415    
2022-06-21 17:50:24,924 - Epoch: [7][  563/  563]    objective_loss 0.237638    Top1 85.416667    LR 0.000500    Time 0.028260    
2022-06-21 17:50:24,967 - --- validate (epoch=7)-----------
2022-06-21 17:50:24,968 - 2000 samples (32 per mini-batch)
2022-06-21 17:50:26,557 - Epoch: [7][   63/   63]    Loss 0.305944    Top1 87.150000    
2022-06-21 17:50:26,600 - ==> Top1: 87.150    Loss: 0.306

2022-06-21 17:50:26,600 - ==> Confusion:
[[818 167]
 [ 90 925]]

2022-06-21 17:50:26,647 - ==> Best [Top1: 87.150 on epoch: 7]
2022-06-21 17:50:26,652 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:50:26,681 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:50:29,691 - Epoch: [8][  100/  563]    objective_loss 0.210397                                        LR 0.000500    Time 0.030048    
2022-06-21 17:50:32,408 - Epoch: [8][  200/  563]    objective_loss 0.222793                                        LR 0.000500    Time 0.028591    
2022-06-21 17:50:35,134 - Epoch: [8][  300/  563]    objective_loss 0.220596                                        LR 0.000500    Time 0.028135    
2022-06-21 17:50:37,855 - Epoch: [8][  400/  563]    objective_loss 0.218085                                        LR 0.000500    Time 0.027897    
2022-06-21 17:50:40,570 - Epoch: [8][  500/  563]    objective_loss 0.218932                                        LR 0.000500    Time 0.027741    
2022-06-21 17:50:42,274 - Epoch: [8][  563/  563]    objective_loss 0.218570    Top1 93.750000    LR 0.000500    Time 0.027660    
2022-06-21 17:50:42,317 - --- validate (epoch=8)-----------
2022-06-21 17:50:42,317 - 2000 samples (32 per mini-batch)
2022-06-21 17:50:43,926 - Epoch: [8][   63/   63]    Loss 0.302589    Top1 87.050000    
2022-06-21 17:50:43,969 - ==> Top1: 87.050    Loss: 0.303

2022-06-21 17:50:43,969 - ==> Confusion:
[[919  66]
 [193 822]]

2022-06-21 17:50:44,025 - ==> Best [Top1: 87.150 on epoch: 7]
2022-06-21 17:50:44,031 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:50:44,060 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:50:47,056 - Epoch: [9][  100/  563]    objective_loss 0.194797                                        LR 0.000500    Time 0.029920    
2022-06-21 17:50:49,790 - Epoch: [9][  200/  563]    objective_loss 0.192877                                        LR 0.000500    Time 0.028610    
2022-06-21 17:50:52,528 - Epoch: [9][  300/  563]    objective_loss 0.195096                                        LR 0.000500    Time 0.028188    
2022-06-21 17:50:55,271 - Epoch: [9][  400/  563]    objective_loss 0.192652                                        LR 0.000500    Time 0.027990    
2022-06-21 17:50:58,003 - Epoch: [9][  500/  563]    objective_loss 0.195119                                        LR 0.000500    Time 0.027847    
2022-06-21 17:50:59,716 - Epoch: [9][  563/  563]    objective_loss 0.194483    Top1 91.666667    LR 0.000500    Time 0.027770    
2022-06-21 17:50:59,759 - --- validate (epoch=9)-----------
2022-06-21 17:50:59,759 - 2000 samples (32 per mini-batch)
2022-06-21 17:51:01,399 - Epoch: [9][   63/   63]    Loss 0.343165    Top1 86.700000    
2022-06-21 17:51:01,442 - ==> Top1: 86.700    Loss: 0.343

2022-06-21 17:51:01,443 - ==> Confusion:
[[778 207]
 [ 59 956]]

2022-06-21 17:51:01,493 - ==> Best [Top1: 87.150 on epoch: 7]
2022-06-21 17:51:01,498 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:51:01,525 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:51:04,494 - Epoch: [10][  100/  563]    objective_loss 0.165373                                        LR 0.000500    Time 0.029649    
2022-06-21 17:51:07,211 - Epoch: [10][  200/  563]    objective_loss 0.181676                                        LR 0.000500    Time 0.028392    
2022-06-21 17:51:09,925 - Epoch: [10][  300/  563]    objective_loss 0.178710                                        LR 0.000500    Time 0.027963    
2022-06-21 17:51:12,645 - Epoch: [10][  400/  563]    objective_loss 0.181563                                        LR 0.000500    Time 0.027763    
2022-06-21 17:51:15,355 - Epoch: [10][  500/  563]    objective_loss 0.184248                                        LR 0.000500    Time 0.027624    
2022-06-21 17:51:17,056 - Epoch: [10][  563/  563]    objective_loss 0.183996    Top1 95.833333    LR 0.000500    Time 0.027550    
2022-06-21 17:51:17,099 - --- validate (epoch=10)-----------
2022-06-21 17:51:17,099 - 2000 samples (32 per mini-batch)
2022-06-21 17:51:18,703 - Epoch: [10][   63/   63]    Loss 0.282476    Top1 88.750000    
2022-06-21 17:51:18,745 - ==> Top1: 88.750    Loss: 0.282

2022-06-21 17:51:18,746 - ==> Confusion:
[[867 118]
 [107 908]]

2022-06-21 17:51:18,796 - ==> Best [Top1: 88.750 on epoch: 10]
2022-06-21 17:51:18,801 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:51:18,829 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:51:21,824 - Epoch: [11][  100/  563]    objective_loss 0.174081                                        LR 0.000500    Time 0.029915    
2022-06-21 17:51:24,550 - Epoch: [11][  200/  563]    objective_loss 0.165652                                        LR 0.000500    Time 0.028567    
2022-06-21 17:51:27,279 - Epoch: [11][  300/  563]    objective_loss 0.170943                                        LR 0.000500    Time 0.028128    
2022-06-21 17:51:30,012 - Epoch: [11][  400/  563]    objective_loss 0.168780                                        LR 0.000500    Time 0.027921    
2022-06-21 17:51:32,739 - Epoch: [11][  500/  563]    objective_loss 0.169082                                        LR 0.000500    Time 0.027784    
2022-06-21 17:51:34,447 - Epoch: [11][  563/  563]    objective_loss 0.167868    Top1 91.666667    LR 0.000500    Time 0.027705    
2022-06-21 17:51:34,489 - --- validate (epoch=11)-----------
2022-06-21 17:51:34,490 - 2000 samples (32 per mini-batch)
2022-06-21 17:51:36,102 - Epoch: [11][   63/   63]    Loss 0.314061    Top1 88.000000    
2022-06-21 17:51:36,146 - ==> Top1: 88.000    Loss: 0.314

2022-06-21 17:51:36,147 - ==> Confusion:
[[888  97]
 [143 872]]

2022-06-21 17:51:36,197 - ==> Best [Top1: 88.750 on epoch: 10]
2022-06-21 17:51:36,202 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:51:36,229 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:51:39,310 - Epoch: [12][  100/  563]    objective_loss 0.156697                                        LR 0.000500    Time 0.030770    
2022-06-21 17:51:42,030 - Epoch: [12][  200/  563]    objective_loss 0.154777                                        LR 0.000500    Time 0.028971    
2022-06-21 17:51:44,752 - Epoch: [12][  300/  563]    objective_loss 0.154092                                        LR 0.000500    Time 0.028377    
2022-06-21 17:51:47,503 - Epoch: [12][  400/  563]    objective_loss 0.159185                                        LR 0.000500    Time 0.028151    
2022-06-21 17:51:50,376 - Epoch: [12][  500/  563]    objective_loss 0.158151                                        LR 0.000500    Time 0.028260    
2022-06-21 17:51:52,159 - Epoch: [12][  563/  563]    objective_loss 0.156857    Top1 100.000000    LR 0.000500    Time 0.028261    
2022-06-21 17:51:52,201 - --- validate (epoch=12)-----------
2022-06-21 17:51:52,202 - 2000 samples (32 per mini-batch)
2022-06-21 17:51:53,772 - Epoch: [12][   63/   63]    Loss 0.329106    Top1 88.000000    
2022-06-21 17:51:53,816 - ==> Top1: 88.000    Loss: 0.329

2022-06-21 17:51:53,816 - ==> Confusion:
[[914  71]
 [169 846]]

2022-06-21 17:51:53,867 - ==> Best [Top1: 88.750 on epoch: 10]
2022-06-21 17:51:53,872 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:51:53,900 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:51:56,882 - Epoch: [13][  100/  563]    objective_loss 0.140222                                        LR 0.000500    Time 0.029773    
2022-06-21 17:51:59,593 - Epoch: [13][  200/  563]    objective_loss 0.134306                                        LR 0.000500    Time 0.028423    
2022-06-21 17:52:02,304 - Epoch: [13][  300/  563]    objective_loss 0.139585                                        LR 0.000500    Time 0.027974    
2022-06-21 17:52:05,018 - Epoch: [13][  400/  563]    objective_loss 0.136090                                        LR 0.000500    Time 0.027758    
2022-06-21 17:52:07,721 - Epoch: [13][  500/  563]    objective_loss 0.140052                                        LR 0.000500    Time 0.027605    
2022-06-21 17:52:09,421 - Epoch: [13][  563/  563]    objective_loss 0.141928    Top1 89.583333    LR 0.000500    Time 0.027532    
2022-06-21 17:52:09,464 - --- validate (epoch=13)-----------
2022-06-21 17:52:09,465 - 2000 samples (32 per mini-batch)
2022-06-21 17:52:11,075 - Epoch: [13][   63/   63]    Loss 0.299849    Top1 88.400000    
2022-06-21 17:52:11,117 - ==> Top1: 88.400    Loss: 0.300

2022-06-21 17:52:11,118 - ==> Confusion:
[[875 110]
 [122 893]]

2022-06-21 17:52:11,168 - ==> Best [Top1: 88.750 on epoch: 10]
2022-06-21 17:52:11,174 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:52:11,203 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:52:14,242 - Epoch: [14][  100/  563]    objective_loss 0.120705                                        LR 0.000500    Time 0.030342    
2022-06-21 17:52:16,978 - Epoch: [14][  200/  563]    objective_loss 0.124730                                        LR 0.000500    Time 0.028830    
2022-06-21 17:52:19,709 - Epoch: [14][  300/  563]    objective_loss 0.125284                                        LR 0.000500    Time 0.028311    
2022-06-21 17:52:22,446 - Epoch: [14][  400/  563]    objective_loss 0.127760                                        LR 0.000500    Time 0.028068    
2022-06-21 17:52:25,173 - Epoch: [14][  500/  563]    objective_loss 0.129284                                        LR 0.000500    Time 0.027902    
2022-06-21 17:52:26,872 - Epoch: [14][  563/  563]    objective_loss 0.131934    Top1 93.750000    LR 0.000500    Time 0.027793    
2022-06-21 17:52:26,917 - --- validate (epoch=14)-----------
2022-06-21 17:52:26,918 - 2000 samples (32 per mini-batch)
2022-06-21 17:52:28,516 - Epoch: [14][   63/   63]    Loss 0.292119    Top1 88.700000    
2022-06-21 17:52:28,559 - ==> Top1: 88.700    Loss: 0.292

2022-06-21 17:52:28,560 - ==> Confusion:
[[862 123]
 [103 912]]

2022-06-21 17:52:28,610 - ==> Best [Top1: 88.750 on epoch: 10]
2022-06-21 17:52:28,615 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:52:28,641 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:52:31,759 - Epoch: [15][  100/  563]    objective_loss 0.115859                                        LR 0.000500    Time 0.031136    
2022-06-21 17:52:34,619 - Epoch: [15][  200/  563]    objective_loss 0.113016                                        LR 0.000500    Time 0.029848    
2022-06-21 17:52:37,348 - Epoch: [15][  300/  563]    objective_loss 0.117450                                        LR 0.000500    Time 0.028987    
2022-06-21 17:52:40,091 - Epoch: [15][  400/  563]    objective_loss 0.116560                                        LR 0.000500    Time 0.028588    
2022-06-21 17:52:42,823 - Epoch: [15][  500/  563]    objective_loss 0.119253                                        LR 0.000500    Time 0.028328    
2022-06-21 17:52:44,551 - Epoch: [15][  563/  563]    objective_loss 0.119802    Top1 95.833333    LR 0.000500    Time 0.028222    
2022-06-21 17:52:44,595 - --- validate (epoch=15)-----------
2022-06-21 17:52:44,595 - 2000 samples (32 per mini-batch)
2022-06-21 17:52:46,207 - Epoch: [15][   63/   63]    Loss 0.295382    Top1 89.050000    
2022-06-21 17:52:46,250 - ==> Top1: 89.050    Loss: 0.295

2022-06-21 17:52:46,250 - ==> Confusion:
[[897  88]
 [131 884]]

2022-06-21 17:52:46,304 - ==> Best [Top1: 89.050 on epoch: 15]
2022-06-21 17:52:46,310 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:52:46,342 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:52:49,331 - Epoch: [16][  100/  563]    objective_loss 0.094048                                        LR 0.000500    Time 0.029855    
2022-06-21 17:52:52,054 - Epoch: [16][  200/  563]    objective_loss 0.104021                                        LR 0.000500    Time 0.028521    
2022-06-21 17:52:54,870 - Epoch: [16][  300/  563]    objective_loss 0.110331                                        LR 0.000500    Time 0.028389    
2022-06-21 17:52:57,709 - Epoch: [16][  400/  563]    objective_loss 0.115451                                        LR 0.000500    Time 0.028381    
2022-06-21 17:53:00,439 - Epoch: [16][  500/  563]    objective_loss 0.114361                                        LR 0.000500    Time 0.028156    
2022-06-21 17:53:02,149 - Epoch: [16][  563/  563]    objective_loss 0.114281    Top1 100.000000    LR 0.000500    Time 0.028039    
2022-06-21 17:53:02,191 - --- validate (epoch=16)-----------
2022-06-21 17:53:02,192 - 2000 samples (32 per mini-batch)
2022-06-21 17:53:03,758 - Epoch: [16][   63/   63]    Loss 0.309801    Top1 89.300000    
2022-06-21 17:53:03,801 - ==> Top1: 89.300    Loss: 0.310

2022-06-21 17:53:03,802 - ==> Confusion:
[[910  75]
 [139 876]]

2022-06-21 17:53:03,853 - ==> Best [Top1: 89.300 on epoch: 16]
2022-06-21 17:53:03,858 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:53:03,887 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:53:06,866 - Epoch: [17][  100/  563]    objective_loss 0.093661                                        LR 0.000500    Time 0.029738    
2022-06-21 17:53:09,575 - Epoch: [17][  200/  563]    objective_loss 0.098471                                        LR 0.000500    Time 0.028391    
2022-06-21 17:53:12,285 - Epoch: [17][  300/  563]    objective_loss 0.104454                                        LR 0.000500    Time 0.027951    
2022-06-21 17:53:15,003 - Epoch: [17][  400/  563]    objective_loss 0.102525                                        LR 0.000500    Time 0.027749    
2022-06-21 17:53:17,849 - Epoch: [17][  500/  563]    objective_loss 0.103822                                        LR 0.000500    Time 0.027885    
2022-06-21 17:53:19,554 - Epoch: [17][  563/  563]    objective_loss 0.103988    Top1 89.583333    LR 0.000500    Time 0.027788    
2022-06-21 17:53:19,597 - --- validate (epoch=17)-----------
2022-06-21 17:53:19,598 - 2000 samples (32 per mini-batch)
2022-06-21 17:53:21,201 - Epoch: [17][   63/   63]    Loss 0.315829    Top1 88.300000    
2022-06-21 17:53:21,245 - ==> Top1: 88.300    Loss: 0.316

2022-06-21 17:53:21,245 - ==> Confusion:
[[886  99]
 [135 880]]

2022-06-21 17:53:21,296 - ==> Best [Top1: 89.300 on epoch: 16]
2022-06-21 17:53:21,301 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:53:21,318 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:53:24,512 - Epoch: [18][  100/  563]    objective_loss 0.093541                                        LR 0.000500    Time 0.031897    
2022-06-21 17:53:27,352 - Epoch: [18][  200/  563]    objective_loss 0.089109                                        LR 0.000500    Time 0.030130    
2022-06-21 17:53:30,197 - Epoch: [18][  300/  563]    objective_loss 0.094153                                        LR 0.000500    Time 0.029558    
2022-06-21 17:53:33,038 - Epoch: [18][  400/  563]    objective_loss 0.096787                                        LR 0.000500    Time 0.029263    
2022-06-21 17:53:35,820 - Epoch: [18][  500/  563]    objective_loss 0.099401                                        LR 0.000500    Time 0.028965    
2022-06-21 17:53:37,515 - Epoch: [18][  563/  563]    objective_loss 0.100979    Top1 95.833333    LR 0.000500    Time 0.028732    
2022-06-21 17:53:37,559 - --- validate (epoch=18)-----------
2022-06-21 17:53:37,560 - 2000 samples (32 per mini-batch)
2022-06-21 17:53:39,166 - Epoch: [18][   63/   63]    Loss 0.284764    Top1 89.450000    
2022-06-21 17:53:39,211 - ==> Top1: 89.450    Loss: 0.285

2022-06-21 17:53:39,211 - ==> Confusion:
[[863 122]
 [ 89 926]]

2022-06-21 17:53:39,262 - ==> Best [Top1: 89.450 on epoch: 18]
2022-06-21 17:53:39,267 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:53:39,297 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:53:42,324 - Epoch: [19][  100/  563]    objective_loss 0.085143                                        LR 0.000500    Time 0.030222    
2022-06-21 17:53:45,056 - Epoch: [19][  200/  563]    objective_loss 0.090256                                        LR 0.000500    Time 0.028751    
2022-06-21 17:53:47,787 - Epoch: [19][  300/  563]    objective_loss 0.092358                                        LR 0.000500    Time 0.028259    
2022-06-21 17:53:50,624 - Epoch: [19][  400/  563]    objective_loss 0.090698                                        LR 0.000500    Time 0.028278    
2022-06-21 17:53:53,488 - Epoch: [19][  500/  563]    objective_loss 0.092449                                        LR 0.000500    Time 0.028343    
2022-06-21 17:53:55,253 - Epoch: [19][  563/  563]    objective_loss 0.092608    Top1 97.916667    LR 0.000500    Time 0.028303    
2022-06-21 17:53:55,296 - --- validate (epoch=19)-----------
2022-06-21 17:53:55,297 - 2000 samples (32 per mini-batch)
2022-06-21 17:53:56,924 - Epoch: [19][   63/   63]    Loss 0.325050    Top1 89.200000    
2022-06-21 17:53:56,966 - ==> Top1: 89.200    Loss: 0.325

2022-06-21 17:53:56,967 - ==> Confusion:
[[873 112]
 [104 911]]

2022-06-21 17:53:57,018 - ==> Best [Top1: 89.450 on epoch: 18]
2022-06-21 17:53:57,022 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:53:57,049 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:54:00,179 - Epoch: [20][  100/  563]    objective_loss 0.074661                                        LR 0.000500    Time 0.031258    
2022-06-21 17:54:03,048 - Epoch: [20][  200/  563]    objective_loss 0.076893                                        LR 0.000500    Time 0.029953    
2022-06-21 17:54:05,918 - Epoch: [20][  300/  563]    objective_loss 0.084027                                        LR 0.000500    Time 0.029525    
2022-06-21 17:54:08,665 - Epoch: [20][  400/  563]    objective_loss 0.086308                                        LR 0.000500    Time 0.029003    
2022-06-21 17:54:11,369 - Epoch: [20][  500/  563]    objective_loss 0.088374                                        LR 0.000500    Time 0.028601    
2022-06-21 17:54:13,073 - Epoch: [20][  563/  563]    objective_loss 0.089937    Top1 91.666667    LR 0.000500    Time 0.028424    
2022-06-21 17:54:13,115 - --- validate (epoch=20)-----------
2022-06-21 17:54:13,116 - 2000 samples (32 per mini-batch)
2022-06-21 17:54:14,706 - Epoch: [20][   63/   63]    Loss 0.338164    Top1 87.950000    
2022-06-21 17:54:14,748 - ==> Top1: 87.950    Loss: 0.338

2022-06-21 17:54:14,749 - ==> Confusion:
[[847 138]
 [103 912]]

2022-06-21 17:54:14,800 - ==> Best [Top1: 89.450 on epoch: 18]
2022-06-21 17:54:14,805 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:54:14,836 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:54:17,795 - Epoch: [21][  100/  563]    objective_loss 0.079159                                        LR 0.000500    Time 0.029549    
2022-06-21 17:54:20,507 - Epoch: [21][  200/  563]    objective_loss 0.076006                                        LR 0.000500    Time 0.028314    
2022-06-21 17:54:23,231 - Epoch: [21][  300/  563]    objective_loss 0.073230                                        LR 0.000500    Time 0.027940    
2022-06-21 17:54:25,953 - Epoch: [21][  400/  563]    objective_loss 0.075614                                        LR 0.000500    Time 0.027752    
2022-06-21 17:54:28,677 - Epoch: [21][  500/  563]    objective_loss 0.075824                                        LR 0.000500    Time 0.027643    
2022-06-21 17:54:30,388 - Epoch: [21][  563/  563]    objective_loss 0.076990    Top1 100.000000    LR 0.000500    Time 0.027585    
2022-06-21 17:54:30,431 - --- validate (epoch=21)-----------
2022-06-21 17:54:30,432 - 2000 samples (32 per mini-batch)
2022-06-21 17:54:32,039 - Epoch: [21][   63/   63]    Loss 0.342887    Top1 88.900000    
2022-06-21 17:54:32,082 - ==> Top1: 88.900    Loss: 0.343

2022-06-21 17:54:32,082 - ==> Confusion:
[[886  99]
 [123 892]]

2022-06-21 17:54:32,134 - ==> Best [Top1: 89.450 on epoch: 18]
2022-06-21 17:54:32,141 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:54:32,176 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:54:35,306 - Epoch: [22][  100/  563]    objective_loss 0.073741                                        LR 0.000500    Time 0.031262    
2022-06-21 17:54:38,043 - Epoch: [22][  200/  563]    objective_loss 0.071205                                        LR 0.000500    Time 0.029300    
2022-06-21 17:54:40,779 - Epoch: [22][  300/  563]    objective_loss 0.076412                                        LR 0.000500    Time 0.028640    
2022-06-21 17:54:43,515 - Epoch: [22][  400/  563]    objective_loss 0.073341                                        LR 0.000500    Time 0.028312    
2022-06-21 17:54:46,241 - Epoch: [22][  500/  563]    objective_loss 0.074144                                        LR 0.000500    Time 0.028095    
2022-06-21 17:54:47,950 - Epoch: [22][  563/  563]    objective_loss 0.076381    Top1 93.750000    LR 0.000500    Time 0.027983    
2022-06-21 17:54:47,993 - --- validate (epoch=22)-----------
2022-06-21 17:54:47,994 - 2000 samples (32 per mini-batch)
2022-06-21 17:54:49,607 - Epoch: [22][   63/   63]    Loss 0.352052    Top1 88.400000    
2022-06-21 17:54:49,651 - ==> Top1: 88.400    Loss: 0.352

2022-06-21 17:54:49,652 - ==> Confusion:
[[913  72]
 [160 855]]

2022-06-21 17:54:49,702 - ==> Best [Top1: 89.450 on epoch: 18]
2022-06-21 17:54:49,707 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:54:49,732 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:54:52,701 - Epoch: [23][  100/  563]    objective_loss 0.066568                                        LR 0.000500    Time 0.029642    
2022-06-21 17:54:55,410 - Epoch: [23][  200/  563]    objective_loss 0.071398                                        LR 0.000500    Time 0.028349    
2022-06-21 17:54:58,118 - Epoch: [23][  300/  563]    objective_loss 0.076172                                        LR 0.000500    Time 0.027912    
2022-06-21 17:55:00,866 - Epoch: [23][  400/  563]    objective_loss 0.075670                                        LR 0.000500    Time 0.027796    
2022-06-21 17:55:03,660 - Epoch: [23][  500/  563]    objective_loss 0.077446                                        LR 0.000500    Time 0.027819    
2022-06-21 17:55:05,349 - Epoch: [23][  563/  563]    objective_loss 0.076265    Top1 100.000000    LR 0.000500    Time 0.027702    
2022-06-21 17:55:05,392 - --- validate (epoch=23)-----------
2022-06-21 17:55:05,393 - 2000 samples (32 per mini-batch)
2022-06-21 17:55:06,996 - Epoch: [23][   63/   63]    Loss 0.358719    Top1 88.500000    
2022-06-21 17:55:07,039 - ==> Top1: 88.500    Loss: 0.359

2022-06-21 17:55:07,040 - ==> Confusion:
[[857 128]
 [102 913]]

2022-06-21 17:55:07,091 - ==> Best [Top1: 89.450 on epoch: 18]
2022-06-21 17:55:07,095 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:55:07,122 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:55:10,076 - Epoch: [24][  100/  563]    objective_loss 0.043816                                        LR 0.000500    Time 0.029499    
2022-06-21 17:55:12,771 - Epoch: [24][  200/  563]    objective_loss 0.053708                                        LR 0.000500    Time 0.028206    
2022-06-21 17:55:15,469 - Epoch: [24][  300/  563]    objective_loss 0.057326                                        LR 0.000500    Time 0.027784    
2022-06-21 17:55:18,174 - Epoch: [24][  400/  563]    objective_loss 0.062702                                        LR 0.000500    Time 0.027592    
2022-06-21 17:55:20,864 - Epoch: [24][  500/  563]    objective_loss 0.063190                                        LR 0.000500    Time 0.027447    
2022-06-21 17:55:22,550 - Epoch: [24][  563/  563]    objective_loss 0.064081    Top1 95.833333    LR 0.000500    Time 0.027367    
2022-06-21 17:55:22,592 - --- validate (epoch=24)-----------
2022-06-21 17:55:22,593 - 2000 samples (32 per mini-batch)
2022-06-21 17:55:24,207 - Epoch: [24][   63/   63]    Loss 0.371534    Top1 88.450000    
2022-06-21 17:55:24,250 - ==> Top1: 88.450    Loss: 0.372

2022-06-21 17:55:24,251 - ==> Confusion:
[[828 157]
 [ 74 941]]

2022-06-21 17:55:24,300 - ==> Best [Top1: 89.450 on epoch: 18]
2022-06-21 17:55:24,305 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:55:24,332 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:55:27,391 - Epoch: [25][  100/  563]    objective_loss 0.052351                                        LR 0.000250    Time 0.030545    
2022-06-21 17:55:30,103 - Epoch: [25][  200/  563]    objective_loss 0.043750                                        LR 0.000250    Time 0.028820    
2022-06-21 17:55:32,822 - Epoch: [25][  300/  563]    objective_loss 0.041512                                        LR 0.000250    Time 0.028262    
2022-06-21 17:55:35,538 - Epoch: [25][  400/  563]    objective_loss 0.041337                                        LR 0.000250    Time 0.027978    
2022-06-21 17:55:38,252 - Epoch: [25][  500/  563]    objective_loss 0.041400                                        LR 0.000250    Time 0.027804    
2022-06-21 17:55:39,964 - Epoch: [25][  563/  563]    objective_loss 0.041247    Top1 97.916667    LR 0.000250    Time 0.027729    
2022-06-21 17:55:40,006 - --- validate (epoch=25)-----------
2022-06-21 17:55:40,006 - 2000 samples (32 per mini-batch)
2022-06-21 17:55:41,616 - Epoch: [25][   63/   63]    Loss 0.374044    Top1 89.950000    
2022-06-21 17:55:41,658 - ==> Top1: 89.950    Loss: 0.374

2022-06-21 17:55:41,659 - ==> Confusion:
[[868 117]
 [ 84 931]]

2022-06-21 17:55:41,714 - ==> Best [Top1: 89.950 on epoch: 25]
2022-06-21 17:55:41,719 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:55:41,751 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:55:44,747 - Epoch: [26][  100/  563]    objective_loss 0.023938                                        LR 0.000250    Time 0.029913    
2022-06-21 17:55:47,473 - Epoch: [26][  200/  563]    objective_loss 0.024654                                        LR 0.000250    Time 0.028568    
2022-06-21 17:55:50,171 - Epoch: [26][  300/  563]    objective_loss 0.028898                                        LR 0.000250    Time 0.028028    
2022-06-21 17:55:52,872 - Epoch: [26][  400/  563]    objective_loss 0.030654                                        LR 0.000250    Time 0.027764    
2022-06-21 17:55:55,571 - Epoch: [26][  500/  563]    objective_loss 0.030384                                        LR 0.000250    Time 0.027604    
2022-06-21 17:55:57,263 - Epoch: [26][  563/  563]    objective_loss 0.029581    Top1 100.000000    LR 0.000250    Time 0.027516    
2022-06-21 17:55:57,304 - --- validate (epoch=26)-----------
2022-06-21 17:55:57,305 - 2000 samples (32 per mini-batch)
2022-06-21 17:55:58,928 - Epoch: [26][   63/   63]    Loss 0.388116    Top1 89.700000    
2022-06-21 17:55:58,970 - ==> Top1: 89.700    Loss: 0.388

2022-06-21 17:55:58,971 - ==> Confusion:
[[891  94]
 [112 903]]

2022-06-21 17:55:59,020 - ==> Best [Top1: 89.950 on epoch: 25]
2022-06-21 17:55:59,025 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:55:59,051 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:56:02,080 - Epoch: [27][  100/  563]    objective_loss 0.032739                                        LR 0.000250    Time 0.030259    
2022-06-21 17:56:04,801 - Epoch: [27][  200/  563]    objective_loss 0.028246                                        LR 0.000250    Time 0.028713    
2022-06-21 17:56:07,525 - Epoch: [27][  300/  563]    objective_loss 0.034949                                        LR 0.000250    Time 0.028209    
2022-06-21 17:56:10,249 - Epoch: [27][  400/  563]    objective_loss 0.032378                                        LR 0.000250    Time 0.027959    
2022-06-21 17:56:12,968 - Epoch: [27][  500/  563]    objective_loss 0.031282                                        LR 0.000250    Time 0.027798    
2022-06-21 17:56:14,673 - Epoch: [27][  563/  563]    objective_loss 0.031750    Top1 97.916667    LR 0.000250    Time 0.027710    
2022-06-21 17:56:14,715 - --- validate (epoch=27)-----------
2022-06-21 17:56:14,715 - 2000 samples (32 per mini-batch)
2022-06-21 17:56:16,340 - Epoch: [27][   63/   63]    Loss 0.467776    Top1 89.250000    
2022-06-21 17:56:16,383 - ==> Top1: 89.250    Loss: 0.468

2022-06-21 17:56:16,383 - ==> Confusion:
[[899  86]
 [129 886]]

2022-06-21 17:56:16,435 - ==> Best [Top1: 89.950 on epoch: 25]
2022-06-21 17:56:16,440 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-174817/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:56:16,467 - Training epoch: 18000 samples (32 per mini-batch)
2022-06-21 17:56:19,518 - Epoch: [28][  100/  563]    objective_loss 0.022319                                        LR 0.000250    Time 0.030476    
2022-06-21 17:56:22,232 - Epoch: [28][  200/  563]    objective_loss 0.022144                                        LR 0.000250    Time 0.028788    
2022-06-21 17:56:24,949 - Epoch: [28][  300/  563]    objective_loss 0.024233                                        LR 0.000250    Time 0.028237    
