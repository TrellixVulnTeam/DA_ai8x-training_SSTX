2022-06-21 17:25:13,668 - Log file for this run: /home/geffencooper/Model_Development/ai8x-training/jupyter_logging/train_log___2022.06.21-172513/train_log___2022.06.21-172513.log
2022-06-21 17:25:13,676 - dataset_name:cats_and_dogs
dataset_fn=<function cats_and_dogs_get_datasets at 0x7fcef0358820>
num_classes=2
model_name=catdognet
dimensions=(3, 128, 128)
batch_size=64
validation_split=0.1
lr=0.001500
2022-06-21 17:25:15,635 - Dataset sizes:
	training=18000
	validation=2000
	test=5000
2022-06-21 17:25:15,635 - Augmentations:Compose(
    Resize(size=(128, 128), interpolation=bilinear)
    RandomHorizontalFlip(p=0.5)
    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 5))
    ToTensor()
    <ai8x.normalize object at 0x7fcee03e56d0>
)
2022-06-21 17:25:19,839 - epochs: 30
2022-06-21 17:25:19,841 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-06-21 17:25:19,842 - lr_schedule:base: [0.0015] milestones: Counter({5: 1, 25: 1}) gamma: 0.5
2022-06-21 17:25:19,842 - qat policy: {'start_epoch': 5, 'weight_bits': 8}
2022-06-21 17:25:23,275 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:25:27,669 - Epoch: [0][  100/  282]    objective_loss 0.627893                                        LR 0.001500    Time 0.043904    
2022-06-21 17:25:31,798 - Epoch: [0][  200/  282]    objective_loss 0.593901                                        LR 0.001500    Time 0.042577    
2022-06-21 17:25:35,173 - Epoch: [0][  282/  282]    objective_loss 0.570501    Top1 78.750000    LR 0.001500    Time 0.042153    
2022-06-21 17:25:35,213 - --- validate (epoch=0)-----------
2022-06-21 17:25:35,214 - 2000 samples (64 per mini-batch)
2022-06-21 17:25:36,731 - Epoch: [0][   32/   32]    Loss 0.626459    Top1 66.200000    
2022-06-21 17:25:36,772 - ==> Top1: 66.200    Loss: 0.626

2022-06-21 17:25:36,773 - ==> Confusion:
[[359 626]
 [ 50 965]]

2022-06-21 17:25:36,830 - ==> Best [Top1: 66.200 on epoch: 0]
2022-06-21 17:25:36,836 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_checkpoint.pth.tar
2022-06-21 17:25:36,861 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:25:41,427 - Epoch: [1][  100/  282]    objective_loss 0.489315                                        LR 0.001500    Time 0.045609    
2022-06-21 17:25:45,590 - Epoch: [1][  200/  282]    objective_loss 0.459987                                        LR 0.001500    Time 0.043597    
2022-06-21 17:25:48,955 - Epoch: [1][  282/  282]    objective_loss 0.450175    Top1 87.500000    LR 0.001500    Time 0.042843    
2022-06-21 17:25:48,996 - --- validate (epoch=1)-----------
2022-06-21 17:25:48,996 - 2000 samples (64 per mini-batch)
2022-06-21 17:25:50,539 - Epoch: [1][   32/   32]    Loss 0.441044    Top1 79.100000    
2022-06-21 17:25:50,579 - ==> Top1: 79.100    Loss: 0.441

2022-06-21 17:25:50,580 - ==> Confusion:
[[771 214]
 [204 811]]

2022-06-21 17:25:50,629 - ==> Best [Top1: 79.100 on epoch: 1]
2022-06-21 17:25:50,634 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_checkpoint.pth.tar
2022-06-21 17:25:50,663 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:25:55,101 - Epoch: [2][  100/  282]    objective_loss 0.380584                                        LR 0.001500    Time 0.044328    
2022-06-21 17:25:59,284 - Epoch: [2][  200/  282]    objective_loss 0.366396                                        LR 0.001500    Time 0.043059    
2022-06-21 17:26:02,699 - Epoch: [2][  282/  282]    objective_loss 0.361813    Top1 86.250000    LR 0.001500    Time 0.042638    
2022-06-21 17:26:02,740 - --- validate (epoch=2)-----------
2022-06-21 17:26:02,740 - 2000 samples (64 per mini-batch)
2022-06-21 17:26:04,266 - Epoch: [2][   32/   32]    Loss 0.620469    Top1 70.000000    
2022-06-21 17:26:04,306 - ==> Top1: 70.000    Loss: 0.620

2022-06-21 17:26:04,307 - ==> Confusion:
[[967  18]
 [582 433]]

2022-06-21 17:26:04,357 - ==> Best [Top1: 79.100 on epoch: 1]
2022-06-21 17:26:04,362 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_checkpoint.pth.tar
2022-06-21 17:26:04,381 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:26:08,814 - Epoch: [3][  100/  282]    objective_loss 0.312141                                        LR 0.001500    Time 0.044282    
2022-06-21 17:26:13,012 - Epoch: [3][  200/  282]    objective_loss 0.322624                                        LR 0.001500    Time 0.043110    
2022-06-21 17:26:16,434 - Epoch: [3][  282/  282]    objective_loss 0.315856    Top1 87.500000    LR 0.001500    Time 0.042702    
2022-06-21 17:26:16,475 - --- validate (epoch=3)-----------
2022-06-21 17:26:16,475 - 2000 samples (64 per mini-batch)
2022-06-21 17:26:17,972 - Epoch: [3][   32/   32]    Loss 0.348057    Top1 84.700000    
2022-06-21 17:26:18,012 - ==> Top1: 84.700    Loss: 0.348

2022-06-21 17:26:18,014 - ==> Confusion:
[[771 214]
 [ 92 923]]

2022-06-21 17:26:18,067 - ==> Best [Top1: 84.700 on epoch: 3]
2022-06-21 17:26:18,073 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_checkpoint.pth.tar
2022-06-21 17:26:18,106 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:26:22,523 - Epoch: [4][  100/  282]    objective_loss 0.281982                                        LR 0.001500    Time 0.044135    
2022-06-21 17:26:26,673 - Epoch: [4][  200/  282]    objective_loss 0.282691                                        LR 0.001500    Time 0.042796    
2022-06-21 17:26:30,089 - Epoch: [4][  282/  282]    objective_loss 0.278887    Top1 92.500000    LR 0.001500    Time 0.042456    
2022-06-21 17:26:30,130 - --- validate (epoch=4)-----------
2022-06-21 17:26:30,131 - 2000 samples (64 per mini-batch)
2022-06-21 17:26:31,638 - Epoch: [4][   32/   32]    Loss 0.400164    Top1 82.200000    
2022-06-21 17:26:31,678 - ==> Top1: 82.200    Loss: 0.400

2022-06-21 17:26:31,679 - ==> Confusion:
[[942  43]
 [313 702]]

2022-06-21 17:26:31,733 - ==> Best [Top1: 84.700 on epoch: 3]
2022-06-21 17:26:31,740 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_checkpoint.pth.tar
2022-06-21 17:26:31,793 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:26:36,398 - Epoch: [5][  100/  282]    objective_loss 0.740468                                        LR 0.001500    Time 0.046011    
2022-06-21 17:26:40,596 - Epoch: [5][  200/  282]    objective_loss 0.717431                                        LR 0.001500    Time 0.043976    
2022-06-21 17:26:44,019 - Epoch: [5][  282/  282]    objective_loss 0.710579    Top1 53.750000    LR 0.001500    Time 0.043318    
2022-06-21 17:26:44,060 - --- validate (epoch=5)-----------
2022-06-21 17:26:44,060 - 2000 samples (64 per mini-batch)
2022-06-21 17:26:45,622 - Epoch: [5][   32/   32]    Loss 0.692995    Top1 50.750000    
2022-06-21 17:26:45,663 - ==> Top1: 50.750    Loss: 0.693

2022-06-21 17:26:45,664 - ==> Confusion:
[[   0  985]
 [   0 1015]]

2022-06-21 17:26:45,714 - ==> Best [Top1: 50.750 on epoch: 5]
2022-06-21 17:26:45,719 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:26:45,738 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:26:50,259 - Epoch: [6][  100/  282]    objective_loss 0.693750                                        LR 0.001500    Time 0.045176    
2022-06-21 17:26:54,471 - Epoch: [6][  200/  282]    objective_loss 0.693948                                        LR 0.001500    Time 0.043624    
2022-06-21 17:26:57,890 - Epoch: [6][  282/  282]    objective_loss 0.693887    Top1 56.250000    LR 0.001500    Time 0.043053    
2022-06-21 17:26:57,931 - --- validate (epoch=6)-----------
2022-06-21 17:26:57,932 - 2000 samples (64 per mini-batch)
2022-06-21 17:26:59,482 - Epoch: [6][   32/   32]    Loss 0.693422    Top1 49.250000    
2022-06-21 17:26:59,522 - ==> Top1: 49.250    Loss: 0.693

2022-06-21 17:26:59,523 - ==> Confusion:
[[ 985    0]
 [1015    0]]

2022-06-21 17:26:59,573 - ==> Best [Top1: 50.750 on epoch: 5]
2022-06-21 17:26:59,578 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:26:59,596 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:27:04,079 - Epoch: [7][  100/  282]    objective_loss 0.693409                                        LR 0.001500    Time 0.044789    
2022-06-21 17:27:08,271 - Epoch: [7][  200/  282]    objective_loss 0.693369                                        LR 0.001500    Time 0.043335    
2022-06-21 17:27:11,668 - Epoch: [7][  282/  282]    objective_loss 0.693421    Top1 45.000000    LR 0.001500    Time 0.042767    
2022-06-21 17:27:11,709 - --- validate (epoch=7)-----------
2022-06-21 17:27:11,709 - 2000 samples (64 per mini-batch)
2022-06-21 17:27:13,264 - Epoch: [7][   32/   32]    Loss 0.693147    Top1 49.250000    
2022-06-21 17:27:13,304 - ==> Top1: 49.250    Loss: 0.693

2022-06-21 17:27:13,305 - ==> Confusion:
[[ 985    0]
 [1015    0]]

2022-06-21 17:27:13,358 - ==> Best [Top1: 50.750 on epoch: 5]
2022-06-21 17:27:13,364 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:27:13,394 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:27:17,856 - Epoch: [8][  100/  282]    objective_loss 0.693659                                        LR 0.001500    Time 0.044569    
2022-06-21 17:27:22,036 - Epoch: [8][  200/  282]    objective_loss 0.693477                                        LR 0.001500    Time 0.043162    
2022-06-21 17:27:25,424 - Epoch: [8][  282/  282]    objective_loss 0.693429    Top1 40.000000    LR 0.001500    Time 0.042616    
2022-06-21 17:27:25,466 - --- validate (epoch=8)-----------
2022-06-21 17:27:25,467 - 2000 samples (64 per mini-batch)
2022-06-21 17:27:27,034 - Epoch: [8][   32/   32]    Loss 0.693120    Top1 50.750000    
2022-06-21 17:27:27,076 - ==> Top1: 50.750    Loss: 0.693

2022-06-21 17:27:27,077 - ==> Confusion:
[[   0  985]
 [   0 1015]]

2022-06-21 17:27:27,118 - ==> Best [Top1: 50.750 on epoch: 8]
2022-06-21 17:27:27,121 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:27:27,145 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:27:31,669 - Epoch: [9][  100/  282]    objective_loss 0.693479                                        LR 0.001500    Time 0.045199    
2022-06-21 17:27:35,943 - Epoch: [9][  200/  282]    objective_loss 0.693492                                        LR 0.001500    Time 0.043946    
2022-06-21 17:27:39,401 - Epoch: [9][  282/  282]    objective_loss 0.693517    Top1 52.500000    LR 0.001500    Time 0.043418    
2022-06-21 17:27:39,442 - --- validate (epoch=9)-----------
2022-06-21 17:27:39,442 - 2000 samples (64 per mini-batch)
2022-06-21 17:27:40,990 - Epoch: [9][   32/   32]    Loss 0.693075    Top1 50.750000    
2022-06-21 17:27:41,030 - ==> Top1: 50.750    Loss: 0.693

2022-06-21 17:27:41,031 - ==> Confusion:
[[   0  985]
 [   0 1015]]

2022-06-21 17:27:41,085 - ==> Best [Top1: 50.750 on epoch: 9]
2022-06-21 17:27:41,091 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:27:41,122 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:27:45,733 - Epoch: [10][  100/  282]    objective_loss 0.693505                                        LR 0.001500    Time 0.046070    
2022-06-21 17:27:49,957 - Epoch: [10][  200/  282]    objective_loss 0.693489                                        LR 0.001500    Time 0.044135    
2022-06-21 17:27:53,381 - Epoch: [10][  282/  282]    objective_loss 0.693491    Top1 52.500000    LR 0.001500    Time 0.043435    
2022-06-21 17:27:53,422 - --- validate (epoch=10)-----------
2022-06-21 17:27:53,423 - 2000 samples (64 per mini-batch)
2022-06-21 17:27:54,985 - Epoch: [10][   32/   32]    Loss 0.693567    Top1 49.250000    
2022-06-21 17:27:55,026 - ==> Top1: 49.250    Loss: 0.694

2022-06-21 17:27:55,027 - ==> Confusion:
[[ 985    0]
 [1015    0]]

2022-06-21 17:27:55,082 - ==> Best [Top1: 50.750 on epoch: 9]
2022-06-21 17:27:55,088 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:27:55,116 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:27:59,596 - Epoch: [11][  100/  282]    objective_loss 0.693702                                        LR 0.001500    Time 0.044753    
2022-06-21 17:28:03,790 - Epoch: [11][  200/  282]    objective_loss 0.693727                                        LR 0.001500    Time 0.043324    
2022-06-21 17:28:07,216 - Epoch: [11][  282/  282]    objective_loss 0.693880    Top1 45.000000    LR 0.001500    Time 0.042865    
2022-06-21 17:28:07,259 - --- validate (epoch=11)-----------
2022-06-21 17:28:07,260 - 2000 samples (64 per mini-batch)
2022-06-21 17:28:08,817 - Epoch: [11][   32/   32]    Loss 0.693216    Top1 50.750000    
2022-06-21 17:28:08,858 - ==> Top1: 50.750    Loss: 0.693

2022-06-21 17:28:08,858 - ==> Confusion:
[[   0  985]
 [   0 1015]]

2022-06-21 17:28:08,908 - ==> Best [Top1: 50.750 on epoch: 11]
2022-06-21 17:28:08,913 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:28:08,942 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:28:13,402 - Epoch: [12][  100/  282]    objective_loss 0.693362                                        LR 0.001500    Time 0.044562    
2022-06-21 17:28:17,625 - Epoch: [12][  200/  282]    objective_loss 0.693444                                        LR 0.001500    Time 0.043375    
2022-06-21 17:28:21,041 - Epoch: [12][  282/  282]    objective_loss 0.693418    Top1 55.000000    LR 0.001500    Time 0.042865    
2022-06-21 17:28:21,082 - --- validate (epoch=12)-----------
2022-06-21 17:28:21,082 - 2000 samples (64 per mini-batch)
2022-06-21 17:28:22,619 - Epoch: [12][   32/   32]    Loss 0.693624    Top1 49.250000    
2022-06-21 17:28:22,671 - ==> Top1: 49.250    Loss: 0.694

2022-06-21 17:28:22,672 - ==> Confusion:
[[ 985    0]
 [1015    0]]

2022-06-21 17:28:22,721 - ==> Best [Top1: 50.750 on epoch: 11]
2022-06-21 17:28:22,726 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:28:22,753 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:28:27,266 - Epoch: [13][  100/  282]    objective_loss 0.693187                                        LR 0.001500    Time 0.045088    
2022-06-21 17:28:31,535 - Epoch: [13][  200/  282]    objective_loss 0.693419                                        LR 0.001500    Time 0.043868    
2022-06-21 17:28:34,970 - Epoch: [13][  282/  282]    objective_loss 0.693412    Top1 53.750000    LR 0.001500    Time 0.043281    
2022-06-21 17:28:35,010 - --- validate (epoch=13)-----------
2022-06-21 17:28:35,011 - 2000 samples (64 per mini-batch)
2022-06-21 17:28:36,558 - Epoch: [13][   32/   32]    Loss 0.694276    Top1 49.250000    
2022-06-21 17:28:36,599 - ==> Top1: 49.250    Loss: 0.694

2022-06-21 17:28:36,600 - ==> Confusion:
[[ 985    0]
 [1015    0]]

2022-06-21 17:28:36,646 - ==> Best [Top1: 50.750 on epoch: 11]
2022-06-21 17:28:36,651 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:28:36,679 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:28:41,118 - Epoch: [14][  100/  282]    objective_loss 0.693519                                        LR 0.001500    Time 0.044342    
2022-06-21 17:28:45,325 - Epoch: [14][  200/  282]    objective_loss 0.693574                                        LR 0.001500    Time 0.043186    
2022-06-21 17:28:48,752 - Epoch: [14][  282/  282]    objective_loss 0.693607    Top1 53.750000    LR 0.001500    Time 0.042771    
2022-06-21 17:28:48,793 - --- validate (epoch=14)-----------
2022-06-21 17:28:48,794 - 2000 samples (64 per mini-batch)
2022-06-21 17:28:50,350 - Epoch: [14][   32/   32]    Loss 0.693796    Top1 49.250000    
2022-06-21 17:28:50,392 - ==> Top1: 49.250    Loss: 0.694

2022-06-21 17:28:50,393 - ==> Confusion:
[[ 985    0]
 [1015    0]]

2022-06-21 17:28:50,434 - ==> Best [Top1: 50.750 on epoch: 11]
2022-06-21 17:28:50,437 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:28:50,451 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:28:55,126 - Epoch: [15][  100/  282]    objective_loss 0.693536                                        LR 0.001500    Time 0.046709    
2022-06-21 17:28:59,415 - Epoch: [15][  200/  282]    objective_loss 0.693600                                        LR 0.001500    Time 0.044780    
2022-06-21 17:29:02,842 - Epoch: [15][  282/  282]    objective_loss 0.693563    Top1 51.250000    LR 0.001500    Time 0.043901    
2022-06-21 17:29:02,882 - --- validate (epoch=15)-----------
2022-06-21 17:29:02,883 - 2000 samples (64 per mini-batch)
2022-06-21 17:29:04,444 - Epoch: [15][   32/   32]    Loss 0.693235    Top1 49.250000    
2022-06-21 17:29:04,485 - ==> Top1: 49.250    Loss: 0.693

2022-06-21 17:29:04,486 - ==> Confusion:
[[ 985    0]
 [1015    0]]

2022-06-21 17:29:04,537 - ==> Best [Top1: 50.750 on epoch: 11]
2022-06-21 17:29:04,542 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172513/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:29:04,560 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:29:09,128 - Epoch: [16][  100/  282]    objective_loss 0.693292                                        LR 0.001500    Time 0.045641    
2022-06-21 17:29:13,364 - Epoch: [16][  200/  282]    objective_loss 0.693160                                        LR 0.001500    Time 0.043981    
