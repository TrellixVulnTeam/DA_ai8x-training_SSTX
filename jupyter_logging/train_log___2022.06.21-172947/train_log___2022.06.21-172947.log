2022-06-21 17:29:47,575 - Log file for this run: /home/geffencooper/Model_Development/ai8x-training/jupyter_logging/train_log___2022.06.21-172947/train_log___2022.06.21-172947.log
2022-06-21 17:29:47,576 - dataset_name:cats_and_dogs
dataset_fn=<function cats_and_dogs_get_datasets at 0x7fcef0358820>
num_classes=2
model_name=catdognet
dimensions=(3, 128, 128)
batch_size=64
validation_split=0.1
lr=0.001000
2022-06-21 17:29:49,413 - Dataset sizes:
	training=18000
	validation=2000
	test=5000
2022-06-21 17:29:49,413 - Augmentations:Compose(
    Resize(size=(128, 128), interpolation=bilinear)
    RandomHorizontalFlip(p=0.5)
    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 5))
    ToTensor()
    <ai8x.normalize object at 0x7fcec5ee8a00>
)
2022-06-21 17:29:52,795 - epochs: 30
2022-06-21 17:29:52,797 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-06-21 17:29:52,798 - lr_schedule:base: [0.001] milestones: Counter({5: 1, 25: 1}) gamma: 0.5
2022-06-21 17:29:52,798 - qat policy: {'start_epoch': 5, 'weight_bits': 8}
2022-06-21 17:29:56,738 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:30:01,312 - Epoch: [0][  100/  282]    objective_loss 0.632911                                        LR 0.001000    Time 0.045709    
2022-06-21 17:30:05,515 - Epoch: [0][  200/  282]    objective_loss 0.596877                                        LR 0.001000    Time 0.043845    
2022-06-21 17:30:08,959 - Epoch: [0][  282/  282]    objective_loss 0.569078    Top1 87.500000    LR 0.001000    Time 0.043300    
2022-06-21 17:30:09,000 - --- validate (epoch=0)-----------
2022-06-21 17:30:09,001 - 2000 samples (64 per mini-batch)
2022-06-21 17:30:10,525 - Epoch: [0][   32/   32]    Loss 0.629831    Top1 66.500000    
2022-06-21 17:30:10,566 - ==> Top1: 66.500    Loss: 0.630

2022-06-21 17:30:10,567 - ==> Confusion:
[[355 630]
 [ 40 975]]

2022-06-21 17:30:10,617 - ==> Best [Top1: 66.500 on epoch: 0]
2022-06-21 17:30:10,623 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_checkpoint.pth.tar
2022-06-21 17:30:10,644 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:30:15,114 - Epoch: [1][  100/  282]    objective_loss 0.466794                                        LR 0.001000    Time 0.044647    
2022-06-21 17:30:19,344 - Epoch: [1][  200/  282]    objective_loss 0.448285                                        LR 0.001000    Time 0.043447    
2022-06-21 17:30:22,762 - Epoch: [1][  282/  282]    objective_loss 0.442824    Top1 80.000000    LR 0.001000    Time 0.042924    
2022-06-21 17:30:22,803 - --- validate (epoch=1)-----------
2022-06-21 17:30:22,804 - 2000 samples (64 per mini-batch)
2022-06-21 17:30:24,327 - Epoch: [1][   32/   32]    Loss 0.420740    Top1 80.050000    
2022-06-21 17:30:24,377 - ==> Top1: 80.050    Loss: 0.421

2022-06-21 17:30:24,378 - ==> Confusion:
[[774 211]
 [188 827]]

2022-06-21 17:30:24,428 - ==> Best [Top1: 80.050 on epoch: 1]
2022-06-21 17:30:24,434 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_checkpoint.pth.tar
2022-06-21 17:30:24,464 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:30:28,858 - Epoch: [2][  100/  282]    objective_loss 0.382359                                        LR 0.001000    Time 0.043895    
2022-06-21 17:30:33,040 - Epoch: [2][  200/  282]    objective_loss 0.378205                                        LR 0.001000    Time 0.042833    
2022-06-21 17:30:36,421 - Epoch: [2][  282/  282]    objective_loss 0.371088    Top1 85.000000    LR 0.001000    Time 0.042357    
2022-06-21 17:30:36,462 - --- validate (epoch=2)-----------
2022-06-21 17:30:36,462 - 2000 samples (64 per mini-batch)
2022-06-21 17:30:37,992 - Epoch: [2][   32/   32]    Loss 0.438196    Top1 79.600000    
2022-06-21 17:30:38,033 - ==> Top1: 79.600    Loss: 0.438

2022-06-21 17:30:38,034 - ==> Confusion:
[[910  75]
 [333 682]]

2022-06-21 17:30:38,083 - ==> Best [Top1: 80.050 on epoch: 1]
2022-06-21 17:30:38,088 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_checkpoint.pth.tar
2022-06-21 17:30:38,115 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:30:42,513 - Epoch: [3][  100/  282]    objective_loss 0.329519                                        LR 0.001000    Time 0.043929    
2022-06-21 17:30:46,679 - Epoch: [3][  200/  282]    objective_loss 0.334033                                        LR 0.001000    Time 0.042777    
2022-06-21 17:30:50,062 - Epoch: [3][  282/  282]    objective_loss 0.330165    Top1 88.750000    LR 0.001000    Time 0.042321    
2022-06-21 17:30:50,104 - --- validate (epoch=3)-----------
2022-06-21 17:30:50,104 - 2000 samples (64 per mini-batch)
2022-06-21 17:30:51,614 - Epoch: [3][   32/   32]    Loss 0.363784    Top1 83.950000    
2022-06-21 17:30:51,655 - ==> Top1: 83.950    Loss: 0.364

2022-06-21 17:30:51,656 - ==> Confusion:
[[790 195]
 [126 889]]

2022-06-21 17:30:51,708 - ==> Best [Top1: 83.950 on epoch: 3]
2022-06-21 17:30:51,714 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_checkpoint.pth.tar
2022-06-21 17:30:51,746 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:30:56,169 - Epoch: [4][  100/  282]    objective_loss 0.289800                                        LR 0.001000    Time 0.044185    
2022-06-21 17:31:00,471 - Epoch: [4][  200/  282]    objective_loss 0.289795                                        LR 0.001000    Time 0.043582    
2022-06-21 17:31:03,917 - Epoch: [4][  282/  282]    objective_loss 0.284693    Top1 90.000000    LR 0.001000    Time 0.043117    
2022-06-21 17:31:03,958 - --- validate (epoch=4)-----------
2022-06-21 17:31:03,959 - 2000 samples (64 per mini-batch)
2022-06-21 17:31:05,476 - Epoch: [4][   32/   32]    Loss 0.349745    Top1 85.200000    
2022-06-21 17:31:05,517 - ==> Top1: 85.200    Loss: 0.350

2022-06-21 17:31:05,517 - ==> Confusion:
[[895  90]
 [206 809]]

2022-06-21 17:31:05,569 - ==> Best [Top1: 85.200 on epoch: 4]
2022-06-21 17:31:05,574 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_checkpoint.pth.tar
2022-06-21 17:31:05,627 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:31:10,143 - Epoch: [5][  100/  282]    objective_loss 0.657222                                        LR 0.001000    Time 0.045118    
2022-06-21 17:31:14,369 - Epoch: [5][  200/  282]    objective_loss 0.588339                                        LR 0.001000    Time 0.043670    
2022-06-21 17:31:17,786 - Epoch: [5][  282/  282]    objective_loss 0.550726    Top1 83.750000    LR 0.001000    Time 0.043077    
2022-06-21 17:31:17,829 - --- validate (epoch=5)-----------
2022-06-21 17:31:17,830 - 2000 samples (64 per mini-batch)
2022-06-21 17:31:19,383 - Epoch: [5][   32/   32]    Loss 0.487988    Top1 76.250000    
2022-06-21 17:31:19,424 - ==> Top1: 76.250    Loss: 0.488

2022-06-21 17:31:19,425 - ==> Confusion:
[[580 405]
 [ 70 945]]

2022-06-21 17:31:19,475 - ==> Best [Top1: 76.250 on epoch: 5]
2022-06-21 17:31:19,480 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:31:19,500 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:31:24,106 - Epoch: [6][  100/  282]    objective_loss 0.423157                                        LR 0.001000    Time 0.046023    
2022-06-21 17:31:28,305 - Epoch: [6][  200/  282]    objective_loss 0.411998                                        LR 0.001000    Time 0.043985    
2022-06-21 17:31:31,742 - Epoch: [6][  282/  282]    objective_loss 0.404095    Top1 92.500000    LR 0.001000    Time 0.043375    
2022-06-21 17:31:31,784 - --- validate (epoch=6)-----------
2022-06-21 17:31:31,785 - 2000 samples (64 per mini-batch)
2022-06-21 17:31:33,356 - Epoch: [6][   32/   32]    Loss 0.393598    Top1 81.800000    
2022-06-21 17:31:33,397 - ==> Top1: 81.800    Loss: 0.394

2022-06-21 17:31:33,398 - ==> Confusion:
[[861 124]
 [240 775]]

2022-06-21 17:31:33,448 - ==> Best [Top1: 81.800 on epoch: 6]
2022-06-21 17:31:33,454 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:31:33,482 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:31:38,020 - Epoch: [7][  100/  282]    objective_loss 0.334517                                        LR 0.001000    Time 0.045339    
2022-06-21 17:31:42,279 - Epoch: [7][  200/  282]    objective_loss 0.338456                                        LR 0.001000    Time 0.043941    
2022-06-21 17:31:45,727 - Epoch: [7][  282/  282]    objective_loss 0.337220    Top1 92.500000    LR 0.001000    Time 0.043380    
2022-06-21 17:31:45,769 - --- validate (epoch=7)-----------
2022-06-21 17:31:45,770 - 2000 samples (64 per mini-batch)
2022-06-21 17:31:47,348 - Epoch: [7][   32/   32]    Loss 0.379651    Top1 83.200000    
2022-06-21 17:31:47,389 - ==> Top1: 83.200    Loss: 0.380

2022-06-21 17:31:47,390 - ==> Confusion:
[[773 212]
 [124 891]]

2022-06-21 17:31:47,440 - ==> Best [Top1: 83.200 on epoch: 7]
2022-06-21 17:31:47,446 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:31:47,468 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:31:51,944 - Epoch: [8][  100/  282]    objective_loss 0.324468                                        LR 0.001000    Time 0.044727    
2022-06-21 17:31:56,152 - Epoch: [8][  200/  282]    objective_loss 0.321064                                        LR 0.001000    Time 0.043377    
2022-06-21 17:31:59,573 - Epoch: [8][  282/  282]    objective_loss 0.313646    Top1 90.000000    LR 0.001000    Time 0.042887    
2022-06-21 17:31:59,615 - --- validate (epoch=8)-----------
2022-06-21 17:31:59,615 - 2000 samples (64 per mini-batch)
2022-06-21 17:32:01,206 - Epoch: [8][   32/   32]    Loss 0.350955    Top1 85.900000    
2022-06-21 17:32:01,249 - ==> Top1: 85.900    Loss: 0.351

2022-06-21 17:32:01,250 - ==> Confusion:
[[917  68]
 [214 801]]

2022-06-21 17:32:01,300 - ==> Best [Top1: 85.900 on epoch: 8]
2022-06-21 17:32:01,305 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:32:01,333 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:32:05,895 - Epoch: [9][  100/  282]    objective_loss 0.288109                                        LR 0.001000    Time 0.045580    
2022-06-21 17:32:10,175 - Epoch: [9][  200/  282]    objective_loss 0.283809                                        LR 0.001000    Time 0.044169    
2022-06-21 17:32:13,605 - Epoch: [9][  282/  282]    objective_loss 0.282013    Top1 91.250000    LR 0.001000    Time 0.043478    
2022-06-21 17:32:13,646 - --- validate (epoch=9)-----------
2022-06-21 17:32:13,647 - 2000 samples (64 per mini-batch)
2022-06-21 17:32:15,197 - Epoch: [9][   32/   32]    Loss 0.329491    Top1 85.200000    
2022-06-21 17:32:15,238 - ==> Top1: 85.200    Loss: 0.329

2022-06-21 17:32:15,239 - ==> Confusion:
[[778 207]
 [ 89 926]]

2022-06-21 17:32:15,289 - ==> Best [Top1: 85.900 on epoch: 8]
2022-06-21 17:32:15,295 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:32:15,322 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:32:19,844 - Epoch: [10][  100/  282]    objective_loss 0.260602                                        LR 0.001000    Time 0.045173    
2022-06-21 17:32:24,080 - Epoch: [10][  200/  282]    objective_loss 0.256374                                        LR 0.001000    Time 0.043750    
2022-06-21 17:32:27,508 - Epoch: [10][  282/  282]    objective_loss 0.261186    Top1 90.000000    LR 0.001000    Time 0.043171    
2022-06-21 17:32:27,552 - --- validate (epoch=10)-----------
2022-06-21 17:32:27,553 - 2000 samples (64 per mini-batch)
2022-06-21 17:32:29,122 - Epoch: [10][   32/   32]    Loss 0.335333    Top1 85.400000    
2022-06-21 17:32:29,163 - ==> Top1: 85.400    Loss: 0.335

2022-06-21 17:32:29,164 - ==> Confusion:
[[890  95]
 [197 818]]

2022-06-21 17:32:29,217 - ==> Best [Top1: 85.900 on epoch: 8]
2022-06-21 17:32:29,224 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:32:29,253 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:32:33,720 - Epoch: [11][  100/  282]    objective_loss 0.259176                                        LR 0.001000    Time 0.044623    
2022-06-21 17:32:37,918 - Epoch: [11][  200/  282]    objective_loss 0.255745                                        LR 0.001000    Time 0.043282    
2022-06-21 17:32:41,348 - Epoch: [11][  282/  282]    objective_loss 0.252273    Top1 93.750000    LR 0.001000    Time 0.042849    
2022-06-21 17:32:41,390 - --- validate (epoch=11)-----------
2022-06-21 17:32:41,390 - 2000 samples (64 per mini-batch)
2022-06-21 17:32:42,948 - Epoch: [11][   32/   32]    Loss 0.288215    Top1 88.200000    
2022-06-21 17:32:42,990 - ==> Top1: 88.200    Loss: 0.288

2022-06-21 17:32:42,991 - ==> Confusion:
[[879 106]
 [130 885]]

2022-06-21 17:32:43,039 - ==> Best [Top1: 88.200 on epoch: 11]
2022-06-21 17:32:43,045 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:32:43,073 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:32:47,587 - Epoch: [12][  100/  282]    objective_loss 0.218132                                        LR 0.001000    Time 0.045101    
2022-06-21 17:32:51,868 - Epoch: [12][  200/  282]    objective_loss 0.231008                                        LR 0.001000    Time 0.043932    
2022-06-21 17:32:55,342 - Epoch: [12][  282/  282]    objective_loss 0.230977    Top1 92.500000    LR 0.001000    Time 0.043467    
2022-06-21 17:32:55,384 - --- validate (epoch=12)-----------
2022-06-21 17:32:55,385 - 2000 samples (64 per mini-batch)
2022-06-21 17:32:57,030 - Epoch: [12][   32/   32]    Loss 0.306389    Top1 87.150000    
2022-06-21 17:32:57,071 - ==> Top1: 87.150    Loss: 0.306

2022-06-21 17:32:57,072 - ==> Confusion:
[[891  94]
 [163 852]]

2022-06-21 17:32:57,121 - ==> Best [Top1: 88.200 on epoch: 11]
2022-06-21 17:32:57,128 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:32:57,156 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:33:01,642 - Epoch: [13][  100/  282]    objective_loss 0.221584                                        LR 0.001000    Time 0.044817    
2022-06-21 17:33:05,866 - Epoch: [13][  200/  282]    objective_loss 0.219226                                        LR 0.001000    Time 0.043504    
2022-06-21 17:33:09,281 - Epoch: [13][  282/  282]    objective_loss 0.225086    Top1 88.750000    LR 0.001000    Time 0.042953    
2022-06-21 17:33:09,323 - --- validate (epoch=13)-----------
2022-06-21 17:33:09,324 - 2000 samples (64 per mini-batch)
2022-06-21 17:33:10,902 - Epoch: [13][   32/   32]    Loss 0.276755    Top1 88.150000    
2022-06-21 17:33:10,944 - ==> Top1: 88.150    Loss: 0.277

2022-06-21 17:33:10,945 - ==> Confusion:
[[878 107]
 [130 885]]

2022-06-21 17:33:10,984 - ==> Best [Top1: 88.200 on epoch: 11]
2022-06-21 17:33:10,987 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:33:11,000 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:33:15,630 - Epoch: [14][  100/  282]    objective_loss 0.218495                                        LR 0.001000    Time 0.046261    
2022-06-21 17:33:19,850 - Epoch: [14][  200/  282]    objective_loss 0.211768                                        LR 0.001000    Time 0.044210    
2022-06-21 17:33:23,266 - Epoch: [14][  282/  282]    objective_loss 0.211482    Top1 86.250000    LR 0.001000    Time 0.043457    
2022-06-21 17:33:23,307 - --- validate (epoch=14)-----------
2022-06-21 17:33:23,308 - 2000 samples (64 per mini-batch)
2022-06-21 17:33:24,891 - Epoch: [14][   32/   32]    Loss 0.294664    Top1 88.250000    
2022-06-21 17:33:24,932 - ==> Top1: 88.250    Loss: 0.295

2022-06-21 17:33:24,933 - ==> Confusion:
[[894  91]
 [144 871]]

2022-06-21 17:33:24,987 - ==> Best [Top1: 88.250 on epoch: 14]
2022-06-21 17:33:24,993 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:33:25,024 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:33:29,542 - Epoch: [15][  100/  282]    objective_loss 0.208336                                        LR 0.001000    Time 0.045131    
2022-06-21 17:33:33,759 - Epoch: [15][  200/  282]    objective_loss 0.203666                                        LR 0.001000    Time 0.043631    
2022-06-21 17:33:37,195 - Epoch: [15][  282/  282]    objective_loss 0.204692    Top1 82.500000    LR 0.001000    Time 0.043115    
2022-06-21 17:33:37,237 - --- validate (epoch=15)-----------
2022-06-21 17:33:37,238 - 2000 samples (64 per mini-batch)
2022-06-21 17:33:38,792 - Epoch: [15][   32/   32]    Loss 0.272141    Top1 88.400000    
2022-06-21 17:33:38,834 - ==> Top1: 88.400    Loss: 0.272

2022-06-21 17:33:38,835 - ==> Confusion:
[[890  95]
 [137 878]]

2022-06-21 17:33:38,874 - ==> Best [Top1: 88.400 on epoch: 15]
2022-06-21 17:33:38,877 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:33:38,906 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:33:43,422 - Epoch: [16][  100/  282]    objective_loss 0.186076                                        LR 0.001000    Time 0.045110    
2022-06-21 17:33:47,680 - Epoch: [16][  200/  282]    objective_loss 0.195449                                        LR 0.001000    Time 0.043826    
2022-06-21 17:33:51,112 - Epoch: [16][  282/  282]    objective_loss 0.193331    Top1 93.750000    LR 0.001000    Time 0.043241    
2022-06-21 17:33:51,153 - --- validate (epoch=16)-----------
2022-06-21 17:33:51,154 - 2000 samples (64 per mini-batch)
2022-06-21 17:33:52,717 - Epoch: [16][   32/   32]    Loss 0.275491    Top1 88.300000    
2022-06-21 17:33:52,769 - ==> Top1: 88.300    Loss: 0.275

2022-06-21 17:33:52,769 - ==> Confusion:
[[898  87]
 [147 868]]

2022-06-21 17:33:52,820 - ==> Best [Top1: 88.400 on epoch: 15]
2022-06-21 17:33:52,826 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:33:52,852 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:33:57,400 - Epoch: [17][  100/  282]    objective_loss 0.175371                                        LR 0.001000    Time 0.045428    
2022-06-21 17:34:01,614 - Epoch: [17][  200/  282]    objective_loss 0.181300                                        LR 0.001000    Time 0.043762    
2022-06-21 17:34:05,023 - Epoch: [17][  282/  282]    objective_loss 0.184974    Top1 91.250000    LR 0.001000    Time 0.043115    
2022-06-21 17:34:05,064 - --- validate (epoch=17)-----------
2022-06-21 17:34:05,065 - 2000 samples (64 per mini-batch)
2022-06-21 17:34:06,619 - Epoch: [17][   32/   32]    Loss 0.286888    Top1 88.650000    
2022-06-21 17:34:06,659 - ==> Top1: 88.650    Loss: 0.287

2022-06-21 17:34:06,661 - ==> Confusion:
[[849 136]
 [ 91 924]]

2022-06-21 17:34:06,710 - ==> Best [Top1: 88.650 on epoch: 17]
2022-06-21 17:34:06,716 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:34:06,744 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:34:11,319 - Epoch: [18][  100/  282]    objective_loss 0.165723                                        LR 0.001000    Time 0.045704    
2022-06-21 17:34:15,544 - Epoch: [18][  200/  282]    objective_loss 0.175417                                        LR 0.001000    Time 0.043957    
2022-06-21 17:34:18,991 - Epoch: [18][  282/  282]    objective_loss 0.175060    Top1 91.250000    LR 0.001000    Time 0.043387    
2022-06-21 17:34:19,032 - --- validate (epoch=18)-----------
2022-06-21 17:34:19,033 - 2000 samples (64 per mini-batch)
2022-06-21 17:34:20,600 - Epoch: [18][   32/   32]    Loss 0.294126    Top1 88.800000    
2022-06-21 17:34:20,642 - ==> Top1: 88.800    Loss: 0.294

2022-06-21 17:34:20,643 - ==> Confusion:
[[888  97]
 [127 888]]

2022-06-21 17:34:20,693 - ==> Best [Top1: 88.800 on epoch: 18]
2022-06-21 17:34:20,699 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:34:20,721 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:34:25,269 - Epoch: [19][  100/  282]    objective_loss 0.152371                                        LR 0.001000    Time 0.045439    
2022-06-21 17:34:29,512 - Epoch: [19][  200/  282]    objective_loss 0.160851                                        LR 0.001000    Time 0.043913    
2022-06-21 17:34:32,936 - Epoch: [19][  282/  282]    objective_loss 0.163069    Top1 91.250000    LR 0.001000    Time 0.043276    
2022-06-21 17:34:32,977 - --- validate (epoch=19)-----------
2022-06-21 17:34:32,978 - 2000 samples (64 per mini-batch)
2022-06-21 17:34:34,540 - Epoch: [19][   32/   32]    Loss 0.323597    Top1 87.550000    
2022-06-21 17:34:34,584 - ==> Top1: 87.550    Loss: 0.324

2022-06-21 17:34:34,585 - ==> Confusion:
[[801 184]
 [ 65 950]]

2022-06-21 17:34:34,642 - ==> Best [Top1: 88.800 on epoch: 18]
2022-06-21 17:34:34,648 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:34:34,679 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:34:39,134 - Epoch: [20][  100/  282]    objective_loss 0.167710                                        LR 0.001000    Time 0.044509    
2022-06-21 17:34:43,403 - Epoch: [20][  200/  282]    objective_loss 0.163965                                        LR 0.001000    Time 0.043580    
2022-06-21 17:34:46,813 - Epoch: [20][  282/  282]    objective_loss 0.161963    Top1 88.750000    LR 0.001000    Time 0.042988    
2022-06-21 17:34:46,855 - --- validate (epoch=20)-----------
2022-06-21 17:34:46,856 - 2000 samples (64 per mini-batch)
2022-06-21 17:34:48,406 - Epoch: [20][   32/   32]    Loss 0.300145    Top1 87.850000    
2022-06-21 17:34:48,447 - ==> Top1: 87.850    Loss: 0.300

2022-06-21 17:34:48,448 - ==> Confusion:
[[900  85]
 [158 857]]

2022-06-21 17:34:48,486 - ==> Best [Top1: 88.800 on epoch: 18]
2022-06-21 17:34:48,489 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:34:48,516 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:34:53,044 - Epoch: [21][  100/  282]    objective_loss 0.157111                                        LR 0.001000    Time 0.045229    
2022-06-21 17:34:57,262 - Epoch: [21][  200/  282]    objective_loss 0.154390                                        LR 0.001000    Time 0.043678    
2022-06-21 17:35:00,699 - Epoch: [21][  282/  282]    objective_loss 0.156842    Top1 93.750000    LR 0.001000    Time 0.043154    
2022-06-21 17:35:00,740 - --- validate (epoch=21)-----------
2022-06-21 17:35:00,741 - 2000 samples (64 per mini-batch)
2022-06-21 17:35:02,304 - Epoch: [21][   32/   32]    Loss 0.301034    Top1 88.300000    
2022-06-21 17:35:02,357 - ==> Top1: 88.300    Loss: 0.301

2022-06-21 17:35:02,358 - ==> Confusion:
[[881 104]
 [130 885]]

2022-06-21 17:35:02,409 - ==> Best [Top1: 88.800 on epoch: 18]
2022-06-21 17:35:02,414 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:35:02,431 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:35:06,938 - Epoch: [22][  100/  282]    objective_loss 0.142005                                        LR 0.001000    Time 0.045022    
2022-06-21 17:35:11,169 - Epoch: [22][  200/  282]    objective_loss 0.150270                                        LR 0.001000    Time 0.043649    
2022-06-21 17:35:14,559 - Epoch: [22][  282/  282]    objective_loss 0.153066    Top1 92.500000    LR 0.001000    Time 0.042965    
2022-06-21 17:35:14,600 - --- validate (epoch=22)-----------
2022-06-21 17:35:14,601 - 2000 samples (64 per mini-batch)
2022-06-21 17:35:16,142 - Epoch: [22][   32/   32]    Loss 0.290276    Top1 88.900000    
2022-06-21 17:35:16,183 - ==> Top1: 88.900    Loss: 0.290

2022-06-21 17:35:16,184 - ==> Confusion:
[[910  75]
 [147 868]]

2022-06-21 17:35:16,234 - ==> Best [Top1: 88.900 on epoch: 22]
2022-06-21 17:35:16,239 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:35:16,267 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:35:20,899 - Epoch: [23][  100/  282]    objective_loss 0.147020                                        LR 0.001000    Time 0.046273    
2022-06-21 17:35:25,389 - Epoch: [23][  200/  282]    objective_loss 0.142247                                        LR 0.001000    Time 0.045568    
2022-06-21 17:35:28,848 - Epoch: [23][  282/  282]    objective_loss 0.148114    Top1 97.500000    LR 0.001000    Time 0.044573    
2022-06-21 17:35:28,889 - --- validate (epoch=23)-----------
2022-06-21 17:35:28,890 - 2000 samples (64 per mini-batch)
2022-06-21 17:35:30,438 - Epoch: [23][   32/   32]    Loss 0.317410    Top1 88.100000    
2022-06-21 17:35:30,482 - ==> Top1: 88.100    Loss: 0.317

2022-06-21 17:35:30,482 - ==> Confusion:
[[918  67]
 [171 844]]

2022-06-21 17:35:30,532 - ==> Best [Top1: 88.900 on epoch: 22]
2022-06-21 17:35:30,537 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:35:30,563 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:35:35,130 - Epoch: [24][  100/  282]    objective_loss 0.126448                                        LR 0.001000    Time 0.045631    
2022-06-21 17:35:39,392 - Epoch: [24][  200/  282]    objective_loss 0.137087                                        LR 0.001000    Time 0.044098    
2022-06-21 17:35:42,870 - Epoch: [24][  282/  282]    objective_loss 0.138581    Top1 96.250000    LR 0.001000    Time 0.043595    
2022-06-21 17:35:42,914 - --- validate (epoch=24)-----------
2022-06-21 17:35:42,915 - 2000 samples (64 per mini-batch)
2022-06-21 17:35:44,535 - Epoch: [24][   32/   32]    Loss 0.315623    Top1 88.800000    
2022-06-21 17:35:44,576 - ==> Top1: 88.800    Loss: 0.316

2022-06-21 17:35:44,576 - ==> Confusion:
[[825 160]
 [ 64 951]]

2022-06-21 17:35:44,626 - ==> Best [Top1: 88.900 on epoch: 22]
2022-06-21 17:35:44,631 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:35:44,648 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:35:49,129 - Epoch: [25][  100/  282]    objective_loss 0.125452                                        LR 0.001000    Time 0.044769    
2022-06-21 17:35:53,313 - Epoch: [25][  200/  282]    objective_loss 0.135125                                        LR 0.001000    Time 0.043281    
2022-06-21 17:35:56,712 - Epoch: [25][  282/  282]    objective_loss 0.139475    Top1 97.500000    LR 0.001000    Time 0.042738    
2022-06-21 17:35:56,753 - --- validate (epoch=25)-----------
2022-06-21 17:35:56,754 - 2000 samples (64 per mini-batch)
2022-06-21 17:35:58,301 - Epoch: [25][   32/   32]    Loss 0.281161    Top1 89.300000    
2022-06-21 17:35:58,342 - ==> Top1: 89.300    Loss: 0.281

2022-06-21 17:35:58,343 - ==> Confusion:
[[868 117]
 [ 97 918]]

2022-06-21 17:35:58,392 - ==> Best [Top1: 89.300 on epoch: 25]
2022-06-21 17:35:58,397 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:35:58,427 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:36:02,918 - Epoch: [26][  100/  282]    objective_loss 0.125330                                        LR 0.001000    Time 0.044864    
2022-06-21 17:36:07,114 - Epoch: [26][  200/  282]    objective_loss 0.132444                                        LR 0.001000    Time 0.043391    
2022-06-21 17:36:10,523 - Epoch: [26][  282/  282]    objective_loss 0.134020    Top1 96.250000    LR 0.001000    Time 0.042854    
2022-06-21 17:36:10,565 - --- validate (epoch=26)-----------
2022-06-21 17:36:10,566 - 2000 samples (64 per mini-batch)
2022-06-21 17:36:12,101 - Epoch: [26][   32/   32]    Loss 0.280924    Top1 89.250000    
2022-06-21 17:36:12,142 - ==> Top1: 89.250    Loss: 0.281

2022-06-21 17:36:12,143 - ==> Confusion:
[[892  93]
 [122 893]]

2022-06-21 17:36:12,190 - ==> Best [Top1: 89.300 on epoch: 25]
2022-06-21 17:36:12,195 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:36:12,220 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:36:16,739 - Epoch: [27][  100/  282]    objective_loss 0.122409                                        LR 0.001000    Time 0.045143    
2022-06-21 17:36:20,922 - Epoch: [27][  200/  282]    objective_loss 0.133389                                        LR 0.001000    Time 0.043470    
2022-06-21 17:36:24,359 - Epoch: [27][  282/  282]    objective_loss 0.132596    Top1 96.250000    LR 0.001000    Time 0.043007    
2022-06-21 17:36:24,400 - --- validate (epoch=27)-----------
2022-06-21 17:36:24,401 - 2000 samples (64 per mini-batch)
2022-06-21 17:36:25,949 - Epoch: [27][   32/   32]    Loss 0.303069    Top1 89.600000    
2022-06-21 17:36:25,991 - ==> Top1: 89.600    Loss: 0.303

2022-06-21 17:36:25,991 - ==> Confusion:
[[872 113]
 [ 95 920]]

2022-06-21 17:36:26,042 - ==> Best [Top1: 89.600 on epoch: 27]
2022-06-21 17:36:26,047 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:36:26,078 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:36:30,586 - Epoch: [28][  100/  282]    objective_loss 0.121156                                        LR 0.001000    Time 0.045041    
2022-06-21 17:36:34,789 - Epoch: [28][  200/  282]    objective_loss 0.122466                                        LR 0.001000    Time 0.043513    
2022-06-21 17:36:38,192 - Epoch: [28][  282/  282]    objective_loss 0.127238    Top1 97.500000    LR 0.001000    Time 0.042916    
2022-06-21 17:36:38,233 - --- validate (epoch=28)-----------
2022-06-21 17:36:38,234 - 2000 samples (64 per mini-batch)
2022-06-21 17:36:39,767 - Epoch: [28][   32/   32]    Loss 0.282892    Top1 89.150000    
2022-06-21 17:36:39,807 - ==> Top1: 89.150    Loss: 0.283

2022-06-21 17:36:39,808 - ==> Confusion:
[[884 101]
 [116 899]]

2022-06-21 17:36:39,849 - ==> Best [Top1: 89.600 on epoch: 27]
2022-06-21 17:36:39,853 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:36:39,875 - Training epoch: 18000 samples (64 per mini-batch)
2022-06-21 17:36:44,314 - Epoch: [29][  100/  282]    objective_loss 0.120178                                        LR 0.001000    Time 0.044341    
2022-06-21 17:36:48,517 - Epoch: [29][  200/  282]    objective_loss 0.123234                                        LR 0.001000    Time 0.043167    
2022-06-21 17:36:51,930 - Epoch: [29][  282/  282]    objective_loss 0.122676    Top1 95.000000    LR 0.001000    Time 0.042706    
2022-06-21 17:36:51,971 - --- validate (epoch=29)-----------
2022-06-21 17:36:51,972 - 2000 samples (64 per mini-batch)
2022-06-21 17:36:53,525 - Epoch: [29][   32/   32]    Loss 0.302452    Top1 89.200000    
2022-06-21 17:36:53,568 - ==> Top1: 89.200    Loss: 0.302

2022-06-21 17:36:53,568 - ==> Confusion:
[[910  75]
 [141 874]]

2022-06-21 17:36:53,622 - ==> Best [Top1: 89.600 on epoch: 27]
2022-06-21 17:36:53,628 - Saving checkpoint to: jupyter_logging/train_log___2022.06.21-172947/catdognet_qat_checkpoint.pth.tar
2022-06-21 17:36:53,648 - 5000 samples (64 per mini-batch)
2022-06-21 17:36:55,822 - Epoch: [29][   79/   79]    Loss 0.291723    Top1 88.600000    
2022-06-21 17:36:55,864 - ==> Top1: 88.600    Loss: 0.292

2022-06-21 17:36:55,865 - ==> Confusion:
[[2288  212]
 [ 358 2142]]

2022-06-21 17:36:55,866 - ==> Best [Top1: 88.600   Top5: 100.000  on test set]
