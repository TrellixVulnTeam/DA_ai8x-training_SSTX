{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b261e12b",
   "metadata": {},
   "source": [
    "# Cats and Dogs Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66236c4",
   "metadata": {},
   "source": [
    "This notebook will train, quantize, and synthesis the Cats and Dogs example. We want to use this example to show that a high test set accuracy does not guarantee a high accuracy on the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dc191",
   "metadata": {},
   "source": [
    "### Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "660421b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "\n",
    "try:\n",
    "    import tensorboard  # pylint: disable=import-error\n",
    "    import tensorflow  # pylint: disable=import-error\n",
    "    tensorflow.io.gfile = tensorboard.compat.tensorflow_stub.io.gfile\n",
    "except (ModuleNotFoundError, AttributeError):\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchnet.meter as tnt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import nnplot\n",
    "import operator\n",
    "import distiller\n",
    "import distiller.apputils as apputils\n",
    "from distiller.data_loggers import PythonLogger, TensorBoardLogger\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'models/')\n",
    "sys.path.insert(1, 'distiller/')\n",
    "sys.path.insert(2, 'datasets/')\n",
    "\n",
    "from cats_and_dogs import *\n",
    "\n",
    "mod = importlib.import_module(\"cat-dog_net\")\n",
    "\n",
    "import ai8x\n",
    "%matplotlib inline\n",
    "\n",
    "# Logger handle\n",
    "msglogger = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fa465",
   "metadata": {},
   "source": [
    "## Define Training Configurations (args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e36ccb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cats_and_dogs\"\n",
    "dataset_fn = cats_and_dogs_get_datasets\n",
    "num_classes = 2\n",
    "model_name = \"cat-dog_net\"\n",
    "dimensions = (3,128,128)\n",
    "workers = 4\n",
    "batch_size = 64\n",
    "validation_split = 0.1\n",
    "log_prefix = \"train_log\"\n",
    "log_dir = \"jupyter_logging\"\n",
    "data_path = \"../Datasets/cats_and_dogs/\"\n",
    "deterministic = True\n",
    "print_freq = 100\n",
    "labels = ('dog', 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebbe33",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fbec67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, act_mode_8bit):\n",
    "        self.act_mode_8bit = act_mode_8bit\n",
    "        self.truncate_testset = False\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f8575a",
   "metadata": {},
   "source": [
    "## Set up the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c84b777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log file for this run: /home/geffencooper/Model_Development/ai8x-training/jupyter_logging/train_log___2022.06.21-161041/train_log___2022.06.21-161041.log\n",
      "dataset_name:cats_and_dogs\n",
      "\tdataset_fn=<function cats_and_dogs_get_datasets at 0x7fcd7eedf280>\n",
      "\tnum_classes=2\n",
      "\tmodel_name=cat-dog_net\n",
      "\tdimensions=(3, 128, 128)\n",
      "\tbatch_size=64\n",
      "\tvalidation_split=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "Logging to TensorBoard - remember to execute the server:\n",
      "> tensorboard --logdir='./logs'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msglogger = apputils.config_pylogger('logging.conf', log_prefix,\n",
    "                                        log_dir)\n",
    "\n",
    "# Log various details about the execution environment.  It is sometimes useful\n",
    "# to refer to past experiment executions and this information may be useful.\n",
    "apputils.log_execution_env_state(None, msglogger.logdir)\n",
    "msglogger.debug(\"Distiller: %s\", distiller.__version__)\n",
    "\n",
    "\n",
    "pylogger = PythonLogger(msglogger, log_1d=True)\n",
    "all_loggers = [pylogger]\n",
    "\n",
    "# tensorboard\n",
    "tflogger = TensorBoardLogger(msglogger.logdir, log_1d=True, comment='_'+dataset_name)\n",
    "\n",
    "tflogger.tblogger.writer.add_text('Command line', \"args ---\")\n",
    "\n",
    "msglogger.info('dataset_name:%s\\ndataset_fn=%s\\nnum_classes=%d\\nmodel_name=%s\\ndimensions=%s\\nbatch_size=%d\\nvalidation_split=%s',\n",
    "                dataset_name,dataset_fn,num_classes,model_name,dimensions,batch_size,validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eadd17",
   "metadata": {},
   "source": [
    "## Create and Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd2047c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dogs': 0, 'cats': 1}\n",
      "{'dogs': 0, 'cats': 1}\n"
     ]
    }
   ],
   "source": [
    "args = Args(act_mode_8bit=False)\n",
    "train_set, test_set = cats_and_dogs_get_datasets((data_path, args), load_train=True, load_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cada0",
   "metadata": {},
   "source": [
    "## Visualize a batch of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c6b5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set.visualize_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b63d2a",
   "metadata": {},
   "source": [
    "## Create the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "196575ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "\ttraining=18000\n",
      "\tvalidation=2000\n",
      "\ttest=5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dogs': 0, 'cats': 1}\n",
      "{'dogs': 0, 'cats': 1}\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(\n",
    "        dataset_fn, (data_path,args), batch_size,\n",
    "        workers, validation_split, deterministic,1, 1, 1)\n",
    "msglogger.info('Dataset sizes:\\n\\ttraining=%d\\n\\tvalidation=%d\\n\\ttest=%d',\n",
    "                   len(train_loader.sampler), len(val_loader.sampler), len(test_loader.sampler))\n",
    "\n",
    "# train_dataloader = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "# test_dataloader = DataLoader(test_set,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c934995",
   "metadata": {},
   "source": [
    "## Set up the device, cuda or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8dabe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e26d9",
   "metadata": {},
   "source": [
    "## Set up the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7db0732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=False.\n",
      "Number of Model Params: 279562\n"
     ]
    }
   ],
   "source": [
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "model = mod.CatsAndDogsClassifier()\n",
    "        \n",
    "model = model.to(device)\n",
    "\n",
    "print(f'Number of Model Params: {count_params(model)}')\n",
    "\n",
    "# configure tensorboard\n",
    "dummy_input = torch.randn((1, ) + dimensions)\n",
    "tflogger.tblogger.writer.add_graph(model.to('cpu'), (dummy_input, ), False)\n",
    "\n",
    "all_loggers.append(tflogger)\n",
    "all_tbloggers = [tflogger]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddad2c1",
   "metadata": {},
   "source": [
    "## Set up the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c00fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizer Type: <class 'torch.optim.adam.Adam'>\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "msglogger.info('Optimizer Type: %s', type(optimizer))\n",
    "ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 25], gamma=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "qat_policy = {'start_epoch':5,\n",
    "              'weight_bits':8}\n",
    "compression_scheduler = distiller.CompressionScheduler(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e446e",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba442fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader, model, criterion, loggers, epoch=-1, tflogger=None):\n",
    "    \"\"\"Execute the validation/test loop.\"\"\"\n",
    "\n",
    "    # store loss stats\n",
    "    losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "    classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "\n",
    "    # validation set info\n",
    "    batch_time = tnt.AverageValueMeter()\n",
    "    total_samples = len(data_loader.sampler)\n",
    "    batch_size = data_loader.batch_size\n",
    "    confusion = tnt.ConfusionMeter(num_classes)\n",
    "    total_steps = (total_samples + batch_size - 1) // batch_size\n",
    "    msglogger.info('%d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    class_probs = []\n",
    "    class_preds = []\n",
    "\n",
    "    # iterate over the batches in the validation set\n",
    "    for validation_step, (inputs, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            # compute output from model\n",
    "            output = model(inputs)\n",
    "            # correct output for accurate loss calculation\n",
    "            if args.act_mode_8bit:\n",
    "                output /= 128.\n",
    "                for key in model.__dict__['_modules'].keys():\n",
    "                    if (hasattr(model.__dict__['_modules'][key], 'wide')\n",
    "                            and model.__dict__['_modules'][key].wide):\n",
    "                        output /= 256.\n",
    "            # compute loss\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            losses['objective_loss'].add(loss.item())\n",
    "            if len(output.data.shape) <= 2:\n",
    "                classerr.add(output.data, target)\n",
    "            else:\n",
    "                classerr.add(output.data.permute(0, 2, 3, 1).flatten(start_dim=0, end_dim=2),\n",
    "                                target.flatten())\n",
    "            \n",
    "            confusion.add(output.data, target)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.add(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # store prediction stats\n",
    "            steps_completed = (validation_step+1)\n",
    "            if steps_completed % print_freq == 0 or steps_completed == total_steps:\n",
    "                class_probs_batch = [torch.nn.functional.softmax(el, dim=0) for el in output]\n",
    "                _, class_preds_batch = torch.max(output, 1)\n",
    "                class_probs.append(class_probs_batch)\n",
    "                class_preds.append(class_preds_batch)\n",
    "\n",
    "                stats = (\n",
    "                    '',\n",
    "                    OrderedDict([('Loss', losses['objective_loss'].mean),\n",
    "                                    ('Top1', classerr.value(1))])\n",
    "                )\n",
    "                if num_classes > 5:\n",
    "                    stats[1]['Top5'] = classerr.value(5)\n",
    "\n",
    "                distiller.log_training_progress(stats, None, epoch, steps_completed,\n",
    "                                                total_steps, print_freq, loggers)\n",
    "\n",
    "                # if tflogger is not None:\n",
    "                #     test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "                #     test_preds = torch.cat(class_preds)\n",
    "                #     for i in range(num_classes):\n",
    "                #         tb_preds = test_preds == i\n",
    "                #         tb_probs = test_probs[:, i]\n",
    "                #         tflogger.tblogger.writer.add_pr_curve(str(args.labels[i]), tb_preds,\n",
    "                #                                             tb_probs, global_step=epoch)\n",
    "\n",
    "                # if steps_completed == total_steps and tflogger is not None:\n",
    "                #     def select_n_random(data, labels, features, n=100):\n",
    "                #         \"\"\"Selects n random datapoints, their corresponding labels and features\"\"\"\n",
    "                #         assert len(data) == len(labels) == len(features)\n",
    "\n",
    "                #         perm = torch.randperm(len(data))\n",
    "                #         return data[perm][:n], labels[perm][:n], features[perm][:n]\n",
    "\n",
    "                #     # Select up to 100 random images and their target indices\n",
    "                #     images, labels, features = select_n_random(inputs, target, output,\n",
    "                #                                                n=min(100, len(inputs)))\n",
    "\n",
    "                #     # Get the class labels for each image\n",
    "                #     class_labels = [args.labels[lab] for lab in labels]\n",
    "\n",
    "                #     tflogger.tblogger.writer.add_embedding(\n",
    "                #         features,\n",
    "                #         metadata=class_labels,\n",
    "                #         label_img=args.visualize_fn(images, args),\n",
    "                #         global_step=epoch,\n",
    "                #         tag='verification/embedding'\n",
    "                #     )\n",
    "\n",
    "    if num_classes > 5:\n",
    "        msglogger.info('==> Top1: %.3f    Top5: %.3f    Loss: %.3f\\n',\n",
    "                        classerr.value()[0], classerr.value()[1],\n",
    "                        losses['objective_loss'].mean)\n",
    "    else:\n",
    "        msglogger.info('==> Top1: %.3f    Loss: %.3f\\n',\n",
    "                        classerr.value()[0], losses['objective_loss'].mean)\n",
    "\n",
    "    msglogger.info('==> Confusion:\\n%s\\n', str(confusion.value()))\n",
    "    if tflogger is not None:\n",
    "        cf = nnplot.confusion_matrix(confusion.value(), labels)\n",
    "        tflogger.tblogger.writer.add_image('Validation/ConfusionMatrix', cf, epoch,\n",
    "                                            dataformats='HWC')\n",
    "    return classerr.value(1), classerr.value(min(num_classes, 5)), losses['objective_loss'].mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92564625",
   "metadata": {},
   "source": [
    "## Run the trianing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1731f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 18000 samples (64 per mini-batch)\n",
      "Epoch: [0][  100/  282]    objective_loss 0.632911                                        LR 0.001000    Time 0.045232    \n",
      "Epoch: [0][  200/  282]    objective_loss 0.596877                                        LR 0.001000    Time 0.043207    \n",
      "Epoch: [0][  282/  282]    objective_loss 0.569078    Top1 87.500000    LR 0.001000    Time 0.042579    \n",
      "--- validate (epoch=0)-----------\n",
      "2000 samples (64 per mini-batch)\n",
      "==> Top1: 67.188    Loss: 0.529\n",
      "\n",
      "==> Confusion:\n",
      "[[13 19]\n",
      " [ 2 30]]\n",
      "\n",
      "==> Top1: 65.625    Loss: 0.611\n",
      "\n",
      "==> Confusion:\n",
      "[[27 40]\n",
      " [ 4 57]]\n",
      "\n",
      "==> Top1: 66.667    Loss: 0.623\n",
      "\n",
      "==> Confusion:\n",
      "[[35 59]\n",
      " [ 5 93]]\n",
      "\n",
      "==> Top1: 65.625    Loss: 0.637\n",
      "\n",
      "==> Confusion:\n",
      "[[ 41  81]\n",
      " [  7 127]]\n",
      "\n",
      "==> Top1: 65.000    Loss: 0.635\n",
      "\n",
      "==> Confusion:\n",
      "[[ 53 103]\n",
      " [  9 155]]\n",
      "\n",
      "==> Top1: 66.146    Loss: 0.610\n",
      "\n",
      "==> Confusion:\n",
      "[[ 63 120]\n",
      " [ 10 191]]\n",
      "\n",
      "==> Top1: 66.741    Loss: 0.611\n",
      "\n",
      "==> Confusion:\n",
      "[[ 73 139]\n",
      " [ 10 226]]\n",
      "\n",
      "==> Top1: 67.188    Loss: 0.613\n",
      "\n",
      "==> Confusion:\n",
      "[[ 89 157]\n",
      " [ 11 255]]\n",
      "\n",
      "==> Top1: 67.188    Loss: 0.619\n",
      "\n",
      "==> Confusion:\n",
      "[[101 178]\n",
      " [ 11 286]]\n",
      "\n",
      "==> Top1: 66.875    Loss: 0.622\n",
      "\n",
      "==> Confusion:\n",
      "[[109 201]\n",
      " [ 11 319]]\n",
      "\n",
      "==> Top1: 65.767    Loss: 0.634\n",
      "\n",
      "==> Confusion:\n",
      "[[119 227]\n",
      " [ 14 344]]\n",
      "\n",
      "==> Top1: 65.365    Loss: 0.642\n",
      "\n",
      "==> Confusion:\n",
      "[[128 249]\n",
      " [ 17 374]]\n",
      "\n",
      "==> Top1: 66.226    Loss: 0.631\n",
      "\n",
      "==> Confusion:\n",
      "[[143 262]\n",
      " [ 19 408]]\n",
      "\n",
      "==> Top1: 66.295    Loss: 0.629\n",
      "\n",
      "==> Confusion:\n",
      "[[154 283]\n",
      " [ 19 440]]\n",
      "\n",
      "==> Top1: 66.771    Loss: 0.620\n",
      "\n",
      "==> Confusion:\n",
      "[[171 299]\n",
      " [ 20 470]]\n",
      "\n",
      "==> Top1: 67.090    Loss: 0.620\n",
      "\n",
      "==> Confusion:\n",
      "[[184 316]\n",
      " [ 21 503]]\n",
      "\n",
      "==> Top1: 67.371    Loss: 0.615\n",
      "\n",
      "==> Confusion:\n",
      "[[202 331]\n",
      " [ 24 531]]\n",
      "\n",
      "==> Top1: 67.101    Loss: 0.618\n",
      "\n",
      "==> Confusion:\n",
      "[[211 354]\n",
      " [ 25 562]]\n",
      "\n",
      "==> Top1: 66.776    Loss: 0.624\n",
      "\n",
      "==> Confusion:\n",
      "[[224 377]\n",
      " [ 27 588]]\n",
      "\n",
      "==> Top1: 66.875    Loss: 0.624\n",
      "\n",
      "==> Confusion:\n",
      "[[232 394]\n",
      " [ 30 624]]\n",
      "\n",
      "==> Top1: 66.815    Loss: 0.625\n",
      "\n",
      "==> Confusion:\n",
      "[[251 415]\n",
      " [ 31 647]]\n",
      "\n",
      "==> Top1: 66.477    Loss: 0.633\n",
      "\n",
      "==> Confusion:\n",
      "[[267 440]\n",
      " [ 32 669]]\n",
      "\n",
      "==> Top1: 66.508    Loss: 0.631\n",
      "\n",
      "==> Confusion:\n",
      "[[276 461]\n",
      " [ 32 703]]\n",
      "\n",
      "==> Top1: 66.471    Loss: 0.630\n",
      "\n",
      "==> Confusion:\n",
      "[[283 481]\n",
      " [ 34 738]]\n",
      "\n",
      "==> Top1: 65.875    Loss: 0.638\n",
      "\n",
      "==> Confusion:\n",
      "[[292 510]\n",
      " [ 36 762]]\n",
      "\n",
      "==> Top1: 66.106    Loss: 0.637\n",
      "\n",
      "==> Confusion:\n",
      "[[300 528]\n",
      " [ 36 800]]\n",
      "\n",
      "==> Top1: 65.799    Loss: 0.644\n",
      "\n",
      "==> Confusion:\n",
      "[[312 554]\n",
      " [ 37 825]]\n",
      "\n",
      "==> Top1: 65.960    Loss: 0.642\n",
      "\n",
      "==> Confusion:\n",
      "[[320 573]\n",
      " [ 37 862]]\n",
      "\n",
      "==> Top1: 66.002    Loss: 0.639\n",
      "\n",
      "==> Confusion:\n",
      "[[332 592]\n",
      " [ 39 893]]\n",
      "\n",
      "==> Top1: 66.250    Loss: 0.634\n",
      "\n",
      "==> Confusion:\n",
      "[[342 609]\n",
      " [ 39 930]]\n",
      "\n",
      "==> Top1: 66.532    Loss: 0.630\n",
      "\n",
      "==> Confusion:\n",
      "[[355 625]\n",
      " [ 39 965]]\n",
      "\n",
      "Epoch: [0][   32/   32]    Loss 0.629831    Top1 66.500000    \n",
      "==> Top1: 66.500    Loss: 0.630\n",
      "\n",
      "==> Confusion:\n",
      "[[355 630]\n",
      " [ 40 975]]\n",
      "\n",
      "==> Best [Top1: 66.500 on epoch: 0]\n",
      "Saving checkpoint to: jupyter_logging/train_log___2022.06.21-160144/cat-dog_net_checkpoint.pth.tar\n",
      "Training epoch: 18000 samples (64 per mini-batch)\n",
      "Epoch: [1][  100/  282]    objective_loss 0.466794                                        LR 0.001000    Time 0.044305    \n",
      "Epoch: [1][  200/  282]    objective_loss 0.448285                                        LR 0.001000    Time 0.043263    \n",
      "Epoch: [1][  282/  282]    objective_loss 0.442824    Top1 80.000000    LR 0.001000    Time 0.042772    \n",
      "--- validate (epoch=1)-----------\n",
      "2000 samples (64 per mini-batch)\n",
      "==> Top1: 81.250    Loss: 0.423\n",
      "\n",
      "==> Confusion:\n",
      "[[24  7]\n",
      " [ 5 28]]\n",
      "\n",
      "==> Top1: 78.125    Loss: 0.447\n",
      "\n",
      "==> Confusion:\n",
      "[[52 13]\n",
      " [15 48]]\n",
      "\n",
      "==> Top1: 78.646    Loss: 0.431\n",
      "\n",
      "==> Confusion:\n",
      "[[77 21]\n",
      " [20 74]]\n",
      "\n",
      "==> Top1: 76.172    Loss: 0.475\n",
      "\n",
      "==> Confusion:\n",
      "[[101  29]\n",
      " [ 32  94]]\n",
      "\n",
      "==> Top1: 76.875    Loss: 0.460\n",
      "\n",
      "==> Confusion:\n",
      "[[126  36]\n",
      " [ 38 120]]\n",
      "\n",
      "==> Top1: 75.781    Loss: 0.469\n",
      "\n",
      "==> Confusion:\n",
      "[[150  47]\n",
      " [ 46 141]]\n",
      "\n",
      "==> Top1: 77.455    Loss: 0.450\n",
      "\n",
      "==> Confusion:\n",
      "[[175  53]\n",
      " [ 48 172]]\n",
      "\n",
      "==> Top1: 78.125    Loss: 0.441\n",
      "\n",
      "==> Confusion:\n",
      "[[201  59]\n",
      " [ 53 199]]\n",
      "\n",
      "==> Top1: 78.125    Loss: 0.448\n",
      "\n",
      "==> Confusion:\n",
      "[[223  68]\n",
      " [ 58 227]]\n",
      "\n",
      "==> Top1: 79.219    Loss: 0.437\n",
      "\n",
      "==> Confusion:\n",
      "[[247  70]\n",
      " [ 63 260]]\n",
      "\n",
      "==> Top1: 79.688    Loss: 0.436\n",
      "\n",
      "==> Confusion:\n",
      "[[276  75]\n",
      " [ 68 285]]\n",
      "\n",
      "==> Top1: 79.557    Loss: 0.437\n",
      "\n",
      "==> Confusion:\n",
      "[[301  85]\n",
      " [ 72 310]]\n",
      "\n",
      "==> Top1: 80.048    Loss: 0.429\n",
      "\n",
      "==> Confusion:\n",
      "[[327  88]\n",
      " [ 78 339]]\n",
      "\n",
      "==> Top1: 79.464    Loss: 0.434\n",
      "\n",
      "==> Confusion:\n",
      "[[349 100]\n",
      " [ 84 363]]\n",
      "\n",
      "==> Top1: 79.896    Loss: 0.428\n",
      "\n",
      "==> Confusion:\n",
      "[[388 105]\n",
      " [ 88 379]]\n",
      "\n",
      "==> Top1: 79.297    Loss: 0.434\n",
      "\n",
      "==> Confusion:\n",
      "[[406 112]\n",
      " [100 406]]\n",
      "\n",
      "==> Top1: 79.504    Loss: 0.431\n",
      "\n",
      "==> Confusion:\n",
      "[[431 119]\n",
      " [104 434]]\n",
      "\n",
      "==> Top1: 79.514    Loss: 0.432\n",
      "\n",
      "==> Confusion:\n",
      "[[450 125]\n",
      " [111 466]]\n",
      "\n",
      "==> Top1: 79.359    Loss: 0.432\n",
      "\n",
      "==> Confusion:\n",
      "[[472 134]\n",
      " [117 493]]\n",
      "\n",
      "==> Top1: 79.141    Loss: 0.436\n",
      "\n",
      "==> Confusion:\n",
      "[[491 142]\n",
      " [125 522]]\n",
      "\n",
      "==> Top1: 79.092    Loss: 0.437\n",
      "\n",
      "==> Confusion:\n",
      "[[520 150]\n",
      " [131 543]]\n",
      "\n",
      "==> Top1: 78.835    Loss: 0.436\n",
      "\n",
      "==> Confusion:\n",
      "[[539 156]\n",
      " [142 571]]\n",
      "\n",
      "==> Top1: 79.144    Loss: 0.433\n",
      "\n",
      "==> Confusion:\n",
      "[[563 162]\n",
      " [145 602]]\n",
      "\n",
      "==> Top1: 79.557    Loss: 0.429\n",
      "\n",
      "==> Confusion:\n",
      "[[596 165]\n",
      " [149 626]]\n",
      "\n",
      "==> Top1: 79.688    Loss: 0.430\n",
      "\n",
      "==> Confusion:\n",
      "[[620 173]\n",
      " [152 655]]\n",
      "\n",
      "==> Top1: 79.868    Loss: 0.425\n",
      "\n",
      "==> Confusion:\n",
      "[[649 177]\n",
      " [158 680]]\n",
      "\n",
      "==> Top1: 80.035    Loss: 0.424\n",
      "\n",
      "==> Confusion:\n",
      "[[665 184]\n",
      " [161 718]]\n",
      "\n",
      "==> Top1: 79.520    Loss: 0.430\n",
      "\n",
      "==> Confusion:\n",
      "[[684 195]\n",
      " [172 741]]\n",
      "\n",
      "==> Top1: 79.795    Loss: 0.428\n",
      "\n",
      "==> Confusion:\n",
      "[[713 198]\n",
      " [177 768]]\n",
      "\n",
      "==> Top1: 79.792    Loss: 0.429\n",
      "\n",
      "==> Confusion:\n",
      "[[738 205]\n",
      " [183 794]]\n",
      "\n",
      "==> Top1: 79.940    Loss: 0.428\n",
      "\n",
      "==> Confusion:\n",
      "[[766 210]\n",
      " [188 820]]\n",
      "\n",
      "Epoch: [1][   32/   32]    Loss 0.420740    Top1 80.050000    \n",
      "==> Top1: 80.050    Loss: 0.421\n",
      "\n",
      "==> Confusion:\n",
      "[[774 211]\n",
      " [188 827]]\n",
      "\n",
      "==> Best [Top1: 80.050 on epoch: 1]\n",
      "Saving checkpoint to: jupyter_logging/train_log___2022.06.21-160144/cat-dog_net_checkpoint.pth.tar\n",
      "Training epoch: 18000 samples (64 per mini-batch)\n",
      "Epoch: [2][  100/  282]    objective_loss 0.382359                                        LR 0.001000    Time 0.044367    \n",
      "Epoch: [2][  200/  282]    objective_loss 0.378205                                        LR 0.001000    Time 0.043260    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=42'>43</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=44'>45</a>\u001b[0m \u001b[39m# iterate over all batches in the dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_step, (inputs, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=46'>47</a>\u001b[0m     \u001b[39m# Measure data loading time\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=47'>48</a>\u001b[0m     data_time\u001b[39m.\u001b[39madd(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m end)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=48'>49</a>\u001b[0m     inputs, target \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1182\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1181\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1182\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1185\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1137\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1138\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1139\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1140\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:986\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    974\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    987\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m    988\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    989\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    180\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    307\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep track of incorrect predictions\n",
    "wrong_samples = None\n",
    "wrong_preds = None\n",
    "actual_preds = None\n",
    "\n",
    "# store model history across epochs\n",
    "perf_scores_history = []\n",
    "model = model.to(device)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(0, num_epochs):\n",
    "    # check if need to switch to QAT\n",
    "    if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "        print('QAT is starting!')\n",
    "        # Fuse the BN parameters into conv layers before Quantization Aware Training (QAT)\n",
    "        ai8x.fuse_bn_layers(model)\n",
    "\n",
    "        # Switch model from unquantized to quantized for QAT\n",
    "        ai8x.initiate_qat(model, qat_policy)\n",
    "\n",
    "        # Model is re-transferred to GPU in case parameters were added\n",
    "        model.to(device)\n",
    "\n",
    "        # Empty the performance scores list for QAT operation\n",
    "        perf_scores_history = []\n",
    "        name = f'{model_name}_qat'\n",
    "\n",
    "    # store loss and training stats\n",
    "    losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "    classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "    batch_time = tnt.AverageValueMeter()\n",
    "    data_time = tnt.AverageValueMeter()\n",
    "\n",
    "    # logging stats\n",
    "    total_samples = len(train_loader.sampler)\n",
    "    batch_size = train_loader.batch_size\n",
    "    steps_per_epoch = (total_samples + batch_size - 1) // batch_size\n",
    "    msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "    acc_stats = []\n",
    "    end = time.time()\n",
    "\n",
    "    # iterate over all batches in the dataset\n",
    "    for train_step, (inputs, target) in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.add(time.time() - end)\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # on the last batch store the stats for the epoch\n",
    "        if train_step >= len(train_loader)-2:\n",
    "            if len(output.data.shape) <= 2:\n",
    "                classerr.add(output.data, target)\n",
    "            else:\n",
    "                classerr.add(output.data.permute(0, 2, 3, 1).flatten(start_dim=0, end_dim=2),\n",
    "                                target.flatten())\n",
    "            acc_stats.append([classerr.value(1), classerr.value(min(num_classes, 5))])\n",
    "\n",
    "        # add the loss for each batch\n",
    "        losses[\"objective_loss\"].add(loss.item())\n",
    "\n",
    "        # reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backwards pass and parameter update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # track batch stats\n",
    "        batch_time.add(time.time() - end)\n",
    "        steps_completed = (train_step+1)\n",
    "\n",
    "        # log stats every 10 batches\n",
    "        if steps_completed % print_freq == 0 or steps_completed == steps_per_epoch:\n",
    "            # Log some statistics\n",
    "            errs = OrderedDict()\n",
    "            if classerr.n != 0:\n",
    "                errs['Top1'] = classerr.value(1)\n",
    "                if num_classes > 5:\n",
    "                    errs['Top5'] = classerr.value(5)\n",
    "            else:\n",
    "                errs['Top1'] = None\n",
    "                errs['Top5'] = None\n",
    "\n",
    "            stats_dict = OrderedDict()\n",
    "            for loss_name, meter in losses.items():\n",
    "                stats_dict[loss_name] = meter.mean\n",
    "            stats_dict.update(errs)\n",
    "            \n",
    "            stats_dict['LR'] = optimizer.param_groups[0]['lr']\n",
    "            stats_dict['Time'] = batch_time.mean\n",
    "            stats = ('Performance/Training/', stats_dict)\n",
    "            params = None\n",
    "            distiller.log_training_progress(stats,\n",
    "                                            params,\n",
    "                                            epoch, steps_completed,\n",
    "                                            steps_per_epoch, print_freq,\n",
    "                                            all_loggers)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    # after a training epoch, do validation\n",
    "    msglogger.info('--- validate (epoch=%d)-----------', epoch)\n",
    "    top1, top5, vloss = validate(val_loader, model, criterion, [pylogger], epoch, tflogger)\n",
    "\n",
    "    # store validation stats\n",
    "    stats = ('Performance/Validation/', OrderedDict([('Loss', vloss), ('Top1', top1)]))\n",
    "    if num_classes > 5:\n",
    "        stats[1]['Top5'] = top5\n",
    "\n",
    "    distiller.log_training_progress(stats, None, epoch, steps_completed=0, total_steps=1,\n",
    "                                            log_freq=1, loggers=all_tbloggers)\n",
    "\n",
    "    perf_scores_history.append(distiller.MutableNamedTuple({'top1': top1, 'top5': top5,\n",
    "                                                            'epoch': epoch}))\n",
    "    # Keep perf_scores_history sorted from best to worst\n",
    "    # Sort by top1 as main sort key, then sort by top5 and epoch\n",
    "    perf_scores_history.sort(key=operator.attrgetter('top1', 'top5', 'epoch'),reverse=True)\n",
    "    for score in perf_scores_history[:1]:\n",
    "        if num_classes > 5:\n",
    "            msglogger.info('==> Best [Top1: %.3f   Top5: %.3f  on epoch: %d]',\n",
    "                            score.top1, score.top5,score.epoch)\n",
    "        else:\n",
    "            msglogger.info('==> Best [Top1: %.3f on epoch: %d]',\n",
    "                            score.top1, score.epoch)\n",
    "\n",
    "    # Save the checkpoint\n",
    "    is_best = epoch == perf_scores_history[0].epoch\n",
    "    checkpoint_extras = {'current_top1': top1,\n",
    "                        'best_top1': perf_scores_history[0].top1,\n",
    "                        'best_epoch': perf_scores_history[0].epoch}\n",
    "\n",
    "    apputils.save_checkpoint(epoch, model_name, model, optimizer=optimizer,\n",
    "                                scheduler=compression_scheduler, extras=checkpoint_extras,\n",
    "                                is_best=is_best, name=model_name,\n",
    "                                dir=msglogger.logdir)\n",
    "\n",
    "# Finally run results on the test set\n",
    "top1, top5, losses = validate(test_loader, model, criterion, [pylogger],None,None)\n",
    "\n",
    "\n",
    "\n",
    "#     running_loss = []\n",
    "#     train_start = time.time()\n",
    "#     model.train()\n",
    "#     for idx, (image, label) in enumerate(train_dataloader):\n",
    "#         image = image.to(device)\n",
    "#         label = label.type(torch.long).to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         model_out = model(image)\n",
    "        \n",
    "#         loss = criterion(model_out, label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "#     mean_loss = np.mean(running_loss)\n",
    "#     train_end = time.time()\n",
    "#     print(\"Epoch: {}/{}\\t LR: {}\\t Train Loss: {:.4f}\\t Dur: {:.2f} sec.\".format(epoch+1, num_epochs, ms_lr_scheduler.get_lr(), mean_loss, (train_end-train_start)))\n",
    "    \n",
    "#     model.eval()\n",
    "#     acc = 0.\n",
    "#     acc_weight = 0\n",
    "#     with torch.no_grad():\n",
    "#         for image, label in test_dataloader:\n",
    "#             image = image.to(device)\n",
    "#             label = label.type(torch.long).to(device)\n",
    "#             model_out = model(image)\n",
    "#             label_out = torch.argmax(model_out, dim=1)\n",
    "\n",
    "#             # display wrong outputs\n",
    "#             pred = model_out.argmax(dim=1, keepdim=True) # get the idxs of the max output\n",
    "#             wrong_idx = (pred != label.view_as(pred)).nonzero()[:, 0] # get wrong predictions\n",
    "#             wrong_samples = image[wrong_idx]\n",
    "#             wrong_preds = pred[wrong_idx]\n",
    "#             actual_preds = label.view_as(pred)[wrong_idx]\n",
    "            \n",
    "#             # test_set.viz_mispredict(wrong_samples,wrong_preds,actual_preds)\n",
    "            \n",
    "#             tp = torch.sum(label_out == label)\n",
    "#             acc_batch = (tp / label_out.numel()).detach().item()\n",
    "#             acc += label_out.shape[0] * acc_batch\n",
    "#             acc_weight += label_out.shape[0]\n",
    "            \n",
    "#         total_acc = 100 * (acc / acc_weight)\n",
    "#         if epoch == qat_policy['start_epoch']: best_acc = 0\n",
    "#         if total_acc > best_acc:\n",
    "#             best_acc = total_acc\n",
    "#             checkpoint_extras = {'current_top1': best_acc,\n",
    "#                                  'best_top1': best_acc,\n",
    "#                                  'best_epoch': epoch}\n",
    "#             model_name = 'catdognet'\n",
    "#             model_prefix = f'{model_name}' if epoch < qat_policy['start_epoch'] else (f'qat_{model_name}')\n",
    "#             apputils.save_checkpoint(epoch, model_name, model, optimizer=optimizer,\n",
    "#                                      scheduler=None, extras=checkpoint_extras,\n",
    "#                                      is_best=True, name=model_prefix,\n",
    "#                                      dir='.')\n",
    "#             print(f'Best model saved with accuracy: {best_acc:.2f}%')\n",
    "            \n",
    "#         print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "        \n",
    "#     ms_lr_scheduler.step()\n",
    "# #test_set.visualize_batch(model,device)\n",
    "# test_set.viz_mispredict(wrong_samples,wrong_preds,actual_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eaab8",
   "metadata": {},
   "source": [
    "## Quantize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed081a7",
   "metadata": {},
   "source": [
    "You must change the kernel to execute within the ai8x-synthesis virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed6b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Configuring device: MAX78000\n",
      "Converting checkpoint file qat_catdognet_best.pth.tar to qat_catdognet_best_q.pth.tar\n",
      "\n",
      "Model keys (state_dict):\n",
      "conv1.output_shift, conv1.weight_bits, conv1.bias_bits, conv1.quantize_activation, conv1.adjust_output_shift, conv1.shift_quantile, conv1.op.weight, conv2.output_shift, conv2.weight_bits, conv2.bias_bits, conv2.quantize_activation, conv2.adjust_output_shift, conv2.shift_quantile, conv2.op.weight, conv3.output_shift, conv3.weight_bits, conv3.bias_bits, conv3.quantize_activation, conv3.adjust_output_shift, conv3.shift_quantile, conv3.op.weight, conv4.output_shift, conv4.weight_bits, conv4.bias_bits, conv4.quantize_activation, conv4.adjust_output_shift, conv4.shift_quantile, conv4.op.weight, conv4.op.bias, conv5.output_shift, conv5.weight_bits, conv5.bias_bits, conv5.quantize_activation, conv5.adjust_output_shift, conv5.shift_quantile, conv5.op.weight, conv5.op.bias, conv6.output_shift, conv6.weight_bits, conv6.bias_bits, conv6.quantize_activation, conv6.adjust_output_shift, conv6.shift_quantile, conv6.op.weight, conv6.op.bias, conv7.output_shift, conv7.weight_bits, conv7.bias_bits, conv7.quantize_activation, conv7.adjust_output_shift, conv7.shift_quantile, conv7.op.weight, conv7.op.bias, conv8.output_shift, conv8.weight_bits, conv8.bias_bits, conv8.quantize_activation, conv8.adjust_output_shift, conv8.shift_quantile, conv8.op.weight, conv8.op.bias, conv9.output_shift, conv9.weight_bits, conv9.bias_bits, conv9.quantize_activation, conv9.adjust_output_shift, conv9.shift_quantile, conv9.op.weight, conv9.op.bias, conv10.output_shift, conv10.weight_bits, conv10.bias_bits, conv10.quantize_activation, conv10.adjust_output_shift, conv10.shift_quantile, conv10.op.weight, conv10.op.bias, fc1.output_shift, fc1.weight_bits, fc1.bias_bits, fc1.quantize_activation, fc1.adjust_output_shift, fc1.shift_quantile, fc1.op.weight, fc1.op.bias, fc2.output_shift, fc2.weight_bits, fc2.bias_bits, fc2.quantize_activation, fc2.adjust_output_shift, fc2.shift_quantile, fc2.op.weight, fc2.op.bias\n",
      "conv1.op.weight avg_max: 0.3854908 max: 0.45627576 mean: -0.0024837037 factor: [256.] bits: 8\n",
      "conv2.op.weight avg_max: 0.44908145 max: 0.6311059 mean: 0.000536748 factor: [128.] bits: 8\n",
      "conv3.op.weight avg_max: 0.32764462 max: 0.51057696 mean: -0.007096592 factor: [128.] bits: 8\n",
      "conv4.op.weight avg_max: 0.58702224 max: 1.16641 mean: -0.01466694 factor: [64.] bits: 8\n",
      "conv4.op.bias avg_max: 0.04040864 max: 0.32063925 mean: 0.04040864 factor: [64.] bits: 8\n",
      "conv5.op.weight avg_max: 0.27100113 max: 0.36622727 mean: -0.00683449 factor: [256.] bits: 8\n",
      "conv5.op.bias avg_max: 0.07195299 max: 0.38003165 mean: 0.07195299 factor: [256.] bits: 8\n",
      "conv6.op.weight avg_max: 0.2669633 max: 0.38850245 mean: -0.0124310665 factor: [256.] bits: 8\n",
      "conv6.op.bias avg_max: 0.07023593 max: 0.46192965 mean: 0.07023593 factor: [256.] bits: 8\n",
      "conv7.op.weight avg_max: 0.21260104 max: 0.29320973 mean: -0.0074455496 factor: [128.] bits: 8\n",
      "conv7.op.bias avg_max: 0.02418859 max: 0.6038124 mean: 0.02418859 factor: [128.] bits: 8\n",
      "conv8.op.weight avg_max: 0.20876801 max: 0.27313992 mean: -0.013293613 factor: [256.] bits: 8\n",
      "conv8.op.bias avg_max: 0.072887756 max: 0.34735835 mean: 0.072887756 factor: [256.] bits: 8\n",
      "conv9.op.weight avg_max: 0.1702366 max: 0.24018726 mean: -0.007925945 factor: [256.] bits: 8\n",
      "conv9.op.bias avg_max: 0.057955693 max: 0.4095358 mean: -0.057955693 factor: [256.] bits: 8\n",
      "conv10.op.weight avg_max: 0.16508639 max: 0.2348954 mean: -0.004653477 factor: [256.] bits: 8\n",
      "conv10.op.bias avg_max: 0.05707618 max: 0.3281022 mean: -0.05707618 factor: [256.] bits: 8\n",
      "fc1.op.weight avg_max: 0.20540045 max: 0.4997843 mean: -0.003593734 factor: [256.] bits: 8\n",
      "fc1.op.bias avg_max: 0.005289898 max: 0.07559087 mean: -0.005289898 factor: [256.] bits: 8\n",
      "fc2.op.weight avg_max: 0.35916835 max: 0.38328177 mean: -0.005065017 factor: [256.] bits: 8\n",
      "fc2.op.bias avg_max: 0.058351293 max: 0.06514479 mean: 0.058351293 factor: [256.] bits: 8\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run ../ai8x-synthesis/quantize.py qat_catdognet_best.pth.tar qat_catdognet_best_q.pth.tar --device MAX78000 -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1681a",
   "metadata": {},
   "source": [
    "## Evaluate Quantized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216527c",
   "metadata": {},
   "source": [
    "Change virtual environment back to ai8x-training and rerun the first cell with the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b61e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=True.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "load_model_path = 'qat_catdognet_best_q.pth.tar'\n",
    "# Change this path to match file system layout\n",
    "data_path = \"../Datasets/cats_and_dogs/\"\n",
    "\n",
    "ai8x.set_device(device=85, simulate=True, round_avg=False)\n",
    "\n",
    "model = mod.CatsAndDogsClassifier()\n",
    "                          \n",
    "checkpoint = torch.load(load_model_path, map_location=lambda storage, loc: storage)\n",
    "ai8x.fuse_bn_layers(model)\n",
    "model = apputils.load_lean_checkpoint(model, load_model_path, model_device=device)\n",
    "ai8x.update_model(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a04b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dogs': 0, 'cats': 1}\n",
      "{'dogs': 0, 'cats': 1}\n"
     ]
    }
   ],
   "source": [
    "args = Args(act_mode_8bit=True)\n",
    "\n",
    "_, test_set = train_set, test_set = cats_and_dogs_get_datasets((data_path, args), load_train=True, load_test=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ccce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized accuracy: 91.58%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "acc = 0.\n",
    "acc_weight = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_dataloader:\n",
    "        image = image.to(device)\n",
    "        label = label.type(torch.long).to(device)\n",
    "        model_out = model(image)\n",
    "        label_out = torch.argmax(model_out, dim=1)\n",
    "\n",
    "        tp = torch.sum(label_out == label)\n",
    "        acc_batch = (tp / label_out.numel()).detach().item()\n",
    "        acc += label_out.shape[0] * acc_batch\n",
    "        acc_weight += label_out.shape[0]\n",
    "\n",
    "    total_acc = 100 * (acc / acc_weight)\n",
    "print(f'Quantized accuracy: {total_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30edf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in test_dataloader:\n",
    "    break\n",
    "\n",
    "im_sample = (image[0].detach().cpu().numpy()).astype(np.int64)\n",
    "\n",
    "np.save('sample_cats_and_dogs.npy', im_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa74c1",
   "metadata": {},
   "source": [
    "## Model Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffee381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING:</span> </pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING:\u001b[0m "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot check for updates for git branch \"DA\" from GitHub - Branch not found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING:</span> </pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING:\u001b[0m "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 11: `flatten` is not needed since input dimensions are 1x1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">ERROR:</span> </pre>\n"
      ],
      "text/plain": [
       "\u001b[31mERROR:\u001b[0m "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The target folder sdk/Examples/MAX78000/CNN/cats_and_dogs exists. Use --overwrite to proceed.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/izer/backend/max7800x.py:756\u001b[0m, in \u001b[0;36mBackend.create_net\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     target_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_directory, test_name)\n\u001b[0;32m--> 756\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(target_dir, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    757\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'sdk/Examples/MAX78000/CNN/cats_and_dogs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2738\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile\u001b[0;34m(self, fname, exit_ignore, raise_exceptions, shell_futures, *where)\u001b[0m\n\u001b[1;32m   2737\u001b[0m     glob, loc \u001b[39m=\u001b[39m (where \u001b[39m+\u001b[39m (\u001b[39mNone\u001b[39;00m, ))[:\u001b[39m2\u001b[39m]\n\u001b[0;32m-> 2738\u001b[0m     py3compat\u001b[39m.\u001b[39;49mexecfile(\n\u001b[1;32m   2739\u001b[0m         fname, glob, loc,\n\u001b[1;32m   2740\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile \u001b[39mif\u001b[39;49;00m shell_futures \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   2741\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mSystemExit\u001b[39;00m \u001b[39mas\u001b[39;00m status:\n\u001b[1;32m   2742\u001b[0m     \u001b[39m# If the call was made with 0 or None exit status (sys.exit(0)\u001b[39;00m\n\u001b[1;32m   2743\u001b[0m     \u001b[39m# or sys.exit() ), don't bother showing a traceback, as both of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2749\u001b[0m     \u001b[39m# For other exit status, we show the exception unless\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m     \u001b[39m# explicitly silenced, but only in short form.\u001b[39;00m\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/utils/py3compat.py:55\u001b[0m, in \u001b[0;36mexecfile\u001b[0;34m(fname, glob, loc, compiler)\u001b[0m\n\u001b[1;32m     54\u001b[0m compiler \u001b[39m=\u001b[39m compiler \u001b[39mor\u001b[39;00m \u001b[39mcompile\u001b[39m\n\u001b[0;32m---> 55\u001b[0m exec(compiler(f\u001b[39m.\u001b[39;49mread(), fname, \u001b[39m\"\u001b[39;49m\u001b[39mexec\u001b[39;49m\u001b[39m\"\u001b[39;49m), glob, loc)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/ai8xize.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, signal_handler)\n\u001b[0;32m---> 29\u001b[0m main()\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/izer/izer.py:656\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    654\u001b[0m be \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mBackend()\n\u001b[0;32m--> 656\u001b[0m tn \u001b[39m=\u001b[39m be\u001b[39m.\u001b[39;49mcreate_net()\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39membedded_code \u001b[39mand\u001b[39;00m args\u001b[39m.\u001b[39mautogen\u001b[39m.\u001b[39mlower() \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/izer/backend/max7800x.py:759\u001b[0m, in \u001b[0;36mBackend.create_net\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite:\n\u001b[0;32m--> 759\u001b[0m     eprint(\u001b[39m'\u001b[39;49m\u001b[39mThe target folder\u001b[39;49m\u001b[39m'\u001b[39;49m, target_dir, \u001b[39m'\u001b[39;49m\u001b[39mexists. Use --overwrite to proceed.\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    760\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/izer/eprint.py:40\u001b[0m, in \u001b[0;36meprint\u001b[0;34m(error, notice, prefix, exit_code, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m error \u001b[39mand\u001b[39;00m exit_code \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     sys\u001b[39m.\u001b[39;49mexit(error)\n",
      "\u001b[0;31mSystemExit\u001b[0m: True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mcd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m../ai8x-synthesis/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mai8xize.py --verbose --log --test-dir sdk/Examples/MAX78000/CNN --prefix cats_and_dogs --checkpoint-file ../ai8x-training/qat_catdognet_best_q.pth.tar --config-file networks/cats_and_dogs.yaml --device MAX78000 --softmax --compact-data --mexpress --timer 0 --fifo --display-checkpoint\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2305\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2304\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2305\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2306\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/magics/execution.py:829\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_with_timing(run, nruns)\n\u001b[1;32m    827\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m             \u001b[39m# regular execution\u001b[39;00m\n\u001b[0;32m--> 829\u001b[0m             run()\n\u001b[1;32m    831\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m opts:\n\u001b[1;32m    832\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns[\u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m __name__save\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/magics/execution.py:814\u001b[0m, in \u001b[0;36mExecutionMagics.run.<locals>.run\u001b[0;34m()\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m():\n\u001b[0;32m--> 814\u001b[0m     runner(filename, prog_ns, prog_ns,\n\u001b[1;32m    815\u001b[0m             exit_ignore\u001b[39m=\u001b[39;49mexit_ignore)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2755\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile\u001b[0;34m(self, fname, exit_ignore, raise_exceptions, shell_futures, *where)\u001b[0m\n\u001b[1;32m   2753\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   2754\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exit_ignore:\n\u001b[0;32m-> 2755\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshowtraceback(exception_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2756\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   2757\u001b[0m     \u001b[39mif\u001b[39;00m raise_exceptions:\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1983\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[1;32m   1981\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1982\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 1983\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[1;32m   1984\u001b[0m                                                      value))\n\u001b[1;32m   1985\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1986\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1987\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   1988\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[1;32m    578\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \n\u001b[1;32m    580\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:443\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    440\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    441\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    442\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 443\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m    444\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[1;32m    445\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[1;32m    446\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[1;32m    447\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[1;32m    449\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[0;32m-> 1118\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1119\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1009\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m   1010\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[1;32m   1011\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1013\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[1;32m    857\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    858\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[1;32m    863\u001b[0m ):\n\u001b[1;32m    864\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m    866\u001b[0m                                                            tb_offset)\n\u001b[1;32m    868\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[1;32m    797\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[1;32m    798\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 799\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    802\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m    803\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    848\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    849\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[1;32m    850\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[1;32m    851\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[1;32m    852\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    853\u001b[0m )\n\u001b[0;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/stack_data/core.py:546\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[1;32m    532\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    537\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    538\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[1;32m    548\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/stack_data/utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     97\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[1;32m     99\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[1;32m    100\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/stack_data/utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[1;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/Model_Development/ai8x-synthesis/venv/lib/python3.8/site-packages/stack_data/utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    171\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 172\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%cd ../ai8x-synthesis/\n",
    "%run ai8xize.py --verbose --log --test-dir sdk/Examples/MAX78000/CNN --prefix cats_and_dogs --checkpoint-file ../ai8x-training/qat_catdognet_best_q.pth.tar --config-file networks/cats_and_dogs.yaml --device MAX78000 --softmax --compact-data --mexpress --timer 0 --fifo --display-checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai8x-training",
   "language": "python",
   "name": "ai8x-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
