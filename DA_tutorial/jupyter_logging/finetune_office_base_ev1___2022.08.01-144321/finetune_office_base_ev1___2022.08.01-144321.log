2022-08-01 14:43:22,004 - Log file for this run: /home/geffencooper/Model_Development/DA_ai8x-training/DA_tutorial/jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/finetune_office_base_ev1___2022.08.01-144321.log
2022-08-01 14:43:22,004 - Number of CPUs: 16
2022-08-01 14:43:22,040 - Number of GPUs: 1
2022-08-01 14:43:22,040 - CUDA version: 10.2
2022-08-01 14:43:22,040 - CUDNN version: 7605
2022-08-01 14:43:22,040 - Kernel: 5.4.0-113-generic
2022-08-01 14:43:22,040 - Python: 3.8.11 (default, Jun 14 2022, 10:01:20) 
[GCC 9.4.0]
2022-08-01 14:43:22,040 - pip freeze: {'absl-py': '1.2.0', 'appdirs': '1.4.4', 'argon2-cffi': '21.3.0', 'argon2-cffi-bindings': '21.2.0', 'asttokens': '2.0.5', 'atomicwrites': '1.4.1', 'attrs': '21.4.0', 'audioread': '2.1.9', 'backcall': '0.2.0', 'beautifulsoup4': '4.11.1', 'bleach': '5.0.1', 'bqplot': '0.11.5', 'cachetools': '5.2.0', 'certifi': '2022.6.15', 'cffi': '1.15.1', 'charset-normalizer': '2.1.0', 'cloudpickle': '2.1.0', 'cycler': '0.11.0', 'debugpy': '1.6.2', 'decorator': '5.1.1', 'defusedxml': '0.7.1', 'distiller': '0.4.0rc0', 'entrypoints': '0.4', 'executing': '0.9.1', 'fastjsonschema': '2.16.1', 'fonttools': '4.34.4', 'google-auth': '2.9.1', 'google-auth-oauthlib': '0.4.6', 'graphviz': '0.10.1', 'grpcio': '1.47.0', 'gym': '0.12.5', 'h5py': '3.7.0', 'idna': '3.3', 'importlib-metadata': '4.12.0', 'importlib-resources': '5.9.0', 'ipykernel': '6.15.1', 'ipython': '8.4.0', 'ipython-genutils': '0.2.0', 'ipywidgets': '7.4.2', 'jedi': '0.18.1', 'jinja2': '3.1.2', 'joblib': '1.1.0', 'jsonpatch': '1.32', 'jsonpointer': '2.3', 'jsonschema': '4.7.2', 'jupyter': '1.0.0', 'jupyter-client': '7.3.4', 'jupyter-console': '6.4.4', 'jupyter-core': '4.11.1', 'jupyterlab-pygments': '0.2.2', 'kiwisolver': '1.4.4', 'librosa': '0.9.2', 'llvmlite': '0.32.1', 'markdown': '3.4.1', 'markupsafe': '2.1.1', 'matplotlib': '3.5.2', 'matplotlib-inline': '0.1.3', 'mistune': '0.8.4', 'more-itertools': '8.13.0', 'munch': '2.5.0', 'nbclient': '0.6.6', 'nbconvert': '6.5.0', 'nbformat': '5.4.0', 'nest-asyncio': '1.5.5', 'notebook': '6.4.12', 'numba': '0.49.1', 'numpy': '1.22.4', 'oauthlib': '3.2.0', 'opencv-python': '4.6.0.66', 'packaging': '21.3', 'pandas': '1.4.3', 'pandocfilters': '1.5.0', 'parso': '0.8.3', 'pexpect': '4.8.0', 'pickleshare': '0.7.5', 'pillow': '9.2.0', 'pip': '22.2', 'pluggy': '0.13.1', 'pooch': '1.6.0', 'pretrainedmodels': '0.7.4', 'prometheus-client': '0.14.1', 'prompt-toolkit': '3.0.30', 'protobuf': '3.20.1', 'psutil': '5.9.1', 'ptyprocess': '0.7.0', 'pure-eval': '0.2.2', 'py': '1.11.0', 'pyasn1': '0.4.8', 'pyasn1-modules': '0.2.8', 'pycparser': '2.21', 'pydot': '1.4.1', 'pyglet': '1.5.26', 'pygments': '2.12.0', 'pyparsing': '3.0.9', 'pyrsistent': '0.18.1', 'pytest': '4.6.11', 'python-dateutil': '2.8.2', 'pytsmod': '0.3.5', 'pytz': '2022.1', 'pyyaml': '6.0', 'pyzmq': '23.2.0', 'qgrid': '1.1.1', 'qtconsole': '5.3.1', 'qtpy': '2.1.0', 'requests': '2.28.1', 'requests-oauthlib': '1.3.1', 'resampy': '0.3.1', 'rsa': '4.9', 'scikit-learn': '0.23.2', 'scipy': '1.8.1', 'send2trash': '1.8.0', 'setuptools': '63.2.0', 'shap': '0.41.0', 'six': '1.16.0', 'slicer': '0.0.7', 'soundfile': '0.10.3.post1', 'soupsieve': '2.3.2.post1', 'stack-data': '0.3.0', 'tabulate': '0.8.3', 'tensorboard': '2.9.0', 'tensorboard-data-server': '0.6.1', 'tensorboard-plugin-wit': '1.8.1', 'terminado': '0.15.0', 'threadpoolctl': '3.1.0', 'tinycss2': '1.1.1', 'tk': '0.1.0', 'torch': '1.8.1', 'torchfile': '0.1.0', 'torchnet': '0.0.4', 'torchvision': '0.9.1', 'tornado': '6.2', 'tqdm': '4.33.0', 'traitlets': '5.3.0', 'traittypes': '0.2.1', 'typing-extensions': '4.3.0', 'urllib3': '1.26.11', 'visdom': '0.1.8.9', 'wcwidth': '0.2.5', 'webencodings': '0.5.1', 'websocket-client': '1.3.3', 'werkzeug': '2.2.0', 'wheel': '0.37.1', 'widgetsnbextension': '3.4.2', 'xlsxwriter': '3.0.3', 'zipp': '3.8.1'}
2022-08-01 14:43:22,040 - Command line: /home/geffencooper/Model_Development/DA_ai8x-training/venv/lib/python3.8/site-packages/ipykernel_launcher.py --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme="hmac-sha256" --Session.key=b"bd3e4f15-a42e-4f9f-98bc-c23f48091043" --shell=9007 --transport="tcp" --iopub=9009 --f=/home/geffencooper/.local/share/jupyter/runtime/kernel-v2-3810819QcSY8mgJcLym.json
2022-08-01 14:43:22,042 - dataset_name:office
dataset_fn=<function office_get_datasets at 0x7fa2da96cc10>
num_classes=6
model_name=officeclassifier
dimensions=(3, 128, 128)
batch_size=32
validation_split=0.1
lr=0.001000
num_epochs=32
qat_policy={'start_epoch': 4, 'weight_bits': 8}
2022-08-01 14:43:24,095 - Dataset sizes:
	training=467
	validation=51
	test=58
2022-08-01 14:43:24,096 - Augmentations:Compose(
    Resize(size=(128, 128), interpolation=bilinear)
    ColorJitter(brightness=(0.85, 1.15), contrast=(0.75, 1.25), saturation=(0.75, 1.25), hue=(-0.4, 0.4))
    RandomGrayscale(p=0.15)
    RandomAffine(degrees=[-10.0, 10.0], translate=(0.27, 0.27))
    RandomHorizontalFlip(p=0.5)
    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.5))
    ToTensor()
    <ai8x.normalize object at 0x7fa2da8a12e0>
)
Augmentation Seed:1882611234
2022-08-01 14:43:26,761 - => loading checkpoint jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar
2022-08-01 14:43:26,766 - => Checkpoint contents:
+----------------------+-------------+---------------------------+
| Key                  | Type        | Value                     |
|----------------------+-------------+---------------------------|
| arch                 | str         | classifierbackbonenet_qat |
| compression_sched    | dict        |                           |
| epoch                | int         | 99                        |
| extras               | dict        |                           |
| optimizer_state_dict | dict        |                           |
| optimizer_type       | type        | Adam                      |
| state_dict           | OrderedDict |                           |
+----------------------+-------------+---------------------------+

2022-08-01 14:43:26,767 - => Checkpoint['extras'] contents:
+-------+--------+---------+
| Key   | Type   |   Value |
|-------+--------+---------|
| epoch | int    |      99 |
+-------+--------+---------+

2022-08-01 14:43:26,768 - Loaded compression schedule from checkpoint (epoch 99)
2022-08-01 14:43:26,771 - => loaded 'state_dict' from checkpoint 'jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar'
2022-08-01 14:43:26,782 - model: OfficeClassifier(
  (feature_extractor): ClassifierBackbone(
    (conv1): FusedConv2dReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv2): FusedConv2dReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv3): FusedMaxPoolConv2dReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv4): FusedConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv5): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv6): FusedConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv7): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv8): FusedConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv9): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv10): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (fc1): FusedLinearReLU(
      (activate): ReLU(inplace=True)
      (op): Linear(in_features=1024, out_features=128, bias=True)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (do1): Dropout(p=0.5, inplace=False)
    (fc2): FusedLinearReLU(
      (activate): ReLU(inplace=True)
      (op): Linear(in_features=128, out_features=64, bias=True)
      (calc_out_shift): OutputShiftSqueeze()
      (calc_weight_scale): One()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Empty()
      (quantize_bias): Empty()
      (clamp_weight): Empty()
      (clamp_bias): Empty()
      (quantize): Empty()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (fc3): Linear(
      (activate): Empty()
      (op): Linear(in_features=64, out_features=6, bias=True)
      (calc_out_shift): OutputShiftSqueeze()
      (calc_weight_scale): One()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Empty()
      (quantize_bias): Empty()
      (clamp_weight): Empty()
      (clamp_bias): Empty()
      (quantize): Empty()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
  )
  (do1): Dropout(p=0.25, inplace=False)
)
2022-08-01 14:43:28,466 - Number of Model Params: 287278
2022-08-01 14:43:29,269 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-08-01 14:43:29,271 - lr_schedule:base: [0.001] milestones: Counter({4: 1, 8: 1, 20: 1, 100: 1}) gamma: 0.75
2022-08-01 14:43:32,594 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:33,268 - Epoch: [0][   15/   15]    objective_loss 1.768876    Top1 31.372549    Top5 92.156863    LR 0.001000    
2022-08-01 14:43:33,303 - --- validate (epoch=0)-----------
2022-08-01 14:43:33,303 - 51 samples (32 per mini-batch)
2022-08-01 14:43:33,459 - Epoch: [0][    2/    2]    Loss 1.655465    Top1 39.215686    Top5 92.156863    
2022-08-01 14:43:33,491 - ==> Top1: 39.216    Top5: 92.157    Loss: 1.655

2022-08-01 14:43:33,492 - ==> Confusion:
[[ 0  1  4  4  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  4  1  0  0]
 [ 0  0 11  0  0  0]
 [ 0  0  6  1  0  0]]

2022-08-01 14:43:33,588 - ==> Best [Top1: 39.216   Top5: 92.157  on epoch: 0]
2022-08-01 14:43:33,597 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_checkpoint.pth.tar
2022-08-01 14:43:33,613 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:34,241 - Epoch: [1][   15/   15]    objective_loss 1.503520    Top1 47.058824    Top5 100.000000    LR 0.001000    
2022-08-01 14:43:34,275 - --- validate (epoch=1)-----------
2022-08-01 14:43:34,276 - 51 samples (32 per mini-batch)
2022-08-01 14:43:34,434 - Epoch: [1][    2/    2]    Loss 1.199226    Top1 52.941176    Top5 100.000000    
2022-08-01 14:43:34,468 - ==> Top1: 52.941    Top5: 100.000    Loss: 1.199

2022-08-01 14:43:34,469 - ==> Confusion:
[[ 7  1  1  0  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  4  1  0  0]
 [ 0  0 11  0  0  0]
 [ 1  0  6  0  0  0]]

2022-08-01 14:43:34,672 - ==> Best [Top1: 52.941   Top5: 100.000  on epoch: 1]
2022-08-01 14:43:34,682 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_checkpoint.pth.tar
2022-08-01 14:43:34,707 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:35,344 - Epoch: [2][   15/   15]    objective_loss 1.419914    Top1 49.019608    Top5 96.078431    LR 0.001000    
2022-08-01 14:43:35,379 - --- validate (epoch=2)-----------
2022-08-01 14:43:35,379 - 51 samples (32 per mini-batch)
2022-08-01 14:43:35,541 - Epoch: [2][    2/    2]    Loss 1.143159    Top1 47.058824    Top5 98.039216    
2022-08-01 14:43:35,574 - ==> Top1: 47.059    Top5: 98.039    Loss: 1.143

2022-08-01 14:43:35,576 - ==> Confusion:
[[ 4  1  1  0  3  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  4  1  0  0]
 [ 0  0 11  0  0  0]
 [ 0  0  6  0  1  0]]

2022-08-01 14:43:35,654 - ==> Best [Top1: 52.941   Top5: 100.000  on epoch: 1]
2022-08-01 14:43:35,659 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_checkpoint.pth.tar
2022-08-01 14:43:35,679 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:36,306 - Epoch: [3][   15/   15]    objective_loss 1.222008    Top1 58.823529    Top5 96.078431    LR 0.001000    
2022-08-01 14:43:36,340 - --- validate (epoch=3)-----------
2022-08-01 14:43:36,341 - 51 samples (32 per mini-batch)
2022-08-01 14:43:36,500 - Epoch: [3][    2/    2]    Loss 0.951232    Top1 70.588235    Top5 100.000000    
2022-08-01 14:43:36,534 - ==> Top1: 70.588    Top5: 100.000    Loss: 0.951

2022-08-01 14:43:36,535 - ==> Confusion:
[[ 7  1  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  1  0  4  0  0]
 [ 0  0  5  0  6  0]
 [ 1  0  1  5  0  0]]

2022-08-01 14:43:36,626 - ==> Best [Top1: 70.588   Top5: 100.000  on epoch: 3]
2022-08-01 14:43:36,636 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_checkpoint.pth.tar
2022-08-01 14:43:36,683 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:37,322 - Epoch: [4][   15/   15]    objective_loss 1.118175    Top1 60.784314    Top5 98.039216    LR 0.000750    
2022-08-01 14:43:37,357 - --- validate (epoch=4)-----------
2022-08-01 14:43:37,358 - 51 samples (32 per mini-batch)
2022-08-01 14:43:37,517 - Epoch: [4][    2/    2]    Loss 0.895025    Top1 60.784314    Top5 100.000000    
2022-08-01 14:43:37,552 - ==> Top1: 60.784    Top5: 100.000    Loss: 0.895

2022-08-01 14:43:37,553 - ==> Confusion:
[[ 6  0  0  1  2  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  1  4  0  0]
 [ 0  0  8  0  3  0]
 [ 0  0  3  4  0  0]]

2022-08-01 14:43:37,648 - ==> Best [Top1: 60.784   Top5: 100.000  on epoch: 4]
2022-08-01 14:43:37,665 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:37,678 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:38,325 - Epoch: [5][   15/   15]    objective_loss 1.223765    Top1 50.980392    Top5 98.039216    LR 0.000750    
2022-08-01 14:43:38,360 - --- validate (epoch=5)-----------
2022-08-01 14:43:38,361 - 51 samples (32 per mini-batch)
2022-08-01 14:43:38,520 - Epoch: [5][    2/    2]    Loss 1.111161    Top1 66.666667    Top5 100.000000    
2022-08-01 14:43:38,554 - ==> Top1: 66.667    Top5: 100.000    Loss: 1.111

2022-08-01 14:43:38,555 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  0  5  0  0]
 [ 0  1  8  0  2  0]
 [ 0  0  1  6  0  0]]

2022-08-01 14:43:38,650 - ==> Best [Top1: 66.667   Top5: 100.000  on epoch: 5]
2022-08-01 14:43:38,660 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:38,685 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:39,323 - Epoch: [6][   15/   15]    objective_loss 1.129671    Top1 66.666667    Top5 100.000000    LR 0.000750    
2022-08-01 14:43:39,358 - --- validate (epoch=6)-----------
2022-08-01 14:43:39,359 - 51 samples (32 per mini-batch)
2022-08-01 14:43:39,519 - Epoch: [6][    2/    2]    Loss 0.870475    Top1 76.470588    Top5 100.000000    
2022-08-01 14:43:39,552 - ==> Top1: 76.471    Top5: 100.000    Loss: 0.870

2022-08-01 14:43:39,553 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  0  5  0  0]
 [ 0  0  4  0  7  0]
 [ 1  0  0  5  1  0]]

2022-08-01 14:43:39,645 - ==> Best [Top1: 76.471   Top5: 100.000  on epoch: 6]
2022-08-01 14:43:39,656 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:39,686 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:40,336 - Epoch: [7][   15/   15]    objective_loss 1.025530    Top1 78.431373    Top5 100.000000    LR 0.000750    
2022-08-01 14:43:40,371 - --- validate (epoch=7)-----------
2022-08-01 14:43:40,372 - 51 samples (32 per mini-batch)
2022-08-01 14:43:40,533 - Epoch: [7][    2/    2]    Loss 0.833723    Top1 76.470588    Top5 100.000000    
2022-08-01 14:43:40,569 - ==> Top1: 76.471    Top5: 100.000    Loss: 0.834

2022-08-01 14:43:40,569 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  5  0  0]
 [ 0  0  3  0  8  0]
 [ 0  0  1  4  2  0]]

2022-08-01 14:43:40,665 - ==> Best [Top1: 76.471   Top5: 100.000  on epoch: 7]
2022-08-01 14:43:40,670 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:40,696 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:41,335 - Epoch: [8][   15/   15]    objective_loss 0.960906    Top1 80.392157    Top5 100.000000    LR 0.000563    
2022-08-01 14:43:41,370 - --- validate (epoch=8)-----------
2022-08-01 14:43:41,370 - 51 samples (32 per mini-batch)
2022-08-01 14:43:41,529 - Epoch: [8][    2/    2]    Loss 0.856699    Top1 76.470588    Top5 100.000000    
2022-08-01 14:43:41,564 - ==> Top1: 76.471    Top5: 100.000    Loss: 0.857

2022-08-01 14:43:41,565 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  0  5  0  0]
 [ 0  0  4  0  7  0]
 [ 0  0  1  5  1  0]]

2022-08-01 14:43:41,659 - ==> Best [Top1: 76.471   Top5: 100.000  on epoch: 8]
2022-08-01 14:43:41,669 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:41,696 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:42,328 - Epoch: [9][   15/   15]    objective_loss 0.921192    Top1 64.705882    Top5 98.039216    LR 0.000563    
2022-08-01 14:43:42,363 - --- validate (epoch=9)-----------
2022-08-01 14:43:42,364 - 51 samples (32 per mini-batch)
2022-08-01 14:43:42,527 - Epoch: [9][    2/    2]    Loss 0.735647    Top1 76.470588    Top5 100.000000    
2022-08-01 14:43:42,561 - ==> Top1: 76.471    Top5: 100.000    Loss: 0.736

2022-08-01 14:43:42,561 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  5  0  0]
 [ 0  0  3  0  8  0]
 [ 0  0  0  6  1  0]]

2022-08-01 14:43:42,654 - ==> Best [Top1: 76.471   Top5: 100.000  on epoch: 9]
2022-08-01 14:43:42,671 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:42,690 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:43,324 - Epoch: [10][   15/   15]    objective_loss 0.906597    Top1 74.509804    Top5 98.039216    LR 0.000563    
2022-08-01 14:43:43,359 - --- validate (epoch=10)-----------
2022-08-01 14:43:43,360 - 51 samples (32 per mini-batch)
2022-08-01 14:43:43,520 - Epoch: [10][    2/    2]    Loss 0.690322    Top1 82.352941    Top5 100.000000    
2022-08-01 14:43:43,555 - ==> Top1: 82.353    Top5: 100.000    Loss: 0.690

2022-08-01 14:43:43,556 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 10  0  2  0]
 [ 0  0  0  4  0  1]
 [ 0  0  1  0 10  0]
 [ 0  0  0  3  1  3]]

2022-08-01 14:43:43,650 - ==> Best [Top1: 82.353   Top5: 100.000  on epoch: 10]
2022-08-01 14:43:43,660 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:43,686 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:44,312 - Epoch: [11][   15/   15]    objective_loss 0.863808    Top1 76.470588    Top5 100.000000    LR 0.000563    
2022-08-01 14:43:44,347 - --- validate (epoch=11)-----------
2022-08-01 14:43:44,348 - 51 samples (32 per mini-batch)
2022-08-01 14:43:44,507 - Epoch: [11][    2/    2]    Loss 0.658792    Top1 78.431373    Top5 100.000000    
2022-08-01 14:43:44,544 - ==> Top1: 78.431    Top5: 100.000    Loss: 0.659

2022-08-01 14:43:44,545 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  5  0  0]
 [ 0  0  2  0  9  0]
 [ 0  0  0  6  1  0]]

2022-08-01 14:43:44,628 - ==> Best [Top1: 82.353   Top5: 100.000  on epoch: 10]
2022-08-01 14:43:44,633 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:44,655 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:45,292 - Epoch: [12][   15/   15]    objective_loss 0.841893    Top1 84.313725    Top5 100.000000    LR 0.000563    
2022-08-01 14:43:45,326 - --- validate (epoch=12)-----------
2022-08-01 14:43:45,327 - 51 samples (32 per mini-batch)
2022-08-01 14:43:45,488 - Epoch: [12][    2/    2]    Loss 0.650968    Top1 78.431373    Top5 100.000000    
2022-08-01 14:43:45,524 - ==> Top1: 78.431    Top5: 100.000    Loss: 0.651

2022-08-01 14:43:45,525 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  5  0  0]
 [ 0  0  2  0  9  0]
 [ 0  0  0  6  1  0]]

2022-08-01 14:43:45,621 - ==> Best [Top1: 82.353   Top5: 100.000  on epoch: 10]
2022-08-01 14:43:45,631 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:45,654 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:46,295 - Epoch: [13][   15/   15]    objective_loss 0.813262    Top1 78.431373    Top5 98.039216    LR 0.000563    
2022-08-01 14:43:46,330 - --- validate (epoch=13)-----------
2022-08-01 14:43:46,331 - 51 samples (32 per mini-batch)
2022-08-01 14:43:46,488 - Epoch: [13][    2/    2]    Loss 0.584900    Top1 90.196078    Top5 100.000000    
2022-08-01 14:43:46,521 - ==> Top1: 90.196    Top5: 100.000    Loss: 0.585

2022-08-01 14:43:46,522 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 10  0  2  0]
 [ 0  0  0  5  0  0]
 [ 0  0  0  0 11  0]
 [ 0  0  0  1  1  5]]

2022-08-01 14:43:46,618 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 13]
2022-08-01 14:43:46,628 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:46,654 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:47,310 - Epoch: [14][   15/   15]    objective_loss 0.829603    Top1 86.274510    Top5 100.000000    LR 0.000563    
2022-08-01 14:43:47,345 - --- validate (epoch=14)-----------
2022-08-01 14:43:47,345 - 51 samples (32 per mini-batch)
2022-08-01 14:43:47,502 - Epoch: [14][    2/    2]    Loss 0.561052    Top1 80.392157    Top5 100.000000    
2022-08-01 14:43:47,538 - ==> Top1: 80.392    Top5: 100.000    Loss: 0.561

2022-08-01 14:43:47,538 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  4  0  1]
 [ 0  0  3  0  8  0]
 [ 0  0  0  2  2  3]]

2022-08-01 14:43:47,615 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 13]
2022-08-01 14:43:47,620 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:47,643 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:48,286 - Epoch: [15][   15/   15]    objective_loss 0.744125    Top1 80.392157    Top5 98.039216    LR 0.000563    
2022-08-01 14:43:48,320 - --- validate (epoch=15)-----------
2022-08-01 14:43:48,321 - 51 samples (32 per mini-batch)
2022-08-01 14:43:48,482 - Epoch: [15][    2/    2]    Loss 0.526358    Top1 90.196078    Top5 100.000000    
2022-08-01 14:43:48,516 - ==> Top1: 90.196    Top5: 100.000    Loss: 0.526

2022-08-01 14:43:48,517 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 10  0  2  0]
 [ 0  0  0  4  0  1]
 [ 0  0  0  0 11  0]
 [ 0  0  0  0  1  6]]

2022-08-01 14:43:48,611 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 15]
2022-08-01 14:43:48,621 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:48,643 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:49,296 - Epoch: [16][   15/   15]    objective_loss 0.690084    Top1 84.313725    Top5 98.039216    LR 0.000563    
2022-08-01 14:43:49,331 - --- validate (epoch=16)-----------
2022-08-01 14:43:49,332 - 51 samples (32 per mini-batch)
2022-08-01 14:43:49,492 - Epoch: [16][    2/    2]    Loss 0.585750    Top1 82.352941    Top5 100.000000    
2022-08-01 14:43:49,525 - ==> Top1: 82.353    Top5: 100.000    Loss: 0.586

2022-08-01 14:43:49,526 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  5  0  0]
 [ 0  0  1  0 10  0]
 [ 0  0  0  6  0  1]]

2022-08-01 14:43:49,601 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 15]
2022-08-01 14:43:49,606 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:49,618 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:50,255 - Epoch: [17][   15/   15]    objective_loss 0.685243    Top1 80.392157    Top5 100.000000    LR 0.000563    
2022-08-01 14:43:50,290 - --- validate (epoch=17)-----------
2022-08-01 14:43:50,291 - 51 samples (32 per mini-batch)
2022-08-01 14:43:50,450 - Epoch: [17][    2/    2]    Loss 0.455408    Top1 86.274510    Top5 100.000000    
2022-08-01 14:43:50,484 - ==> Top1: 86.275    Top5: 100.000    Loss: 0.455

2022-08-01 14:43:50,485 - ==> Confusion:
[[ 8  0  0  0  0  1]
 [ 0  7  0  0  0  0]
 [ 0  0 10  0  2  0]
 [ 0  0  0  3  0  2]
 [ 0  0  0  0 11  0]
 [ 0  0  0  0  2  5]]

2022-08-01 14:43:50,581 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 15]
2022-08-01 14:43:50,591 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:50,605 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:51,237 - Epoch: [18][   15/   15]    objective_loss 0.653966    Top1 80.392157    Top5 100.000000    LR 0.000563    
2022-08-01 14:43:51,271 - --- validate (epoch=18)-----------
2022-08-01 14:43:51,272 - 51 samples (32 per mini-batch)
2022-08-01 14:43:51,429 - Epoch: [18][    2/    2]    Loss 0.525083    Top1 88.235294    Top5 100.000000    
2022-08-01 14:43:51,464 - ==> Top1: 88.235    Top5: 100.000    Loss: 0.525

2022-08-01 14:43:51,464 - ==> Confusion:
[[ 6  0  0  1  1  1]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  5  0  0]
 [ 0  0  1  0 10  0]
 [ 0  0  0  1  0  6]]

2022-08-01 14:43:51,539 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 15]
2022-08-01 14:43:51,549 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:51,565 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:52,206 - Epoch: [19][   15/   15]    objective_loss 0.668161    Top1 84.313725    Top5 98.039216    LR 0.000563    
2022-08-01 14:43:52,241 - --- validate (epoch=19)-----------
2022-08-01 14:43:52,242 - 51 samples (32 per mini-batch)
2022-08-01 14:43:52,406 - Epoch: [19][    2/    2]    Loss 0.599539    Top1 82.352941    Top5 100.000000    
2022-08-01 14:43:52,440 - ==> Top1: 82.353    Top5: 100.000    Loss: 0.600

2022-08-01 14:43:52,441 - ==> Confusion:
[[ 6  0  0  1  2  0]
 [ 0  7  0  0  0  0]
 [ 0  0  9  1  2  0]
 [ 0  0  0  4  0  1]
 [ 0  0  0  0 11  0]
 [ 0  0  0  0  2  5]]

2022-08-01 14:43:52,518 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 15]
2022-08-01 14:43:52,523 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:52,535 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:53,175 - Epoch: [20][   15/   15]    objective_loss 0.695145    Top1 88.235294    Top5 100.000000    LR 0.000422    
2022-08-01 14:43:53,209 - --- validate (epoch=20)-----------
2022-08-01 14:43:53,210 - 51 samples (32 per mini-batch)
2022-08-01 14:43:53,369 - Epoch: [20][    2/    2]    Loss 0.510885    Top1 86.274510    Top5 100.000000    
2022-08-01 14:43:53,405 - ==> Top1: 86.275    Top5: 100.000    Loss: 0.511

2022-08-01 14:43:53,406 - ==> Confusion:
[[ 8  0  0  0  0  1]
 [ 0  7  0  0  0  0]
 [ 0  0 10  0  2  0]
 [ 0  0  0  2  1  2]
 [ 0  0  0  0 11  0]
 [ 0  0  0  0  1  6]]

2022-08-01 14:43:53,503 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 15]
2022-08-01 14:43:53,513 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:53,526 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:54,161 - Epoch: [21][   15/   15]    objective_loss 0.611017    Top1 86.274510    Top5 100.000000    LR 0.000422    
2022-08-01 14:43:54,207 - --- validate (epoch=21)-----------
2022-08-01 14:43:54,209 - 51 samples (32 per mini-batch)
2022-08-01 14:43:54,370 - Epoch: [21][    2/    2]    Loss 0.552351    Top1 86.274510    Top5 100.000000    
2022-08-01 14:43:54,403 - ==> Top1: 86.275    Top5: 100.000    Loss: 0.552

2022-08-01 14:43:54,404 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  1  4  0  0]
 [ 0  0  1  0 10  0]
 [ 0  0  0  1  2  4]]

2022-08-01 14:43:54,498 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 15]
2022-08-01 14:43:54,508 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:54,523 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:55,160 - Epoch: [22][   15/   15]    objective_loss 0.586933    Top1 86.274510    Top5 100.000000    LR 0.000422    
2022-08-01 14:43:55,195 - --- validate (epoch=22)-----------
2022-08-01 14:43:55,196 - 51 samples (32 per mini-batch)
2022-08-01 14:43:55,358 - Epoch: [22][    2/    2]    Loss 0.408509    Top1 90.196078    Top5 100.000000    
2022-08-01 14:43:55,394 - ==> Top1: 90.196    Top5: 100.000    Loss: 0.409

2022-08-01 14:43:55,395 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  4  0  1]
 [ 0  0  1  0 10  0]
 [ 0  0  0  1  0  6]]

2022-08-01 14:43:55,490 - ==> Best [Top1: 90.196   Top5: 100.000  on epoch: 22]
2022-08-01 14:43:55,500 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:55,516 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:56,151 - Epoch: [23][   15/   15]    objective_loss 0.557857    Top1 88.235294    Top5 100.000000    LR 0.000422    
2022-08-01 14:43:56,186 - --- validate (epoch=23)-----------
2022-08-01 14:43:56,187 - 51 samples (32 per mini-batch)
2022-08-01 14:43:56,346 - Epoch: [23][    2/    2]    Loss 0.398572    Top1 92.156863    Top5 100.000000    
2022-08-01 14:43:56,380 - ==> Top1: 92.157    Top5: 100.000    Loss: 0.399

2022-08-01 14:43:56,380 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  4  0  1]
 [ 0  0  0  0 10  1]
 [ 0  0  0  0  0  7]]

2022-08-01 14:43:56,458 - ==> Best [Top1: 92.157   Top5: 100.000  on epoch: 23]
2022-08-01 14:43:56,463 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:56,477 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:57,129 - Epoch: [24][   15/   15]    objective_loss 0.575068    Top1 90.196078    Top5 100.000000    LR 0.000422    
2022-08-01 14:43:57,164 - --- validate (epoch=24)-----------
2022-08-01 14:43:57,165 - 51 samples (32 per mini-batch)
2022-08-01 14:43:57,326 - Epoch: [24][    2/    2]    Loss 0.434495    Top1 90.196078    Top5 100.000000    
2022-08-01 14:43:57,360 - ==> Top1: 90.196    Top5: 100.000    Loss: 0.434

2022-08-01 14:43:57,361 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 10  0  2  0]
 [ 0  0  0  4  0  1]
 [ 0  0  0  0 11  0]
 [ 0  0  0  0  1  6]]

2022-08-01 14:43:57,457 - ==> Best [Top1: 92.157   Top5: 100.000  on epoch: 23]
2022-08-01 14:43:57,467 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:57,480 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:58,114 - Epoch: [25][   15/   15]    objective_loss 0.535467    Top1 82.352941    Top5 100.000000    LR 0.000422    
2022-08-01 14:43:58,149 - --- validate (epoch=25)-----------
2022-08-01 14:43:58,150 - 51 samples (32 per mini-batch)
2022-08-01 14:43:58,308 - Epoch: [25][    2/    2]    Loss 0.583074    Top1 84.313725    Top5 100.000000    
2022-08-01 14:43:58,341 - ==> Top1: 84.314    Top5: 100.000    Loss: 0.583

2022-08-01 14:43:58,342 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  1  4  0  0]
 [ 0  0  3  0  8  0]
 [ 0  0  1  2  0  4]]

2022-08-01 14:43:58,422 - ==> Best [Top1: 92.157   Top5: 100.000  on epoch: 23]
2022-08-01 14:43:58,432 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:58,449 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:43:59,089 - Epoch: [26][   15/   15]    objective_loss 0.558046    Top1 82.352941    Top5 100.000000    LR 0.000422    
2022-08-01 14:43:59,124 - --- validate (epoch=26)-----------
2022-08-01 14:43:59,124 - 51 samples (32 per mini-batch)
2022-08-01 14:43:59,284 - Epoch: [26][    2/    2]    Loss 0.372428    Top1 90.196078    Top5 100.000000    
2022-08-01 14:43:59,318 - ==> Top1: 90.196    Top5: 100.000    Loss: 0.372

2022-08-01 14:43:59,319 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  0  4  0  1]
 [ 0  0  0  0 10  1]
 [ 0  0  0  1  0  6]]

2022-08-01 14:43:59,395 - ==> Best [Top1: 92.157   Top5: 100.000  on epoch: 23]
2022-08-01 14:43:59,400 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:43:59,506 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:44:00,147 - Epoch: [27][   15/   15]    objective_loss 0.508042    Top1 92.156863    Top5 100.000000    LR 0.000422    
2022-08-01 14:44:00,182 - --- validate (epoch=27)-----------
2022-08-01 14:44:00,183 - 51 samples (32 per mini-batch)
2022-08-01 14:44:00,343 - Epoch: [27][    2/    2]    Loss 0.449687    Top1 92.156863    Top5 100.000000    
2022-08-01 14:44:00,377 - ==> Top1: 92.157    Top5: 100.000    Loss: 0.450

2022-08-01 14:44:00,377 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 11  0  1  0]
 [ 0  0  1  4  0  0]
 [ 0  0  1  0 10  0]
 [ 0  0  0  0  0  7]]

2022-08-01 14:44:00,473 - ==> Best [Top1: 92.157   Top5: 100.000  on epoch: 27]
2022-08-01 14:44:00,482 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:44:00,499 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:44:01,139 - Epoch: [28][   15/   15]    objective_loss 0.484382    Top1 92.156863    Top5 100.000000    LR 0.000422    
2022-08-01 14:44:01,173 - --- validate (epoch=28)-----------
2022-08-01 14:44:01,174 - 51 samples (32 per mini-batch)
2022-08-01 14:44:01,338 - Epoch: [28][    2/    2]    Loss 0.423060    Top1 94.117647    Top5 100.000000    
2022-08-01 14:44:01,371 - ==> Top1: 94.118    Top5: 100.000    Loss: 0.423

2022-08-01 14:44:01,373 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  1  4  0  0]
 [ 0  0  1  0 10  0]
 [ 0  0  0  0  0  7]]

2022-08-01 14:44:01,454 - ==> Best [Top1: 94.118   Top5: 100.000  on epoch: 28]
2022-08-01 14:44:01,464 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:44:01,483 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:44:02,122 - Epoch: [29][   15/   15]    objective_loss 0.483104    Top1 84.313725    Top5 100.000000    LR 0.000422    
2022-08-01 14:44:02,157 - --- validate (epoch=29)-----------
2022-08-01 14:44:02,158 - 51 samples (32 per mini-batch)
2022-08-01 14:44:02,317 - Epoch: [29][    2/    2]    Loss 0.509571    Top1 88.235294    Top5 100.000000    
2022-08-01 14:44:02,350 - ==> Top1: 88.235    Top5: 100.000    Loss: 0.510

2022-08-01 14:44:02,351 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  1  4  0  0]
 [ 0  0  3  0  8  0]
 [ 1  0  0  0  0  6]]

2022-08-01 14:44:02,427 - ==> Best [Top1: 94.118   Top5: 100.000  on epoch: 28]
2022-08-01 14:44:02,432 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:44:02,445 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:44:03,100 - Epoch: [30][   15/   15]    objective_loss 0.459741    Top1 90.196078    Top5 100.000000    LR 0.000422    
2022-08-01 14:44:03,136 - --- validate (epoch=30)-----------
2022-08-01 14:44:03,137 - 51 samples (32 per mini-batch)
2022-08-01 14:44:03,296 - Epoch: [30][    2/    2]    Loss 0.463513    Top1 92.156863    Top5 98.039216    
2022-08-01 14:44:03,330 - ==> Top1: 92.157    Top5: 98.039    Loss: 0.464

2022-08-01 14:44:03,331 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  1  4  0  0]
 [ 0  0  1  0 10  0]
 [ 0  0  0  1  0  6]]

2022-08-01 14:44:03,406 - ==> Best [Top1: 94.118   Top5: 100.000  on epoch: 28]
2022-08-01 14:44:03,416 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:44:03,434 - Training epoch: 467 samples (32 per mini-batch)
2022-08-01 14:44:04,084 - Epoch: [31][   15/   15]    objective_loss 0.454645    Top1 92.156863    Top5 100.000000    LR 0.000422    
2022-08-01 14:44:04,119 - --- validate (epoch=31)-----------
2022-08-01 14:44:04,120 - 51 samples (32 per mini-batch)
2022-08-01 14:44:04,280 - Epoch: [31][    2/    2]    Loss 0.305135    Top1 94.117647    Top5 100.000000    
2022-08-01 14:44:04,314 - ==> Top1: 94.118    Top5: 100.000    Loss: 0.305

2022-08-01 14:44:04,315 - ==> Confusion:
[[ 8  0  0  1  0  0]
 [ 0  7  0  0  0  0]
 [ 0  0 12  0  0  0]
 [ 0  0  0  4  0  1]
 [ 0  0  1  0 10  0]
 [ 0  0  0  0  0  7]]

2022-08-01 14:44:04,391 - ==> Best [Top1: 94.118   Top5: 100.000  on epoch: 31]
2022-08-01 14:44:04,401 - Saving checkpoint to: jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_checkpoint.pth.tar
2022-08-01 14:44:04,420 - Training time: 0:00:31.826174
2022-08-01 14:44:26,946 - => loading checkpoint jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar
2022-08-01 14:44:26,952 - => Checkpoint contents:
+----------------------+-------------+---------------------------+
| Key                  | Type        | Value                     |
|----------------------+-------------+---------------------------|
| arch                 | str         | classifierbackbonenet_qat |
| compression_sched    | dict        |                           |
| epoch                | int         | 99                        |
| extras               | dict        |                           |
| optimizer_state_dict | dict        |                           |
| optimizer_type       | type        | Adam                      |
| state_dict           | OrderedDict |                           |
+----------------------+-------------+---------------------------+

2022-08-01 14:44:26,953 - => Checkpoint['extras'] contents:
+-------+--------+---------+
| Key   | Type   |   Value |
|-------+--------+---------|
| epoch | int    |      99 |
+-------+--------+---------+

2022-08-01 14:44:26,953 - Loaded compression schedule from checkpoint (epoch 99)
2022-08-01 14:44:26,959 - => loaded 'state_dict' from checkpoint 'jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar'
2022-08-01 14:44:26,982 - => loading checkpoint jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_best.pth.tar
2022-08-01 14:44:26,987 - => Checkpoint contents:
+----------------------+-------------+----------------------+
| Key                  | Type        | Value                |
|----------------------+-------------+----------------------|
| arch                 | str         | officeclassifier_qat |
| compression_sched    | dict        |                      |
| epoch                | int         | 31                   |
| extras               | dict        |                      |
| optimizer_state_dict | dict        |                      |
| optimizer_type       | type        | Adam                 |
| state_dict           | OrderedDict |                      |
+----------------------+-------------+----------------------+

2022-08-01 14:44:26,988 - => Checkpoint['extras'] contents:
+--------------+--------+---------+
| Key          | Type   |   Value |
|--------------+--------+---------|
| best_epoch   | int    | 31      |
| best_top1    | float  | 94.1176 |
| current_top1 | float  | 94.1176 |
+--------------+--------+---------+

2022-08-01 14:44:26,989 - Loaded compression schedule from checkpoint (epoch 31)
2022-08-01 14:44:27,026 - => loaded 'state_dict' from checkpoint 'jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_best.pth.tar'
2022-08-01 14:44:27,038 - 58 samples (32 per mini-batch)
2022-08-01 14:44:27,200 - Test: [    2/    2]    Loss 0.399842    Top1 91.379310    Top5 100.000000    
2022-08-01 14:44:27,233 - ==> Top1: 91.379    Top5: 100.000    Loss: 0.400

2022-08-01 14:44:27,234 - ==> Confusion:
[[10  0  0  0  0  0]
 [ 0  8  0  0  0  0]
 [ 0  0 10  0  0  0]
 [ 0  0  2  8  0  0]
 [ 0  0  0  0 10  0]
 [ 0  0  1  1  1  7]]

2022-08-01 14:44:27,235 - ==> Test Set [Top1: 91.379   Top5: 100.000  on test set]
2022-08-01 14:44:52,294 - => loading checkpoint jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar
2022-08-01 14:44:52,301 - => Checkpoint contents:
+----------------------+-------------+---------------------------+
| Key                  | Type        | Value                     |
|----------------------+-------------+---------------------------|
| arch                 | str         | classifierbackbonenet_qat |
| compression_sched    | dict        |                           |
| epoch                | int         | 99                        |
| extras               | dict        |                           |
| optimizer_state_dict | dict        |                           |
| optimizer_type       | type        | Adam                      |
| state_dict           | OrderedDict |                           |
+----------------------+-------------+---------------------------+

2022-08-01 14:44:52,301 - => Checkpoint['extras'] contents:
+-------+--------+---------+
| Key   | Type   |   Value |
|-------+--------+---------|
| epoch | int    |      99 |
+-------+--------+---------+

2022-08-01 14:44:52,302 - Loaded compression schedule from checkpoint (epoch 99)
2022-08-01 14:44:52,307 - => loaded 'state_dict' from checkpoint 'jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar'
2022-08-01 14:44:52,330 - => loading checkpoint jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_best.pth.tar
2022-08-01 14:44:52,335 - => Checkpoint contents:
+----------------------+-------------+----------------------+
| Key                  | Type        | Value                |
|----------------------+-------------+----------------------|
| arch                 | str         | officeclassifier_qat |
| compression_sched    | dict        |                      |
| epoch                | int         | 31                   |
| extras               | dict        |                      |
| optimizer_state_dict | dict        |                      |
| optimizer_type       | type        | Adam                 |
| state_dict           | OrderedDict |                      |
+----------------------+-------------+----------------------+

2022-08-01 14:44:52,335 - => Checkpoint['extras'] contents:
+--------------+--------+---------+
| Key          | Type   |   Value |
|--------------+--------+---------|
| best_epoch   | int    | 31      |
| best_top1    | float  | 94.1176 |
| current_top1 | float  | 94.1176 |
+--------------+--------+---------+

2022-08-01 14:44:52,336 - Loaded compression schedule from checkpoint (epoch 31)
2022-08-01 14:44:52,379 - => loaded 'state_dict' from checkpoint 'jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_best.pth.tar'
2022-08-01 14:44:52,391 - 78 samples (32 per mini-batch)
2022-08-01 14:44:52,547 - Test: [    3/    3]    Loss 3.728716    Top1 14.102564    Top5 85.897436    
2022-08-01 14:44:52,580 - ==> Top1: 14.103    Top5: 85.897    Loss: 3.729

2022-08-01 14:44:52,581 - ==> Confusion:
[[ 0 11  0  0  0  0]
 [ 0 10  0  0  0  0]
 [ 0  8  0  0  0  0]
 [ 0 16  0  0  0  0]
 [ 0 18  0  0  1  0]
 [ 0 14  0  0  0  0]]

2022-08-01 14:44:52,581 - ==> Test Set [Top1: 14.103   Top5: 85.897  on test set]
2022-08-01 14:45:22,953 - => loading checkpoint jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar
2022-08-01 14:45:22,958 - => Checkpoint contents:
+----------------------+-------------+---------------------------+
| Key                  | Type        | Value                     |
|----------------------+-------------+---------------------------|
| arch                 | str         | classifierbackbonenet_qat |
| compression_sched    | dict        |                           |
| epoch                | int         | 99                        |
| extras               | dict        |                           |
| optimizer_state_dict | dict        |                           |
| optimizer_type       | type        | Adam                      |
| state_dict           | OrderedDict |                           |
+----------------------+-------------+---------------------------+

2022-08-01 14:45:22,959 - => Checkpoint['extras'] contents:
+-------+--------+---------+
| Key   | Type   |   Value |
|-------+--------+---------|
| epoch | int    |      99 |
+-------+--------+---------+

2022-08-01 14:45:22,959 - Loaded compression schedule from checkpoint (epoch 99)
2022-08-01 14:45:22,964 - => loaded 'state_dict' from checkpoint 'jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar'
2022-08-01 14:45:22,989 - => loading checkpoint jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_best.pth.tar
2022-08-01 14:45:22,993 - => Checkpoint contents:
+----------------------+-------------+----------------------+
| Key                  | Type        | Value                |
|----------------------+-------------+----------------------|
| arch                 | str         | officeclassifier_qat |
| compression_sched    | dict        |                      |
| epoch                | int         | 31                   |
| extras               | dict        |                      |
| optimizer_state_dict | dict        |                      |
| optimizer_type       | type        | Adam                 |
| state_dict           | OrderedDict |                      |
+----------------------+-------------+----------------------+

2022-08-01 14:45:22,994 - => Checkpoint['extras'] contents:
+--------------+--------+---------+
| Key          | Type   |   Value |
|--------------+--------+---------|
| best_epoch   | int    | 31      |
| best_top1    | float  | 94.1176 |
| current_top1 | float  | 94.1176 |
+--------------+--------+---------+

2022-08-01 14:45:22,995 - Loaded compression schedule from checkpoint (epoch 31)
2022-08-01 14:45:23,038 - => loaded 'state_dict' from checkpoint 'jupyter_logging/finetune_office_base_ev1___2022.08.01-144321/officeclassifier_qat_best.pth.tar'
