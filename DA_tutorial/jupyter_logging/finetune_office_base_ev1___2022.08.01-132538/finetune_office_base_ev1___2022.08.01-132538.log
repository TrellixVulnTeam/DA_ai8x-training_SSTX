2022-08-01 13:25:38,476 - Log file for this run: /home/geffencooper/Model_Development/DA_ai8x-training/DA_tutorial/jupyter_logging/finetune_office_base_ev1___2022.08.01-132538/finetune_office_base_ev1___2022.08.01-132538.log
2022-08-01 13:25:38,477 - Number of CPUs: 16
2022-08-01 13:25:38,477 - Number of GPUs: 1
2022-08-01 13:25:38,477 - CUDA version: 10.2
2022-08-01 13:25:38,477 - CUDNN version: 7605
2022-08-01 13:25:38,477 - Kernel: 5.4.0-113-generic
2022-08-01 13:25:38,477 - Python: 3.8.11 (default, Jun 14 2022, 10:01:20) 
[GCC 9.4.0]
2022-08-01 13:25:38,477 - pip freeze: {'absl-py': '1.2.0', 'appdirs': '1.4.4', 'argon2-cffi': '21.3.0', 'argon2-cffi-bindings': '21.2.0', 'asttokens': '2.0.5', 'atomicwrites': '1.4.1', 'attrs': '21.4.0', 'audioread': '2.1.9', 'backcall': '0.2.0', 'beautifulsoup4': '4.11.1', 'bleach': '5.0.1', 'bqplot': '0.11.5', 'cachetools': '5.2.0', 'certifi': '2022.6.15', 'cffi': '1.15.1', 'charset-normalizer': '2.1.0', 'cloudpickle': '2.1.0', 'cycler': '0.11.0', 'debugpy': '1.6.2', 'decorator': '5.1.1', 'defusedxml': '0.7.1', 'distiller': '0.4.0rc0', 'entrypoints': '0.4', 'executing': '0.9.1', 'fastjsonschema': '2.16.1', 'fonttools': '4.34.4', 'google-auth': '2.9.1', 'google-auth-oauthlib': '0.4.6', 'graphviz': '0.10.1', 'grpcio': '1.47.0', 'gym': '0.12.5', 'h5py': '3.7.0', 'idna': '3.3', 'importlib-metadata': '4.12.0', 'importlib-resources': '5.9.0', 'ipykernel': '6.15.1', 'ipython': '8.4.0', 'ipython-genutils': '0.2.0', 'ipywidgets': '7.4.2', 'jedi': '0.18.1', 'jinja2': '3.1.2', 'joblib': '1.1.0', 'jsonpatch': '1.32', 'jsonpointer': '2.3', 'jsonschema': '4.7.2', 'jupyter': '1.0.0', 'jupyter-client': '7.3.4', 'jupyter-console': '6.4.4', 'jupyter-core': '4.11.1', 'jupyterlab-pygments': '0.2.2', 'kiwisolver': '1.4.4', 'librosa': '0.9.2', 'llvmlite': '0.32.1', 'markdown': '3.4.1', 'markupsafe': '2.1.1', 'matplotlib': '3.5.2', 'matplotlib-inline': '0.1.3', 'mistune': '0.8.4', 'more-itertools': '8.13.0', 'munch': '2.5.0', 'nbclient': '0.6.6', 'nbconvert': '6.5.0', 'nbformat': '5.4.0', 'nest-asyncio': '1.5.5', 'notebook': '6.4.12', 'numba': '0.49.1', 'numpy': '1.22.4', 'oauthlib': '3.2.0', 'opencv-python': '4.6.0.66', 'packaging': '21.3', 'pandas': '1.4.3', 'pandocfilters': '1.5.0', 'parso': '0.8.3', 'pexpect': '4.8.0', 'pickleshare': '0.7.5', 'pillow': '9.2.0', 'pip': '22.2', 'pluggy': '0.13.1', 'pooch': '1.6.0', 'pretrainedmodels': '0.7.4', 'prometheus-client': '0.14.1', 'prompt-toolkit': '3.0.30', 'protobuf': '3.20.1', 'psutil': '5.9.1', 'ptyprocess': '0.7.0', 'pure-eval': '0.2.2', 'py': '1.11.0', 'pyasn1': '0.4.8', 'pyasn1-modules': '0.2.8', 'pycparser': '2.21', 'pydot': '1.4.1', 'pyglet': '1.5.26', 'pygments': '2.12.0', 'pyparsing': '3.0.9', 'pyrsistent': '0.18.1', 'pytest': '4.6.11', 'python-dateutil': '2.8.2', 'pytsmod': '0.3.5', 'pytz': '2022.1', 'pyyaml': '6.0', 'pyzmq': '23.2.0', 'qgrid': '1.1.1', 'qtconsole': '5.3.1', 'qtpy': '2.1.0', 'requests': '2.28.1', 'requests-oauthlib': '1.3.1', 'resampy': '0.3.1', 'rsa': '4.9', 'scikit-learn': '0.23.2', 'scipy': '1.8.1', 'send2trash': '1.8.0', 'setuptools': '63.2.0', 'shap': '0.41.0', 'six': '1.16.0', 'slicer': '0.0.7', 'soundfile': '0.10.3.post1', 'soupsieve': '2.3.2.post1', 'stack-data': '0.3.0', 'tabulate': '0.8.3', 'tensorboard': '2.9.0', 'tensorboard-data-server': '0.6.1', 'tensorboard-plugin-wit': '1.8.1', 'terminado': '0.15.0', 'threadpoolctl': '3.1.0', 'tinycss2': '1.1.1', 'tk': '0.1.0', 'torch': '1.8.1', 'torchfile': '0.1.0', 'torchnet': '0.0.4', 'torchvision': '0.9.1', 'tornado': '6.2', 'tqdm': '4.33.0', 'traitlets': '5.3.0', 'traittypes': '0.2.1', 'typing-extensions': '4.3.0', 'urllib3': '1.26.11', 'visdom': '0.1.8.9', 'wcwidth': '0.2.5', 'webencodings': '0.5.1', 'websocket-client': '1.3.3', 'werkzeug': '2.2.0', 'wheel': '0.37.1', 'widgetsnbextension': '3.4.2', 'xlsxwriter': '3.0.3', 'zipp': '3.8.1'}
2022-08-01 13:25:38,477 - Command line: /home/geffencooper/Model_Development/DA_ai8x-training/venv/lib/python3.8/site-packages/ipykernel_launcher.py --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme="hmac-sha256" --Session.key=b"452fe294-0cca-412a-815a-1e974475143a" --shell=9007 --transport="tcp" --iopub=9009 --f=/home/geffencooper/.local/share/jupyter/runtime/kernel-v2-38108191AOeOBiwOm7z.json
2022-08-01 13:25:38,478 - dataset_name:office
dataset_fn=<function office_get_datasets at 0x7fd4667e1c10>
num_classes=5
model_name=officeclassifier
dimensions=(3, 128, 128)
batch_size=32
validation_split=0.1
lr=0.001000
num_epochs=32
qat_policy={'start_epoch': 4, 'weight_bits': 8}
2022-08-01 13:25:44,602 - Dataset sizes:
	training=392
	validation=43
	test=50
2022-08-01 13:25:44,603 - Augmentations:Compose(
    Resize(size=(128, 128), interpolation=bilinear)
    ColorJitter(brightness=(0.85, 1.15), contrast=(0.75, 1.25), saturation=(0.75, 1.25), hue=(-0.4, 0.4))
    RandomGrayscale(p=0.15)
    RandomAffine(degrees=[-10.0, 10.0], translate=(0.27, 0.27))
    RandomHorizontalFlip(p=0.5)
    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.5))
    ToTensor()
    <ai8x.normalize object at 0x7fd4667a5280>
)
Augmentation Seed:1460996336
2022-08-01 13:25:56,016 - => loading checkpoint jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar
2022-08-01 13:25:56,021 - => Checkpoint contents:
+----------------------+-------------+---------------------------+
| Key                  | Type        | Value                     |
|----------------------+-------------+---------------------------|
| arch                 | str         | classifierbackbonenet_qat |
| compression_sched    | dict        |                           |
| epoch                | int         | 99                        |
| extras               | dict        |                           |
| optimizer_state_dict | dict        |                           |
| optimizer_type       | type        | Adam                      |
| state_dict           | OrderedDict |                           |
+----------------------+-------------+---------------------------+

2022-08-01 13:25:56,022 - => Checkpoint['extras'] contents:
+-------+--------+---------+
| Key   | Type   |   Value |
|-------+--------+---------|
| epoch | int    |      99 |
+-------+--------+---------+

2022-08-01 13:25:56,022 - Loaded compression schedule from checkpoint (epoch 99)
2022-08-01 13:25:56,026 - => loaded 'state_dict' from checkpoint 'jupyter_logging/SSL___2022.07.15-171757/classifierbackbonenet_qat_checkpoint.pth.tar'
2022-08-01 13:25:56,037 - model: OfficeClassifier(
  (feature_extractor): ClassifierBackbone(
    (conv1): FusedConv2dReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv2): FusedConv2dReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv3): FusedMaxPoolConv2dReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv4): FusedConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv5): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv6): FusedConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv7): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv8): FusedConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv9): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (conv10): FusedMaxPoolConv2dBNReLU(
      (activate): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): None
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (fc1): FusedLinearReLU(
      (activate): ReLU(inplace=True)
      (op): Linear(in_features=1024, out_features=128, bias=True)
      (calc_out_shift): OutputShift()
      (calc_weight_scale): WeightScale()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Quantize()
      (quantize_bias): Quantize()
      (clamp_weight): Clamp()
      (clamp_bias): Clamp()
      (quantize): Quantize()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (do1): Dropout(p=0.5, inplace=False)
    (fc2): FusedLinearReLU(
      (activate): ReLU(inplace=True)
      (op): Linear(in_features=128, out_features=64, bias=True)
      (calc_out_shift): OutputShiftSqueeze()
      (calc_weight_scale): One()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Empty()
      (quantize_bias): Empty()
      (clamp_weight): Empty()
      (clamp_bias): Empty()
      (quantize): Empty()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
    (fc3): Linear(
      (activate): Empty()
      (op): Linear(in_features=64, out_features=6, bias=True)
      (calc_out_shift): OutputShiftSqueeze()
      (calc_weight_scale): One()
      (scale): Scaler()
      (calc_out_scale): OutputScale()
      (quantize_weight): Empty()
      (quantize_bias): Empty()
      (clamp_weight): Empty()
      (clamp_bias): Empty()
      (quantize): Empty()
      (clamp): Clamp()
      (quantize_pool): Empty()
      (clamp_pool): Empty()
    )
  )
  (do1): Dropout(p=0.25, inplace=False)
)
2022-08-01 13:25:57,756 - Number of Model Params: 287278
2022-08-01 13:26:01,834 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-08-01 13:26:01,835 - lr_schedule:base: [0.001] milestones: Counter({4: 1, 8: 1, 20: 1, 100: 1}) gamma: 0.75
2022-08-01 13:26:07,410 - Training epoch: 392 samples (32 per mini-batch)
2022-08-01 13:26:08,047 - Epoch: [0][   13/   13]    objective_loss 1.697892    Top1 22.500000    LR 0.001000    
2022-08-01 13:26:08,092 - --- validate (epoch=0)-----------
2022-08-01 13:26:08,093 - 43 samples (32 per mini-batch)
